{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine-Tune Orchid219 Image classification with ViT",
      "provenance": [],
      "collapsed_sections": [
        "5lYnSRfsvhd_",
        "2kKsDcHu0hlX",
        "F3AZ8EIyzzir",
        "2ozr9xyv0ZMi",
        "NhO8MiJ41HLI",
        "RcO8DSXZz7W5",
        "MzvQ9zfD34bE",
        "p9t54nRI4B5q",
        "NNvuAbjI4PWH",
        "WJsYvA7u4dLr"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# FOR TPU needs\n",
        "---"
      ],
      "metadata": {
        "id": "5lYnSRfsvhd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip uninstall -y torch\n",
        "!pip install torch==1.8.2+cpu torchvision==0.9.2+cpu -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html\n",
        "!pip install cloud-tpu-client==0.10 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8-cp37-cp37m-linux_x86_64.whl"
      ],
      "metadata": {
        "id": "94vK4zQPvfGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 是否要掛載 Google Drive\n",
        "---"
      ],
      "metadata": {
        "id": "2kKsDcHu0hlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4aEAQyCz1950"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 確認 GPU 類型\n",
        "---"
      ],
      "metadata": {
        "id": "2ozr9xyv0ZMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "if not torch.cuda.is_available():\n",
        "  raise Exception(\"GPU not availalbe. CPU training will be too slow.\")\n",
        "print(\"device name\", torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "id": "aDtXj7uU119F",
        "outputId": "1db356df-3fd5-4db4-ac6b-8802a772e177",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device name Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 安裝 transformers,datastes,... 相依套件\n",
        "---"
      ],
      "metadata": {
        "id": "1O9n-3Ak0rik"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9T850192NHC"
      },
      "source": [
        "%%capture\n",
        "!pip install git+https://github.com/huggingface/datasets.git\n",
        "!pip install git+https://github.com/huggingface/transformers.git\n",
        "!pip install soundfile\n",
        "!pip install jiwer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/huggingface/transformers.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngh37Hdl7cWi",
        "outputId": "c0db270b-3c6f-4c84-afaa-bc1146f4f84d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 100736, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 100736 (delta 50), reused 54 (delta 44), pack-reused 100643\u001b[K\n",
            "Receiving objects: 100% (100736/100736), 90.26 MiB | 14.63 MiB/s, done.\n",
            "Resolving deltas: 100% (73838/73838), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! apt install git-lfs\n",
        "! git config --global user.email \"gary109@gmail.com\"\n",
        "! git config --global user.name \"GARY\"\n",
        "! git config --global credential.helper store"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuGCGjXT7fIK",
        "outputId": "d245637d-50ee-4036-c877-83d2168ac7f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (2.3.4-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 登入 huggingface \n",
        "---"
      ],
      "metadata": {
        "id": "A1JcSRcJ0_uA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! huggingface-cli login\n",
        "# from huggingface_hub import notebook_login\n",
        "# notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e13db7f1-3470-4115-bc0b-ffdf7e43fe75",
        "id": "yC1Cp6_e2U77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "        _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "        _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "        _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "        _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "        _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "        To login, `huggingface_hub` now requires a token generated from https://huggingface.co/settings/tokens.\n",
            "        (Deprecated, will be removed in v0.3.0) To login with username and password instead, interrupt with Ctrl+C.\n",
            "        \n",
            "Token: \n",
            "Login successful\n",
            "Your token has been saved to /root/.huggingface/token\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 安裝加速器\n",
        "---"
      ],
      "metadata": {
        "id": "F3AZ8EIyzzir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! pip install accelerate deepspeed"
      ],
      "metadata": {
        "id": "WsDxQ0683W6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! accelerate config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJJEgLEi7OBF",
        "outputId": "58667fd7-e4d7-4af6-c720-a5809254feba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In which compute environment are you running? ([0] This machine, [1] AWS (Amazon SageMaker)): 0\n",
            "Which type of machine are you using? ([0] No distributed training, [1] multi-CPU, [2] multi-GPU, [3] TPU): 0\n",
            "Do you want to run your training on CPU only (even if a GPU is available)? [no]:\n",
            "Do you want to use DeepSpeed? [yes/NO]: \n",
            "How many processes in total will you use? [1]: \n",
            "Do you wish to use FP16 or BF16 (mixed precision)? [NO/fp16/bf16]: fp16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! accelerate test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1EszQTy7JTh",
        "outputId": "1e1d82e2-eeeb-448e-93f6-249c23b19671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running:  accelerate-launch --config_file=None /usr/local/lib/python3.7/dist-packages/accelerate/test_utils/test_script.py\n",
            "stdout: **Initialization**\n",
            "stdout: Testing, testing. 1, 2, 3.\n",
            "stdout: Distributed environment: NO\n",
            "stdout: Num processes: 1\n",
            "stdout: Process index: 0\n",
            "stdout: Local process index: 0\n",
            "stdout: Device: cuda\n",
            "stdout: Mixed precision type: fp16\n",
            "stdout: \n",
            "stdout: \n",
            "stdout: **Test random number generator synchronization**\n",
            "stdout: All rng are properly synched.\n",
            "stdout: \n",
            "stdout: **DataLoader integration test**\n",
            "stdout: 0 tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
            "stdout:         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31],\n",
            "stdout:        device='cuda:0') <class 'accelerate.data_loader.DataLoaderShard'>\n",
            "stdout: Non-shuffled dataloader passing.\n",
            "stdout: Shuffled dataloader passing.\n",
            "stdout: Non-shuffled central dataloader passing.\n",
            "stdout: Shuffled central dataloader passing.\n",
            "stdout: \n",
            "stdout: **Training integration test**\n",
            "stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32\n",
            "stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32\n",
            "stdout: Training yielded the same results on one CPU or distributed setup with no batch split.\n",
            "stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32\n",
            "stdout: Training yielded the same results on one CPU or distributes setup with batch split.\n",
            "stdout: FP16 training check.\n",
            "stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32\n",
            "stdout: Legacy FP16 training check.\n",
            "stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32\n",
            "stdout: BF16 training check.\n",
            "stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32\n",
            "Test is a success! You are ready for your distributed training!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 下載 orchid219_classification 程式碼\n",
        "--- "
      ],
      "metadata": {
        "id": "NhO8MiJ41HLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://gary109:Gygy844109109@gitlab.com/gary109/orchid219_classification.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfPGSNnqqdLE",
        "outputId": "4346bcf5-effc-4882-f366-f3109d2f7e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'orchid219_classification'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 16 (delta 4), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 載入 orchid219 訓練資料集\n",
        "---"
      ],
      "metadata": {
        "id": "RcO8DSXZz7W5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"./orchid219_classification/datasets/orchid219.py\", use_auth_token=True)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "21e29e71a14849a590345644bbe77c12",
            "92ca2a9769f64f7d9136941126af9de5",
            "e9836e9361b24fa499d9dbfdf167d62c",
            "e735b6e2d50b4ff0bc9e068ec9f8b281",
            "791a6d92ba8a4184ae7de36623cdce0b",
            "80b448779bc84556897d5fe1f3085a58",
            "9b7c67bb6af14a97bbabab0d3d85b4ba",
            "84ed12e3496347b4a0474eb5272ca6b4",
            "6772501c9cc342e099402c6a54abd2b2",
            "212f4978f88245a58cf5295cf98ebce9",
            "77515809ffcb4a3e93c3bbee6ff00293",
            "65b2bddcc6f54aaaac41ec3f571a1256",
            "78854db8781d4c5d803be185dde1add6",
            "59b10a26b44a41018bca1501e843c67b",
            "b2c6dd13978f433cbcbf80d181b1ab71",
            "09af7a2b26e74cefb6710271618e4afe",
            "52fec1ebe01148dbb021e10f09604b30",
            "a9721625069e47d8ab353789dc0ad271",
            "181175ee577d43adb97ff38ae124b45b",
            "9da2f2471d54430585f79edd12ff8b9d",
            "411c2cb2d273499ea12aa4359f94a0ff",
            "34d6eb1c9bd347969b70d0b44c903005",
            "aa52d499b79342d6b55b1d347f93b377",
            "a68c652fa64e47f496b51d302f993a65",
            "b1f6d853fd1f4599b76e612b20564bd1",
            "85f547c8b558450085ab8d4cf3f7fea6",
            "583cecceec114c61bb852a78fc85ba3f",
            "3acb0a6652904fe18bef56e26b72c1f3",
            "2be77b553bd045bf9889f6a9ca470c0e",
            "dd35a450779d402e9156a90087d40d60",
            "108f9f7e212a4aac8d1956228f492333",
            "c724687aaef04034a48df3e389194a1d",
            "768e988bb8934475850cdf12e31314db",
            "cd522ecafef04c05abdcd3eaf58b99ee",
            "23b4a6b3cddf43eaa572b8119d7f7054",
            "6e3b05e8aa7b436bad215df0f6a61314",
            "100422bb34f446ecb657fffd52a9f2b7",
            "8de92688689145b39b05e2a125cae85f",
            "45a3002bfeb047a8b5f6a0f7670bff5a",
            "5b1a3e5b4ec44a648a52d7642c0a8cee",
            "47255aecde6545b5a1c7dc73f4dd9c8c",
            "8f1d942292864a5b9c9fd153b06c23eb",
            "73ecb91dc75e4fb1a0204d58279b1d56",
            "b11bcb507c384d7f8a43549c5481221c"
          ]
        },
        "outputId": "387bde46-099d-4f9a-cad0-2283e758a115",
        "id": "U_idZeBF2zie"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset crop14/crop14-small to /root/.cache/huggingface/datasets/crop14/crop14-small/0.0.3/84d7648f2ea0b147531986b7c0c46914c93dc9da31daac0a5ec3c57590c4e99a...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/2.92G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21e29e71a14849a590345644bbe77c12"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65b2bddcc6f54aaaac41ec3f571a1256"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa52d499b79342d6b55b1d347f93b377"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset crop14 downloaded and prepared to /root/.cache/huggingface/datasets/crop14/crop14-small/0.0.3/84d7648f2ea0b147531986b7c0c46914c93dc9da31daac0a5ec3c57590c4e99a. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd522ecafef04c05abdcd3eaf58b99ee"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.utils.dummy_vision_objects import ImageGPTFeatureExtractor\n",
        "import random\n",
        "from PIL import ImageDraw, ImageFont, Image\n",
        "\n",
        "def show_examples(ds, seed: int = 1234, examples_per_class: int = 3, size=(100, 100)):\n",
        "\n",
        "    w, h = size\n",
        "    labels = ds['train'].features['category'].names\n",
        "    labels = labels[:9]\n",
        "    grid = Image.new('RGB', size=(examples_per_class * w, len(labels) * h))\n",
        "    draw = ImageDraw.Draw(grid)\n",
        "    font = ImageFont.truetype(\"./fonts/LiberationMono-Bold.ttf\", 24)\n",
        "    for label_id, label in enumerate(labels):\n",
        "\n",
        "        # Filter the dataset by a single label, shuffle it, and grab a few samples\n",
        "        ds_slice = ds['train'].filter(lambda ex: ex['category'] == label_id).shuffle(seed).select(range(examples_per_class))\n",
        "\n",
        "        # Plot this label's examples along a row\n",
        "        for i, example in enumerate(ds_slice):\n",
        "            image = example['image']\n",
        "            idx = examples_per_class * label_id + i\n",
        "            box = (idx % examples_per_class * w, idx // examples_per_class * h)\n",
        "            grid.paste(image.resize(size), box=box)\n",
        "            draw.text(box, str(label), (255, 255, 255), font=font)\n",
        "\n",
        "    return grid\n",
        "\n",
        "show_examples(dataset, seed=random.randint(0, 1337), examples_per_class=3)\n",
        "# dataset['train'][0]['image']"
      ],
      "metadata": {
        "id": "7iNPEbNz2zie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.push_to_hub(\"gary109/orchid219\")"
      ],
      "metadata": {
        "id": "1gymd4g12zif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 開始訓練\n",
        "---"
      ],
      "metadata": {
        "id": "GBQ4LLFm2CJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/transformers/examples/pytorch/image-classification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E5Kms3u0Gx6",
        "outputId": "05be04f6-8c1c-42f3-f9bd-5fe16db3cddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/transformers/examples/pytorch/image-classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## google/vit-base-patch16-224-in21k\n",
        "---"
      ],
      "metadata": {
        "id": "MzvQ9zfD34bE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! accelerate launch run_image_classification.py \\\n",
        "    --dataset_name \"orchid219\" \\\n",
        "    --output_dir ./orchid219_vit-base-patch16-224-in21k/ \\\n",
        "    --remove_unused_columns False \\\n",
        "    --overwrite_output_dir \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --push_to_hub \\\n",
        "    --push_to_hub_model_id orchid219_vit-base-patch16-224-in21k \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --num_train_epochs 20 \\\n",
        "    --per_device_train_batch_size 80 \\\n",
        "    --per_device_eval_batch_size 16 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --evaluation_strategy epoch \\\n",
        "    --save_strategy epoch \\\n",
        "    --load_best_model_at_end True \\\n",
        "    --save_total_limit 3 \\\n",
        "    --use_auth_token \\\n",
        "    --seed 1337\n",
        "    # --gradient_accumulation_steps 8 \\\n",
        "    # --gradient_checkpointing"
      ],
      "metadata": {
        "id": "tNMZWv7q0G02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## google/vit-base-patch32-224-in21k\n",
        "---"
      ],
      "metadata": {
        "id": "p9t54nRI4B5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! accelerate launch run_image_classification.py \\\n",
        "    --dataset_name \"orchid219\" \\\n",
        "    --model_name_or_path \"google/vit-base-patch32-224-in21k\" \\\n",
        "    --output_dir ./orchid219_vit-base-patch32-224-in21k/ \\\n",
        "    --remove_unused_columns False \\\n",
        "    --overwrite_output_dir \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --push_to_hub \\\n",
        "    --push_to_hub_model_id orchid219_vit-base-patch32-224-in21k \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --num_train_epochs 20 \\\n",
        "    --per_device_train_batch_size 80 \\\n",
        "    --per_device_eval_batch_size 16 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --evaluation_strategy epoch \\\n",
        "    --save_strategy epoch \\\n",
        "    --load_best_model_at_end True \\\n",
        "    --save_total_limit 3 \\\n",
        "    --use_auth_token \\\n",
        "    --seed 1337\n",
        "    # --gradient_accumulation_steps 8 \\\n",
        "    # --gradient_checkpointing"
      ],
      "metadata": {
        "id": "XTWxM4p30G3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## google/vit-large-patch16-224-in21k\n",
        "---"
      ],
      "metadata": {
        "id": "NNvuAbjI4PWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! accelerate launch run_image_classification.py \\\n",
        "    --dataset_name \"orchid219\" \\\n",
        "    --model_name_or_path \"google/vit-large-patch16-224-in21k\" \\\n",
        "    --output_dir \"./orchid219_vit-large-patch16-224-in21k\" \\\n",
        "    --remove_unused_columns False \\\n",
        "    --overwrite_output_dir \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --push_to_hub \\\n",
        "    --push_to_hub_model_id \"orchid219_vit-large-patch16-224-in21k\" \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --num_train_epochs 20 \\\n",
        "    --per_device_train_batch_size 16 \\\n",
        "    --per_device_eval_batch_size 16 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --evaluation_strategy epoch \\\n",
        "    --save_strategy epoch \\\n",
        "    --load_best_model_at_end True \\\n",
        "    --save_total_limit 3 \\\n",
        "    --use_auth_token \\\n",
        "    --seed 1337\n",
        "    # --gradient_accumulation_steps 8 \\\n",
        "    # --gradient_checkpointing"
      ],
      "metadata": {
        "id": "Xo5w2JgH0G6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## google/vit-large-patch32-224-in21k\n",
        "---"
      ],
      "metadata": {
        "id": "WJsYvA7u4dLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! accelerate launch run_image_classification.py \\\n",
        "    --dataset_name \"gary109/orchid219\" \\\n",
        "    --model_name_or_path \"google/vit-large-patch32-224-in21k\" \\\n",
        "    --output_dir \"./orchid219_vit-large-patch32-224-in21k\" \\\n",
        "    --remove_unused_columns False \\\n",
        "    --overwrite_output_dir \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --push_to_hub \\\n",
        "    --push_to_hub_model_id \"orchid219_vit-large-patch32-224-in21k\" \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --num_train_epochs 20 \\\n",
        "    --per_device_train_batch_size 16 \\\n",
        "    --per_device_eval_batch_size 16 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 10 \\\n",
        "    --evaluation_strategy epoch \\\n",
        "    --save_strategy epoch \\\n",
        "    --load_best_model_at_end True \\\n",
        "    --save_total_limit 1 \\\n",
        "    --use_auth_token \\\n",
        "    --seed 1337\n",
        "    # --gradient_accumulation_steps 8 \\\n",
        "    # --gradient_checkpointing"
      ],
      "metadata": {
        "id": "c13vuvEg4dlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## google/vit-huge-patch14-224-in21k\n",
        "---"
      ],
      "metadata": {
        "id": "qaNA2JF34UPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! accelerate launch run_image_classification.py \\\n",
        "    --dataset_name \"gary109/orchid219\" \\\n",
        "    --model_name_or_path \"google/vit-huge-patch14-224-in21k\" \\\n",
        "    --output_dir \"./orchid219_vit-huge-patch14-224-in21k\" \\\n",
        "    --remove_unused_columns False \\\n",
        "    --overwrite_output_dir \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --push_to_hub \\\n",
        "    --push_to_hub_model_id \"orchid219_vit-huge-patch14-224-in21k\" \\\n",
        "    --learning_rate 2e-5 \\\n",
        "    --num_train_epochs 20 \\\n",
        "    --per_device_train_batch_size 4 \\\n",
        "    --per_device_eval_batch_size 4 \\\n",
        "    --logging_strategy steps \\\n",
        "    --logging_steps 5 \\\n",
        "    --evaluation_strategy epoch \\\n",
        "    --save_strategy epoch \\\n",
        "    --load_best_model_at_end True \\\n",
        "    --save_total_limit 1 \\\n",
        "    --use_auth_token \\\n",
        "    --seed 1337 \\\n",
        "    --gradient_accumulation_steps 8 \\\n",
        "    --gradient_checkpointing"
      ],
      "metadata": {
        "id": "Gd5cMkQ9kBjI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "957bfed6-9970-4699-87ba-d113d0da1cd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/training_args.py:978: FutureWarning: `--push_to_hub_model_id` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_model_id` instead and pass the full repo name to this argument (in this case gary109/orchid219_vit-huge-patch14-224-in21k).\n",
            "  FutureWarning,\n",
            "04/28/2022 00:28:35 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "04/28/2022 00:28:35 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.EPOCH,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=8,\n",
            "gradient_checkpointing=True,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=gary109/orchid219_vit-huge-patch14-224-in21k,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=./orchid219_vit-huge-patch14-224-in21k/runs/Apr28_00-28-34_680580e82b1e,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=5,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=20.0,\n",
            "optim=OptimizerNames.ADAMW_HF,\n",
            "output_dir=./orchid219_vit-huge-patch14-224-in21k,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=4,\n",
            "per_device_train_batch_size=4,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=True,\n",
            "push_to_hub_model_id=orchid219_vit-huge-patch14-224-in21k,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "remove_unused_columns=False,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=./orchid219_vit-huge-patch14-224-in21k,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=IntervalStrategy.EPOCH,\n",
            "save_total_limit=1,\n",
            "seed=1337,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "04/28/2022 00:28:38 - WARNING - datasets.builder - Using custom data configuration gary109--orchid219-53e55d447bfb4b23\n",
            "04/28/2022 00:28:38 - WARNING - datasets.builder - Reusing dataset parquet (/root/.cache/huggingface/datasets/parquet/gary109--orchid219-53e55d447bfb4b23/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n",
            "100% 2/2 [00:00<00:00, 84.59it/s]\n",
            "04/28/2022 00:28:39 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/parquet/gary109--orchid219-53e55d447bfb4b23/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-7390eeefe5a21145.arrow\n",
            "04/28/2022 00:28:39 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/parquet/gary109--orchid219-53e55d447bfb4b23/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-a589d500576625c6.arrow\n",
            "[INFO|configuration_utils.py:659] 2022-04-28 00:28:40,869 >> loading configuration file https://huggingface.co/google/vit-huge-patch14-224-in21k/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/8ade236f30a7feb4a8dba30a453548d0570e96d6544bfee36b460db42557c7c1.4421305ebaffc3e34437ab7e4244ddb07cf9cab530b37fa79b40117d724755cb\n",
            "[INFO|configuration_utils.py:704] 2022-04-28 00:28:40,871 >> Model config ViTConfig {\n",
            "  \"_name_or_path\": \"google/vit-huge-patch14-224-in21k\",\n",
            "  \"architectures\": [\n",
            "    \"ViTModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"encoder_stride\": 16,\n",
            "  \"finetuning_task\": \"image-classification\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 1280,\n",
            "  \"id2label\": {\n",
            "    \"0\": 0,\n",
            "    \"1\": 1,\n",
            "    \"10\": 10,\n",
            "    \"100\": 100,\n",
            "    \"101\": 101,\n",
            "    \"102\": 102,\n",
            "    \"103\": 103,\n",
            "    \"104\": 104,\n",
            "    \"105\": 105,\n",
            "    \"106\": 106,\n",
            "    \"107\": 107,\n",
            "    \"108\": 108,\n",
            "    \"109\": 109,\n",
            "    \"11\": 11,\n",
            "    \"110\": 110,\n",
            "    \"111\": 111,\n",
            "    \"112\": 112,\n",
            "    \"113\": 113,\n",
            "    \"114\": 114,\n",
            "    \"115\": 115,\n",
            "    \"116\": 116,\n",
            "    \"117\": 117,\n",
            "    \"118\": 118,\n",
            "    \"119\": 119,\n",
            "    \"12\": 12,\n",
            "    \"120\": 120,\n",
            "    \"121\": 121,\n",
            "    \"122\": 122,\n",
            "    \"123\": 123,\n",
            "    \"124\": 124,\n",
            "    \"125\": 125,\n",
            "    \"126\": 126,\n",
            "    \"127\": 127,\n",
            "    \"128\": 128,\n",
            "    \"129\": 129,\n",
            "    \"13\": 13,\n",
            "    \"130\": 130,\n",
            "    \"131\": 131,\n",
            "    \"132\": 132,\n",
            "    \"133\": 133,\n",
            "    \"134\": 134,\n",
            "    \"135\": 135,\n",
            "    \"136\": 136,\n",
            "    \"137\": 137,\n",
            "    \"138\": 138,\n",
            "    \"139\": 139,\n",
            "    \"14\": 14,\n",
            "    \"140\": 140,\n",
            "    \"141\": 141,\n",
            "    \"142\": 142,\n",
            "    \"143\": 143,\n",
            "    \"144\": 144,\n",
            "    \"145\": 145,\n",
            "    \"146\": 146,\n",
            "    \"147\": 147,\n",
            "    \"148\": 148,\n",
            "    \"149\": 149,\n",
            "    \"15\": 15,\n",
            "    \"150\": 150,\n",
            "    \"151\": 151,\n",
            "    \"152\": 152,\n",
            "    \"153\": 153,\n",
            "    \"154\": 154,\n",
            "    \"155\": 155,\n",
            "    \"156\": 156,\n",
            "    \"157\": 157,\n",
            "    \"158\": 158,\n",
            "    \"159\": 159,\n",
            "    \"16\": 16,\n",
            "    \"160\": 160,\n",
            "    \"161\": 161,\n",
            "    \"162\": 162,\n",
            "    \"163\": 163,\n",
            "    \"164\": 164,\n",
            "    \"165\": 165,\n",
            "    \"166\": 166,\n",
            "    \"167\": 167,\n",
            "    \"168\": 168,\n",
            "    \"169\": 169,\n",
            "    \"17\": 17,\n",
            "    \"170\": 170,\n",
            "    \"171\": 171,\n",
            "    \"172\": 172,\n",
            "    \"173\": 173,\n",
            "    \"174\": 174,\n",
            "    \"175\": 175,\n",
            "    \"176\": 176,\n",
            "    \"177\": 177,\n",
            "    \"178\": 178,\n",
            "    \"179\": 179,\n",
            "    \"18\": 18,\n",
            "    \"180\": 180,\n",
            "    \"181\": 181,\n",
            "    \"182\": 182,\n",
            "    \"183\": 183,\n",
            "    \"184\": 184,\n",
            "    \"185\": 185,\n",
            "    \"186\": 186,\n",
            "    \"187\": 187,\n",
            "    \"188\": 188,\n",
            "    \"189\": 189,\n",
            "    \"19\": 19,\n",
            "    \"190\": 190,\n",
            "    \"191\": 191,\n",
            "    \"192\": 192,\n",
            "    \"193\": 193,\n",
            "    \"194\": 194,\n",
            "    \"195\": 195,\n",
            "    \"196\": 196,\n",
            "    \"197\": 197,\n",
            "    \"198\": 198,\n",
            "    \"199\": 199,\n",
            "    \"2\": 2,\n",
            "    \"20\": 20,\n",
            "    \"200\": 200,\n",
            "    \"201\": 201,\n",
            "    \"202\": 202,\n",
            "    \"203\": 203,\n",
            "    \"204\": 204,\n",
            "    \"205\": 205,\n",
            "    \"206\": 206,\n",
            "    \"207\": 207,\n",
            "    \"208\": 208,\n",
            "    \"209\": 209,\n",
            "    \"21\": 21,\n",
            "    \"210\": 210,\n",
            "    \"211\": 211,\n",
            "    \"212\": 212,\n",
            "    \"213\": 213,\n",
            "    \"214\": 214,\n",
            "    \"215\": 215,\n",
            "    \"216\": 216,\n",
            "    \"217\": 217,\n",
            "    \"218\": 218,\n",
            "    \"22\": 22,\n",
            "    \"23\": 23,\n",
            "    \"24\": 24,\n",
            "    \"25\": 25,\n",
            "    \"26\": 26,\n",
            "    \"27\": 27,\n",
            "    \"28\": 28,\n",
            "    \"29\": 29,\n",
            "    \"3\": 3,\n",
            "    \"30\": 30,\n",
            "    \"31\": 31,\n",
            "    \"32\": 32,\n",
            "    \"33\": 33,\n",
            "    \"34\": 34,\n",
            "    \"35\": 35,\n",
            "    \"36\": 36,\n",
            "    \"37\": 37,\n",
            "    \"38\": 38,\n",
            "    \"39\": 39,\n",
            "    \"4\": 4,\n",
            "    \"40\": 40,\n",
            "    \"41\": 41,\n",
            "    \"42\": 42,\n",
            "    \"43\": 43,\n",
            "    \"44\": 44,\n",
            "    \"45\": 45,\n",
            "    \"46\": 46,\n",
            "    \"47\": 47,\n",
            "    \"48\": 48,\n",
            "    \"49\": 49,\n",
            "    \"5\": 5,\n",
            "    \"50\": 50,\n",
            "    \"51\": 51,\n",
            "    \"52\": 52,\n",
            "    \"53\": 53,\n",
            "    \"54\": 54,\n",
            "    \"55\": 55,\n",
            "    \"56\": 56,\n",
            "    \"57\": 57,\n",
            "    \"58\": 58,\n",
            "    \"59\": 59,\n",
            "    \"6\": 6,\n",
            "    \"60\": 60,\n",
            "    \"61\": 61,\n",
            "    \"62\": 62,\n",
            "    \"63\": 63,\n",
            "    \"64\": 64,\n",
            "    \"65\": 65,\n",
            "    \"66\": 66,\n",
            "    \"67\": 67,\n",
            "    \"68\": 68,\n",
            "    \"69\": 69,\n",
            "    \"7\": 7,\n",
            "    \"70\": 70,\n",
            "    \"71\": 71,\n",
            "    \"72\": 72,\n",
            "    \"73\": 73,\n",
            "    \"74\": 74,\n",
            "    \"75\": 75,\n",
            "    \"76\": 76,\n",
            "    \"77\": 77,\n",
            "    \"78\": 78,\n",
            "    \"79\": 79,\n",
            "    \"8\": 8,\n",
            "    \"80\": 80,\n",
            "    \"81\": 81,\n",
            "    \"82\": 82,\n",
            "    \"83\": 83,\n",
            "    \"84\": 84,\n",
            "    \"85\": 85,\n",
            "    \"86\": 86,\n",
            "    \"87\": 87,\n",
            "    \"88\": 88,\n",
            "    \"89\": 89,\n",
            "    \"9\": 9,\n",
            "    \"90\": 90,\n",
            "    \"91\": 91,\n",
            "    \"92\": 92,\n",
            "    \"93\": 93,\n",
            "    \"94\": 94,\n",
            "    \"95\": 95,\n",
            "    \"96\": 96,\n",
            "    \"97\": 97,\n",
            "    \"98\": 98,\n",
            "    \"99\": 99\n",
            "  },\n",
            "  \"image_size\": 224,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 5120,\n",
            "  \"label2id\": {\n",
            "    \"0\": \"0\",\n",
            "    \"1\": \"1\",\n",
            "    \"2\": \"2\",\n",
            "    \"3\": \"3\",\n",
            "    \"4\": \"4\",\n",
            "    \"5\": \"5\",\n",
            "    \"6\": \"6\",\n",
            "    \"7\": \"7\",\n",
            "    \"8\": \"8\",\n",
            "    \"9\": \"9\",\n",
            "    \"10\": \"10\",\n",
            "    \"11\": \"11\",\n",
            "    \"12\": \"12\",\n",
            "    \"13\": \"13\",\n",
            "    \"14\": \"14\",\n",
            "    \"15\": \"15\",\n",
            "    \"16\": \"16\",\n",
            "    \"17\": \"17\",\n",
            "    \"18\": \"18\",\n",
            "    \"19\": \"19\",\n",
            "    \"20\": \"20\",\n",
            "    \"21\": \"21\",\n",
            "    \"22\": \"22\",\n",
            "    \"23\": \"23\",\n",
            "    \"24\": \"24\",\n",
            "    \"25\": \"25\",\n",
            "    \"26\": \"26\",\n",
            "    \"27\": \"27\",\n",
            "    \"28\": \"28\",\n",
            "    \"29\": \"29\",\n",
            "    \"30\": \"30\",\n",
            "    \"31\": \"31\",\n",
            "    \"32\": \"32\",\n",
            "    \"33\": \"33\",\n",
            "    \"34\": \"34\",\n",
            "    \"35\": \"35\",\n",
            "    \"36\": \"36\",\n",
            "    \"37\": \"37\",\n",
            "    \"38\": \"38\",\n",
            "    \"39\": \"39\",\n",
            "    \"40\": \"40\",\n",
            "    \"41\": \"41\",\n",
            "    \"42\": \"42\",\n",
            "    \"43\": \"43\",\n",
            "    \"44\": \"44\",\n",
            "    \"45\": \"45\",\n",
            "    \"46\": \"46\",\n",
            "    \"47\": \"47\",\n",
            "    \"48\": \"48\",\n",
            "    \"49\": \"49\",\n",
            "    \"50\": \"50\",\n",
            "    \"51\": \"51\",\n",
            "    \"52\": \"52\",\n",
            "    \"53\": \"53\",\n",
            "    \"54\": \"54\",\n",
            "    \"55\": \"55\",\n",
            "    \"56\": \"56\",\n",
            "    \"57\": \"57\",\n",
            "    \"58\": \"58\",\n",
            "    \"59\": \"59\",\n",
            "    \"60\": \"60\",\n",
            "    \"61\": \"61\",\n",
            "    \"62\": \"62\",\n",
            "    \"63\": \"63\",\n",
            "    \"64\": \"64\",\n",
            "    \"65\": \"65\",\n",
            "    \"66\": \"66\",\n",
            "    \"67\": \"67\",\n",
            "    \"68\": \"68\",\n",
            "    \"69\": \"69\",\n",
            "    \"70\": \"70\",\n",
            "    \"71\": \"71\",\n",
            "    \"72\": \"72\",\n",
            "    \"73\": \"73\",\n",
            "    \"74\": \"74\",\n",
            "    \"75\": \"75\",\n",
            "    \"76\": \"76\",\n",
            "    \"77\": \"77\",\n",
            "    \"78\": \"78\",\n",
            "    \"79\": \"79\",\n",
            "    \"80\": \"80\",\n",
            "    \"81\": \"81\",\n",
            "    \"82\": \"82\",\n",
            "    \"83\": \"83\",\n",
            "    \"84\": \"84\",\n",
            "    \"85\": \"85\",\n",
            "    \"86\": \"86\",\n",
            "    \"87\": \"87\",\n",
            "    \"88\": \"88\",\n",
            "    \"89\": \"89\",\n",
            "    \"90\": \"90\",\n",
            "    \"91\": \"91\",\n",
            "    \"92\": \"92\",\n",
            "    \"93\": \"93\",\n",
            "    \"94\": \"94\",\n",
            "    \"95\": \"95\",\n",
            "    \"96\": \"96\",\n",
            "    \"97\": \"97\",\n",
            "    \"98\": \"98\",\n",
            "    \"99\": \"99\",\n",
            "    \"100\": \"100\",\n",
            "    \"101\": \"101\",\n",
            "    \"102\": \"102\",\n",
            "    \"103\": \"103\",\n",
            "    \"104\": \"104\",\n",
            "    \"105\": \"105\",\n",
            "    \"106\": \"106\",\n",
            "    \"107\": \"107\",\n",
            "    \"108\": \"108\",\n",
            "    \"109\": \"109\",\n",
            "    \"110\": \"110\",\n",
            "    \"111\": \"111\",\n",
            "    \"112\": \"112\",\n",
            "    \"113\": \"113\",\n",
            "    \"114\": \"114\",\n",
            "    \"115\": \"115\",\n",
            "    \"116\": \"116\",\n",
            "    \"117\": \"117\",\n",
            "    \"118\": \"118\",\n",
            "    \"119\": \"119\",\n",
            "    \"120\": \"120\",\n",
            "    \"121\": \"121\",\n",
            "    \"122\": \"122\",\n",
            "    \"123\": \"123\",\n",
            "    \"124\": \"124\",\n",
            "    \"125\": \"125\",\n",
            "    \"126\": \"126\",\n",
            "    \"127\": \"127\",\n",
            "    \"128\": \"128\",\n",
            "    \"129\": \"129\",\n",
            "    \"130\": \"130\",\n",
            "    \"131\": \"131\",\n",
            "    \"132\": \"132\",\n",
            "    \"133\": \"133\",\n",
            "    \"134\": \"134\",\n",
            "    \"135\": \"135\",\n",
            "    \"136\": \"136\",\n",
            "    \"137\": \"137\",\n",
            "    \"138\": \"138\",\n",
            "    \"139\": \"139\",\n",
            "    \"140\": \"140\",\n",
            "    \"141\": \"141\",\n",
            "    \"142\": \"142\",\n",
            "    \"143\": \"143\",\n",
            "    \"144\": \"144\",\n",
            "    \"145\": \"145\",\n",
            "    \"146\": \"146\",\n",
            "    \"147\": \"147\",\n",
            "    \"148\": \"148\",\n",
            "    \"149\": \"149\",\n",
            "    \"150\": \"150\",\n",
            "    \"151\": \"151\",\n",
            "    \"152\": \"152\",\n",
            "    \"153\": \"153\",\n",
            "    \"154\": \"154\",\n",
            "    \"155\": \"155\",\n",
            "    \"156\": \"156\",\n",
            "    \"157\": \"157\",\n",
            "    \"158\": \"158\",\n",
            "    \"159\": \"159\",\n",
            "    \"160\": \"160\",\n",
            "    \"161\": \"161\",\n",
            "    \"162\": \"162\",\n",
            "    \"163\": \"163\",\n",
            "    \"164\": \"164\",\n",
            "    \"165\": \"165\",\n",
            "    \"166\": \"166\",\n",
            "    \"167\": \"167\",\n",
            "    \"168\": \"168\",\n",
            "    \"169\": \"169\",\n",
            "    \"170\": \"170\",\n",
            "    \"171\": \"171\",\n",
            "    \"172\": \"172\",\n",
            "    \"173\": \"173\",\n",
            "    \"174\": \"174\",\n",
            "    \"175\": \"175\",\n",
            "    \"176\": \"176\",\n",
            "    \"177\": \"177\",\n",
            "    \"178\": \"178\",\n",
            "    \"179\": \"179\",\n",
            "    \"180\": \"180\",\n",
            "    \"181\": \"181\",\n",
            "    \"182\": \"182\",\n",
            "    \"183\": \"183\",\n",
            "    \"184\": \"184\",\n",
            "    \"185\": \"185\",\n",
            "    \"186\": \"186\",\n",
            "    \"187\": \"187\",\n",
            "    \"188\": \"188\",\n",
            "    \"189\": \"189\",\n",
            "    \"190\": \"190\",\n",
            "    \"191\": \"191\",\n",
            "    \"192\": \"192\",\n",
            "    \"193\": \"193\",\n",
            "    \"194\": \"194\",\n",
            "    \"195\": \"195\",\n",
            "    \"196\": \"196\",\n",
            "    \"197\": \"197\",\n",
            "    \"198\": \"198\",\n",
            "    \"199\": \"199\",\n",
            "    \"200\": \"200\",\n",
            "    \"201\": \"201\",\n",
            "    \"202\": \"202\",\n",
            "    \"203\": \"203\",\n",
            "    \"204\": \"204\",\n",
            "    \"205\": \"205\",\n",
            "    \"206\": \"206\",\n",
            "    \"207\": \"207\",\n",
            "    \"208\": \"208\",\n",
            "    \"209\": \"209\",\n",
            "    \"210\": \"210\",\n",
            "    \"211\": \"211\",\n",
            "    \"212\": \"212\",\n",
            "    \"213\": \"213\",\n",
            "    \"214\": \"214\",\n",
            "    \"215\": \"215\",\n",
            "    \"216\": \"216\",\n",
            "    \"217\": \"217\",\n",
            "    \"218\": \"218\"\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"model_type\": \"vit\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_channels\": 3,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"patch_size\": 14,\n",
            "  \"qkv_bias\": true,\n",
            "  \"transformers_version\": \"4.19.0.dev0\"\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:1879] 2022-04-28 00:28:41,785 >> loading weights file https://huggingface.co/google/vit-huge-patch14-224-in21k/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/0e1d87a339ae8bdffce2108071c66b5a0db276a5dc294fe5d123fed1473d7c1e.6e61a750a3a5b1ac7b5a9f5cf2edc3506e1218bc898b57eae7e3c45c6429357b\n",
            "[WARNING|modeling_utils.py:2181] 2022-04-28 00:28:56,742 >> Some weights of the model checkpoint at google/vit-huge-patch14-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:2192] 2022-04-28 00:28:56,742 >> Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-huge-patch14-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[INFO|feature_extraction_utils.py:465] 2022-04-28 00:28:57,662 >> loading feature extractor configuration file https://huggingface.co/google/vit-huge-patch14-224-in21k/resolve/main/preprocessor_config.json from cache at /root/.cache/huggingface/transformers/ffb3ab81931c92867adb522fc01b459b501bc18f909584a14b11ba76194a2f8d.c322cbf30b69973d5aae6c0866f5cba198b5fe51a2fe259d2a506827ec6274bc\n",
            "[INFO|configuration_utils.py:659] 2022-04-28 00:28:58,556 >> loading configuration file https://huggingface.co/google/vit-huge-patch14-224-in21k/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/8ade236f30a7feb4a8dba30a453548d0570e96d6544bfee36b460db42557c7c1.4421305ebaffc3e34437ab7e4244ddb07cf9cab530b37fa79b40117d724755cb\n",
            "[INFO|configuration_utils.py:704] 2022-04-28 00:28:58,557 >> Model config ViTConfig {\n",
            "  \"_name_or_path\": \"google/vit-huge-patch14-224-in21k\",\n",
            "  \"architectures\": [\n",
            "    \"ViTModel\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"encoder_stride\": 16,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 1280,\n",
            "  \"image_size\": 224,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 5120,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"model_type\": \"vit\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_channels\": 3,\n",
            "  \"num_hidden_layers\": 32,\n",
            "  \"patch_size\": 14,\n",
            "  \"qkv_bias\": true,\n",
            "  \"transformers_version\": \"4.19.0.dev0\"\n",
            "}\n",
            "\n",
            "[INFO|feature_extraction_utils.py:501] 2022-04-28 00:28:58,560 >> Feature extractor ViTFeatureExtractor {\n",
            "  \"do_normalize\": true,\n",
            "  \"do_resize\": true,\n",
            "  \"feature_extractor_type\": \"ViTFeatureExtractor\",\n",
            "  \"image_mean\": [\n",
            "    0.5,\n",
            "    0.5,\n",
            "    0.5\n",
            "  ],\n",
            "  \"image_std\": [\n",
            "    0.5,\n",
            "    0.5,\n",
            "    0.5\n",
            "  ],\n",
            "  \"resample\": 2,\n",
            "  \"size\": 224\n",
            "}\n",
            "\n",
            "/content/transformers/examples/pytorch/image-classification/./orchid219_vit-huge-patch14-224-in21k is already a clone of https://huggingface.co/gary109/orchid219_vit-huge-patch14-224-in21k. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "04/28/2022 00:29:11 - WARNING - huggingface_hub.repository - /content/transformers/examples/pytorch/image-classification/./orchid219_vit-huge-patch14-224-in21k is already a clone of https://huggingface.co/gary109/orchid219_vit-huge-patch14-224-in21k. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "[INFO|trainer.py:1317] 2022-04-28 00:29:15,124 >> ***** Running training *****\n",
            "[INFO|trainer.py:1318] 2022-04-28 00:29:15,125 >>   Num examples = 1971\n",
            "[INFO|trainer.py:1319] 2022-04-28 00:29:15,125 >>   Num Epochs = 20\n",
            "[INFO|trainer.py:1320] 2022-04-28 00:29:15,125 >>   Instantaneous batch size per device = 4\n",
            "[INFO|trainer.py:1321] 2022-04-28 00:29:15,125 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "[INFO|trainer.py:1322] 2022-04-28 00:29:15,125 >>   Gradient Accumulation steps = 8\n",
            "[INFO|trainer.py:1323] 2022-04-28 00:29:15,125 >>   Total optimization steps = 1220\n",
            "{'loss': 5.3902, 'learning_rate': 1.991803278688525e-05, 'epoch': 0.08}\n",
            "{'loss': 5.3844, 'learning_rate': 1.9836065573770492e-05, 'epoch': 0.16}\n",
            "{'loss': 5.3827, 'learning_rate': 1.975409836065574e-05, 'epoch': 0.24}\n",
            "{'loss': 5.3811, 'learning_rate': 1.9672131147540985e-05, 'epoch': 0.32}\n",
            "{'loss': 5.3702, 'learning_rate': 1.9590163934426232e-05, 'epoch': 0.41}\n",
            "{'loss': 5.3744, 'learning_rate': 1.9508196721311475e-05, 'epoch': 0.49}\n",
            "{'loss': 5.361, 'learning_rate': 1.9426229508196722e-05, 'epoch': 0.57}\n",
            "{'loss': 5.36, 'learning_rate': 1.934426229508197e-05, 'epoch': 0.65}\n",
            "{'loss': 5.361, 'learning_rate': 1.9262295081967216e-05, 'epoch': 0.73}\n",
            "{'loss': 5.3412, 'learning_rate': 1.918032786885246e-05, 'epoch': 0.81}\n",
            "{'loss': 5.3358, 'learning_rate': 1.9098360655737706e-05, 'epoch': 0.89}\n",
            "{'loss': 5.3356, 'learning_rate': 1.9016393442622952e-05, 'epoch': 0.97}\n",
            "  5% 61/1220 [15:02<4:51:43, 15.10s/it][INFO|trainer.py:2443] 2022-04-28 00:44:26,149 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2445] 2022-04-28 00:44:26,149 >>   Num examples = 219\n",
            "[INFO|trainer.py:2448] 2022-04-28 00:44:26,149 >>   Batch size = 4\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:14,  3.74it/s]\u001b[A\n",
            "  5% 3/55 [00:01<00:19,  2.66it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:22,  2.30it/s]\u001b[A\n",
            "  9% 5/55 [00:02<00:23,  2.15it/s]\u001b[A\n",
            " 11% 6/55 [00:02<00:24,  2.04it/s]\u001b[A\n",
            " 13% 7/55 [00:03<00:23,  2.00it/s]\u001b[A\n",
            " 15% 8/55 [00:03<00:24,  1.95it/s]\u001b[A\n",
            " 16% 9/55 [00:04<00:23,  1.94it/s]\u001b[A\n",
            " 18% 10/55 [00:04<00:23,  1.91it/s]\u001b[A\n",
            " 20% 11/55 [00:05<00:23,  1.91it/s]\u001b[A\n",
            " 22% 12/55 [00:05<00:22,  1.90it/s]\u001b[A\n",
            " 24% 13/55 [00:06<00:22,  1.90it/s]\u001b[A\n",
            " 25% 14/55 [00:06<00:21,  1.89it/s]\u001b[A\n",
            " 27% 15/55 [00:07<00:21,  1.89it/s]\u001b[A\n",
            " 29% 16/55 [00:07<00:20,  1.89it/s]\u001b[A\n",
            " 31% 17/55 [00:08<00:20,  1.89it/s]\u001b[A\n",
            " 33% 18/55 [00:09<00:19,  1.88it/s]\u001b[A\n",
            " 35% 19/55 [00:09<00:19,  1.89it/s]\u001b[A\n",
            " 36% 20/55 [00:10<00:18,  1.88it/s]\u001b[A\n",
            " 38% 21/55 [00:10<00:18,  1.88it/s]\u001b[A\n",
            " 40% 22/55 [00:11<00:17,  1.88it/s]\u001b[A\n",
            " 42% 23/55 [00:11<00:16,  1.88it/s]\u001b[A\n",
            " 44% 24/55 [00:12<00:16,  1.88it/s]\u001b[A\n",
            " 45% 25/55 [00:12<00:15,  1.88it/s]\u001b[A\n",
            " 47% 26/55 [00:13<00:15,  1.89it/s]\u001b[A\n",
            " 49% 27/55 [00:13<00:14,  1.89it/s]\u001b[A\n",
            " 51% 28/55 [00:14<00:14,  1.89it/s]\u001b[A\n",
            " 53% 29/55 [00:14<00:13,  1.88it/s]\u001b[A\n",
            " 55% 30/55 [00:15<00:13,  1.88it/s]\u001b[A\n",
            " 56% 31/55 [00:15<00:12,  1.88it/s]\u001b[A\n",
            " 58% 32/55 [00:16<00:12,  1.88it/s]\u001b[A\n",
            " 60% 33/55 [00:16<00:11,  1.88it/s]\u001b[A\n",
            " 62% 34/55 [00:17<00:11,  1.88it/s]\u001b[A\n",
            " 64% 35/55 [00:18<00:10,  1.88it/s]\u001b[A\n",
            " 65% 36/55 [00:18<00:10,  1.88it/s]\u001b[A\n",
            " 67% 37/55 [00:19<00:09,  1.88it/s]\u001b[A\n",
            " 69% 38/55 [00:19<00:09,  1.88it/s]\u001b[A\n",
            " 71% 39/55 [00:20<00:08,  1.88it/s]\u001b[A\n",
            " 73% 40/55 [00:20<00:07,  1.88it/s]\u001b[A\n",
            " 75% 41/55 [00:21<00:07,  1.88it/s]\u001b[A\n",
            " 76% 42/55 [00:21<00:06,  1.88it/s]\u001b[A\n",
            " 78% 43/55 [00:22<00:06,  1.88it/s]\u001b[A\n",
            " 80% 44/55 [00:22<00:05,  1.88it/s]\u001b[A\n",
            " 82% 45/55 [00:23<00:05,  1.88it/s]\u001b[A\n",
            " 84% 46/55 [00:23<00:04,  1.88it/s]\u001b[A\n",
            " 85% 47/55 [00:24<00:04,  1.88it/s]\u001b[A\n",
            " 87% 48/55 [00:24<00:03,  1.88it/s]\u001b[A\n",
            " 89% 49/55 [00:25<00:03,  1.88it/s]\u001b[A\n",
            " 91% 50/55 [00:26<00:02,  1.88it/s]\u001b[A\n",
            " 93% 51/55 [00:26<00:02,  1.88it/s]\u001b[A\n",
            " 95% 52/55 [00:27<00:01,  1.88it/s]\u001b[A\n",
            " 96% 53/55 [00:27<00:01,  1.88it/s]\u001b[A\n",
            " 98% 54/55 [00:28<00:00,  1.88it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 5.314497947692871, 'eval_accuracy': 0.0639269406392694, 'eval_runtime': 29.1281, 'eval_samples_per_second': 7.519, 'eval_steps_per_second': 1.888, 'epoch': 0.99}\n",
            "  5% 61/1220 [15:40<4:51:43, 15.10s/it]\n",
            "100% 55/55 [00:28<00:00,  2.02it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2193] 2022-04-28 00:44:55,278 >> Saving model checkpoint to ./orchid219_vit-huge-patch14-224-in21k/checkpoint-61\n",
            "[INFO|configuration_utils.py:446] 2022-04-28 00:44:55,280 >> Configuration saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-61/config.json\n",
            "[INFO|modeling_utils.py:1468] 2022-04-28 00:45:04,886 >> Model weights saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-61/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-04-28 00:45:04,887 >> Feature extractor saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-61/preprocessor_config.json\n",
            "[INFO|feature_extraction_utils.py:351] 2022-04-28 00:45:36,192 >> Feature extractor saved in ./orchid219_vit-huge-patch14-224-in21k/preprocessor_config.json\n",
            "{'loss': 5.9746, 'learning_rate': 1.89344262295082e-05, 'epoch': 1.06}\n",
            "{'loss': 5.2973, 'learning_rate': 1.8852459016393446e-05, 'epoch': 1.15}\n",
            "{'loss': 5.2881, 'learning_rate': 1.877049180327869e-05, 'epoch': 1.23}\n",
            "{'loss': 5.2743, 'learning_rate': 1.8688524590163936e-05, 'epoch': 1.31}\n",
            "{'loss': 5.2668, 'learning_rate': 1.8606557377049183e-05, 'epoch': 1.39}\n",
            "{'loss': 5.2593, 'learning_rate': 1.852459016393443e-05, 'epoch': 1.47}\n",
            "{'loss': 5.2563, 'learning_rate': 1.8442622950819673e-05, 'epoch': 1.55}\n",
            "{'loss': 5.2605, 'learning_rate': 1.836065573770492e-05, 'epoch': 1.63}\n",
            "{'loss': 5.2271, 'learning_rate': 1.8278688524590166e-05, 'epoch': 1.71}\n",
            "{'loss': 5.2426, 'learning_rate': 1.8196721311475413e-05, 'epoch': 1.8}\n",
            "{'loss': 5.2248, 'learning_rate': 1.8114754098360656e-05, 'epoch': 1.88}\n",
            "{'loss': 5.2005, 'learning_rate': 1.8032786885245903e-05, 'epoch': 1.96}\n",
            " 10% 122/1220 [32:01<4:36:31, 15.11s/it][INFO|trainer.py:2443] 2022-04-28 01:01:25,354 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2445] 2022-04-28 01:01:25,355 >>   Num examples = 219\n",
            "[INFO|trainer.py:2448] 2022-04-28 01:01:25,355 >>   Batch size = 4\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:14,  3.70it/s]\u001b[A\n",
            "  5% 3/55 [00:01<00:19,  2.65it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:22,  2.28it/s]\u001b[A\n",
            "  9% 5/55 [00:02<00:23,  2.13it/s]\u001b[A\n",
            " 11% 6/55 [00:02<00:24,  2.03it/s]\u001b[A\n",
            " 13% 7/55 [00:03<00:24,  1.99it/s]\u001b[A\n",
            " 15% 8/55 [00:03<00:24,  1.94it/s]\u001b[A\n",
            " 16% 9/55 [00:04<00:23,  1.92it/s]\u001b[A\n",
            " 18% 10/55 [00:04<00:23,  1.91it/s]\u001b[A\n",
            " 20% 11/55 [00:05<00:23,  1.90it/s]\u001b[A\n",
            " 22% 12/55 [00:05<00:22,  1.89it/s]\u001b[A\n",
            " 24% 13/55 [00:06<00:22,  1.88it/s]\u001b[A\n",
            " 25% 14/55 [00:06<00:21,  1.87it/s]\u001b[A\n",
            " 27% 15/55 [00:07<00:21,  1.88it/s]\u001b[A\n",
            " 29% 16/55 [00:08<00:20,  1.87it/s]\u001b[A\n",
            " 31% 17/55 [00:08<00:20,  1.87it/s]\u001b[A\n",
            " 33% 18/55 [00:09<00:19,  1.87it/s]\u001b[A\n",
            " 35% 19/55 [00:09<00:19,  1.87it/s]\u001b[A\n",
            " 36% 20/55 [00:10<00:18,  1.87it/s]\u001b[A\n",
            " 38% 21/55 [00:10<00:18,  1.88it/s]\u001b[A\n",
            " 40% 22/55 [00:11<00:17,  1.87it/s]\u001b[A\n",
            " 42% 23/55 [00:11<00:17,  1.87it/s]\u001b[A\n",
            " 44% 24/55 [00:12<00:16,  1.87it/s]\u001b[A\n",
            " 45% 25/55 [00:12<00:16,  1.87it/s]\u001b[A\n",
            " 47% 26/55 [00:13<00:15,  1.87it/s]\u001b[A\n",
            " 49% 27/55 [00:13<00:14,  1.88it/s]\u001b[A\n",
            " 51% 28/55 [00:14<00:14,  1.88it/s]\u001b[A\n",
            " 53% 29/55 [00:14<00:13,  1.88it/s]\u001b[A\n",
            " 55% 30/55 [00:15<00:13,  1.88it/s]\u001b[A\n",
            " 56% 31/55 [00:16<00:12,  1.88it/s]\u001b[A\n",
            " 58% 32/55 [00:16<00:12,  1.88it/s]\u001b[A\n",
            " 60% 33/55 [00:17<00:11,  1.88it/s]\u001b[A\n",
            " 62% 34/55 [00:17<00:11,  1.87it/s]\u001b[A\n",
            " 64% 35/55 [00:18<00:10,  1.88it/s]\u001b[A\n",
            " 65% 36/55 [00:18<00:10,  1.88it/s]\u001b[A\n",
            " 67% 37/55 [00:19<00:09,  1.88it/s]\u001b[A\n",
            " 69% 38/55 [00:19<00:09,  1.88it/s]\u001b[A\n",
            " 71% 39/55 [00:20<00:08,  1.88it/s]\u001b[A\n",
            " 73% 40/55 [00:20<00:07,  1.88it/s]\u001b[A\n",
            " 75% 41/55 [00:21<00:07,  1.88it/s]\u001b[A\n",
            " 76% 42/55 [00:21<00:06,  1.88it/s]\u001b[A\n",
            " 78% 43/55 [00:22<00:06,  1.88it/s]\u001b[A\n",
            " 80% 44/55 [00:22<00:05,  1.88it/s]\u001b[A\n",
            " 82% 45/55 [00:23<00:05,  1.87it/s]\u001b[A\n",
            " 84% 46/55 [00:24<00:04,  1.87it/s]\u001b[A\n",
            " 85% 47/55 [00:24<00:04,  1.87it/s]\u001b[A\n",
            " 87% 48/55 [00:25<00:03,  1.88it/s]\u001b[A\n",
            " 89% 49/55 [00:25<00:03,  1.88it/s]\u001b[A\n",
            " 91% 50/55 [00:26<00:02,  1.88it/s]\u001b[A\n",
            " 93% 51/55 [00:26<00:02,  1.89it/s]\u001b[A\n",
            " 95% 52/55 [00:27<00:01,  1.88it/s]\u001b[A\n",
            " 96% 53/55 [00:27<00:01,  1.88it/s]\u001b[A\n",
            " 98% 54/55 [00:28<00:00,  1.89it/s]\u001b[A\n",
            "                                        \n",
            "\u001b[A{'eval_loss': 5.2109551429748535, 'eval_accuracy': 0.2146118721461187, 'eval_runtime': 29.3336, 'eval_samples_per_second': 7.466, 'eval_steps_per_second': 1.875, 'epoch': 1.99}\n",
            " 10% 122/1220 [32:39<4:36:31, 15.11s/it]\n",
            "100% 55/55 [00:28<00:00,  2.03it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2193] 2022-04-28 01:01:54,690 >> Saving model checkpoint to ./orchid219_vit-huge-patch14-224-in21k/checkpoint-122\n",
            "[INFO|configuration_utils.py:446] 2022-04-28 01:01:54,692 >> Configuration saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-122/config.json\n",
            "[INFO|modeling_utils.py:1468] 2022-04-28 01:02:04,331 >> Model weights saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-122/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-04-28 01:02:04,332 >> Feature extractor saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-122/preprocessor_config.json\n",
            "{'loss': 5.8614, 'learning_rate': 1.795081967213115e-05, 'epoch': 2.05}\n",
            "{'loss': 5.186, 'learning_rate': 1.7868852459016393e-05, 'epoch': 2.13}\n",
            "{'loss': 5.1564, 'learning_rate': 1.7786885245901643e-05, 'epoch': 2.21}\n",
            "{'loss': 5.1441, 'learning_rate': 1.7704918032786887e-05, 'epoch': 2.29}\n",
            "{'loss': 5.137, 'learning_rate': 1.7622950819672133e-05, 'epoch': 2.37}\n",
            "{'loss': 5.129, 'learning_rate': 1.7540983606557377e-05, 'epoch': 2.45}\n",
            "{'loss': 5.1437, 'learning_rate': 1.7459016393442624e-05, 'epoch': 2.54}\n",
            "{'loss': 5.1307, 'learning_rate': 1.737704918032787e-05, 'epoch': 2.62}\n",
            "{'loss': 5.1144, 'learning_rate': 1.7295081967213117e-05, 'epoch': 2.7}\n",
            "{'loss': 5.1102, 'learning_rate': 1.721311475409836e-05, 'epoch': 2.78}\n",
            "{'loss': 5.0947, 'learning_rate': 1.7131147540983607e-05, 'epoch': 2.86}\n",
            "{'loss': 5.0697, 'learning_rate': 1.7049180327868854e-05, 'epoch': 2.94}\n",
            " 15% 183/1220 [48:27<4:20:31, 15.07s/it][INFO|trainer.py:2443] 2022-04-28 01:17:51,657 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2445] 2022-04-28 01:17:51,657 >>   Num examples = 219\n",
            "[INFO|trainer.py:2448] 2022-04-28 01:17:51,657 >>   Batch size = 4\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:14,  3.72it/s]\u001b[A\n",
            "  5% 3/55 [00:01<00:19,  2.67it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:22,  2.31it/s]\u001b[A\n",
            "  9% 5/55 [00:02<00:23,  2.15it/s]\u001b[A\n",
            " 11% 6/55 [00:02<00:23,  2.04it/s]\u001b[A\n",
            " 13% 7/55 [00:03<00:24,  2.00it/s]\u001b[A\n",
            " 15% 8/55 [00:03<00:24,  1.95it/s]\u001b[A\n",
            " 16% 9/55 [00:04<00:23,  1.93it/s]\u001b[A\n",
            " 18% 10/55 [00:04<00:23,  1.91it/s]\u001b[A\n",
            " 20% 11/55 [00:05<00:23,  1.91it/s]\u001b[A\n",
            " 22% 12/55 [00:05<00:22,  1.90it/s]\u001b[A\n",
            " 24% 13/55 [00:06<00:22,  1.90it/s]\u001b[A\n",
            " 25% 14/55 [00:06<00:21,  1.90it/s]\u001b[A\n",
            " 27% 15/55 [00:07<00:21,  1.89it/s]\u001b[A\n",
            " 29% 16/55 [00:07<00:20,  1.89it/s]\u001b[A\n",
            " 31% 17/55 [00:08<00:20,  1.89it/s]\u001b[A\n",
            " 33% 18/55 [00:09<00:19,  1.89it/s]\u001b[A\n",
            " 35% 19/55 [00:09<00:19,  1.89it/s]\u001b[A\n",
            " 36% 20/55 [00:10<00:18,  1.89it/s]\u001b[A\n",
            " 38% 21/55 [00:10<00:17,  1.90it/s]\u001b[A\n",
            " 40% 22/55 [00:11<00:17,  1.89it/s]\u001b[A\n",
            " 42% 23/55 [00:11<00:16,  1.90it/s]\u001b[A\n",
            " 44% 24/55 [00:12<00:16,  1.89it/s]\u001b[A\n",
            " 45% 25/55 [00:12<00:15,  1.89it/s]\u001b[A\n",
            " 47% 26/55 [00:13<00:15,  1.89it/s]\u001b[A\n",
            " 49% 27/55 [00:13<00:14,  1.89it/s]\u001b[A\n",
            " 51% 28/55 [00:14<00:14,  1.89it/s]\u001b[A\n",
            " 53% 29/55 [00:14<00:13,  1.89it/s]\u001b[A\n",
            " 55% 30/55 [00:15<00:13,  1.89it/s]\u001b[A\n",
            " 56% 31/55 [00:15<00:12,  1.89it/s]\u001b[A\n",
            " 58% 32/55 [00:16<00:12,  1.88it/s]\u001b[A\n",
            " 60% 33/55 [00:16<00:11,  1.89it/s]\u001b[A\n",
            " 62% 34/55 [00:17<00:11,  1.89it/s]\u001b[A\n",
            " 64% 35/55 [00:18<00:10,  1.89it/s]\u001b[A\n",
            " 65% 36/55 [00:18<00:10,  1.88it/s]\u001b[A\n",
            " 67% 37/55 [00:19<00:09,  1.89it/s]\u001b[A\n",
            " 69% 38/55 [00:19<00:09,  1.89it/s]\u001b[A\n",
            " 71% 39/55 [00:20<00:08,  1.89it/s]\u001b[A\n",
            " 73% 40/55 [00:20<00:07,  1.89it/s]\u001b[A\n",
            " 75% 41/55 [00:21<00:07,  1.89it/s]\u001b[A\n",
            " 76% 42/55 [00:21<00:06,  1.89it/s]\u001b[A\n",
            " 78% 43/55 [00:22<00:06,  1.89it/s]\u001b[A\n",
            " 80% 44/55 [00:22<00:05,  1.89it/s]\u001b[A\n",
            " 82% 45/55 [00:23<00:05,  1.89it/s]\u001b[A\n",
            " 84% 46/55 [00:23<00:04,  1.89it/s]\u001b[A\n",
            " 85% 47/55 [00:24<00:04,  1.89it/s]\u001b[A\n",
            " 87% 48/55 [00:24<00:03,  1.89it/s]\u001b[A\n",
            " 89% 49/55 [00:25<00:03,  1.89it/s]\u001b[A\n",
            " 91% 50/55 [00:25<00:02,  1.89it/s]\u001b[A\n",
            " 93% 51/55 [00:26<00:02,  1.90it/s]\u001b[A\n",
            " 95% 52/55 [00:27<00:01,  1.89it/s]\u001b[A\n",
            " 96% 53/55 [00:27<00:01,  1.90it/s]\u001b[A\n",
            " 98% 54/55 [00:28<00:00,  1.89it/s]\u001b[A\n",
            "                                        \n",
            "\u001b[A{'eval_loss': 5.098244667053223, 'eval_accuracy': 0.3607305936073059, 'eval_runtime': 29.0484, 'eval_samples_per_second': 7.539, 'eval_steps_per_second': 1.893, 'epoch': 2.99}\n",
            " 15% 183/1220 [49:05<4:20:31, 15.07s/it]\n",
            "100% 55/55 [00:28<00:00,  2.05it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2193] 2022-04-28 01:18:20,708 >> Saving model checkpoint to ./orchid219_vit-huge-patch14-224-in21k/checkpoint-183\n",
            "[INFO|configuration_utils.py:446] 2022-04-28 01:18:20,709 >> Configuration saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-183/config.json\n",
            "[INFO|modeling_utils.py:1468] 2022-04-28 01:18:30,272 >> Model weights saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-183/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-04-28 01:18:30,273 >> Feature extractor saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-183/preprocessor_config.json\n",
            "[INFO|trainer.py:2271] 2022-04-28 01:18:50,424 >> Deleting older checkpoint [orchid219_vit-huge-patch14-224-in21k/checkpoint-61] due to args.save_total_limit\n",
            "{'loss': 5.6908, 'learning_rate': 1.69672131147541e-05, 'epoch': 3.03}\n",
            "{'loss': 5.0276, 'learning_rate': 1.6885245901639347e-05, 'epoch': 3.11}\n",
            "{'loss': 5.0072, 'learning_rate': 1.680327868852459e-05, 'epoch': 3.19}\n",
            "{'loss': 5.0114, 'learning_rate': 1.6721311475409837e-05, 'epoch': 3.28}\n",
            "{'loss': 4.9926, 'learning_rate': 1.6639344262295084e-05, 'epoch': 3.36}\n",
            "{'loss': 5.0023, 'learning_rate': 1.655737704918033e-05, 'epoch': 3.44}\n",
            "{'loss': 4.9866, 'learning_rate': 1.6475409836065574e-05, 'epoch': 3.52}\n",
            "{'loss': 4.9837, 'learning_rate': 1.639344262295082e-05, 'epoch': 3.6}\n",
            "{'loss': 5.0005, 'learning_rate': 1.6311475409836068e-05, 'epoch': 3.68}\n",
            "{'loss': 4.9516, 'learning_rate': 1.6229508196721314e-05, 'epoch': 3.76}\n",
            "{'loss': 4.9615, 'learning_rate': 1.6147540983606558e-05, 'epoch': 3.84}\n",
            "{'loss': 4.9396, 'learning_rate': 1.6065573770491805e-05, 'epoch': 3.92}\n",
            " 20% 244/1220 [1:04:51<4:06:00, 15.12s/it][INFO|trainer.py:2443] 2022-04-28 01:34:15,588 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2445] 2022-04-28 01:34:15,588 >>   Num examples = 219\n",
            "[INFO|trainer.py:2448] 2022-04-28 01:34:15,588 >>   Batch size = 4\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:14,  3.74it/s]\u001b[A\n",
            "  5% 3/55 [00:01<00:19,  2.66it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:22,  2.30it/s]\u001b[A\n",
            "  9% 5/55 [00:02<00:23,  2.14it/s]\u001b[A\n",
            " 11% 6/55 [00:02<00:23,  2.05it/s]\u001b[A\n",
            " 13% 7/55 [00:03<00:24,  1.99it/s]\u001b[A\n",
            " 15% 8/55 [00:03<00:23,  1.96it/s]\u001b[A\n",
            " 16% 9/55 [00:04<00:23,  1.94it/s]\u001b[A\n",
            " 18% 10/55 [00:04<00:23,  1.93it/s]\u001b[A\n",
            " 20% 11/55 [00:05<00:23,  1.91it/s]\u001b[A\n",
            " 22% 12/55 [00:05<00:22,  1.90it/s]\u001b[A\n",
            " 24% 13/55 [00:06<00:22,  1.90it/s]\u001b[A\n",
            " 25% 14/55 [00:06<00:21,  1.89it/s]\u001b[A\n",
            " 27% 15/55 [00:07<00:21,  1.89it/s]\u001b[A\n",
            " 29% 16/55 [00:07<00:20,  1.89it/s]\u001b[A\n",
            " 31% 17/55 [00:08<00:20,  1.89it/s]\u001b[A\n",
            " 33% 18/55 [00:09<00:19,  1.89it/s]\u001b[A\n",
            " 35% 19/55 [00:09<00:19,  1.89it/s]\u001b[A\n",
            " 36% 20/55 [00:10<00:18,  1.89it/s]\u001b[A\n",
            " 38% 21/55 [00:10<00:18,  1.89it/s]\u001b[A\n",
            " 40% 22/55 [00:11<00:17,  1.88it/s]\u001b[A\n",
            " 42% 23/55 [00:11<00:17,  1.88it/s]\u001b[A\n",
            " 44% 24/55 [00:12<00:16,  1.88it/s]\u001b[A\n",
            " 45% 25/55 [00:12<00:15,  1.89it/s]\u001b[A\n",
            " 47% 26/55 [00:13<00:15,  1.89it/s]\u001b[A\n",
            " 49% 27/55 [00:13<00:14,  1.88it/s]\u001b[A\n",
            " 51% 28/55 [00:14<00:14,  1.89it/s]\u001b[A\n",
            " 53% 29/55 [00:14<00:13,  1.89it/s]\u001b[A\n",
            " 55% 30/55 [00:15<00:13,  1.89it/s]\u001b[A\n",
            " 56% 31/55 [00:15<00:12,  1.89it/s]\u001b[A\n",
            " 58% 32/55 [00:16<00:12,  1.89it/s]\u001b[A\n",
            " 60% 33/55 [00:16<00:11,  1.88it/s]\u001b[A\n",
            " 62% 34/55 [00:17<00:11,  1.88it/s]\u001b[A\n",
            " 64% 35/55 [00:18<00:10,  1.88it/s]\u001b[A\n",
            " 65% 36/55 [00:18<00:10,  1.89it/s]\u001b[A\n",
            " 67% 37/55 [00:19<00:09,  1.89it/s]\u001b[A\n",
            " 69% 38/55 [00:19<00:09,  1.89it/s]\u001b[A\n",
            " 71% 39/55 [00:20<00:08,  1.88it/s]\u001b[A\n",
            " 73% 40/55 [00:20<00:07,  1.89it/s]\u001b[A\n",
            " 75% 41/55 [00:21<00:07,  1.88it/s]\u001b[A\n",
            " 76% 42/55 [00:21<00:06,  1.89it/s]\u001b[A\n",
            " 78% 43/55 [00:22<00:06,  1.89it/s]\u001b[A\n",
            " 80% 44/55 [00:22<00:05,  1.89it/s]\u001b[A\n",
            " 82% 45/55 [00:23<00:05,  1.89it/s]\u001b[A\n",
            " 84% 46/55 [00:23<00:04,  1.89it/s]\u001b[A\n",
            " 85% 47/55 [00:24<00:04,  1.89it/s]\u001b[A\n",
            " 87% 48/55 [00:24<00:03,  1.89it/s]\u001b[A\n",
            " 89% 49/55 [00:25<00:03,  1.90it/s]\u001b[A\n",
            " 91% 50/55 [00:25<00:02,  1.89it/s]\u001b[A\n",
            " 93% 51/55 [00:26<00:02,  1.89it/s]\u001b[A\n",
            " 95% 52/55 [00:27<00:01,  1.89it/s]\u001b[A\n",
            " 96% 53/55 [00:27<00:01,  1.90it/s]\u001b[A\n",
            " 98% 54/55 [00:28<00:00,  1.90it/s]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 4.977859973907471, 'eval_accuracy': 0.4520547945205479, 'eval_runtime': 29.0224, 'eval_samples_per_second': 7.546, 'eval_steps_per_second': 1.895, 'epoch': 3.99}\n",
            " 20% 244/1220 [1:05:29<4:06:00, 15.12s/it]\n",
            "100% 55/55 [00:28<00:00,  2.05it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2193] 2022-04-28 01:34:44,612 >> Saving model checkpoint to ./orchid219_vit-huge-patch14-224-in21k/checkpoint-244\n",
            "[INFO|configuration_utils.py:446] 2022-04-28 01:34:44,614 >> Configuration saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-244/config.json\n",
            "[INFO|modeling_utils.py:1468] 2022-04-28 01:34:54,189 >> Model weights saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-244/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-04-28 01:34:54,190 >> Feature extractor saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-244/preprocessor_config.json\n",
            "[INFO|trainer.py:2271] 2022-04-28 01:35:14,256 >> Deleting older checkpoint [orchid219_vit-huge-patch14-224-in21k/checkpoint-122] due to args.save_total_limit\n",
            "{'loss': 5.5553, 'learning_rate': 1.598360655737705e-05, 'epoch': 4.02}\n",
            "{'loss': 4.9099, 'learning_rate': 1.5901639344262295e-05, 'epoch': 4.1}\n",
            "{'loss': 4.905, 'learning_rate': 1.5819672131147545e-05, 'epoch': 4.18}\n",
            "{'loss': 4.8808, 'learning_rate': 1.5737704918032788e-05, 'epoch': 4.26}\n",
            "{'loss': 4.8753, 'learning_rate': 1.5655737704918035e-05, 'epoch': 4.34}\n",
            "{'loss': 4.8815, 'learning_rate': 1.5573770491803278e-05, 'epoch': 4.42}\n",
            "{'loss': 4.8661, 'learning_rate': 1.5491803278688525e-05, 'epoch': 4.5}\n",
            "{'loss': 4.8201, 'learning_rate': 1.5409836065573772e-05, 'epoch': 4.58}\n",
            "{'loss': 4.8287, 'learning_rate': 1.532786885245902e-05, 'epoch': 4.67}\n",
            "{'loss': 4.8458, 'learning_rate': 1.5245901639344264e-05, 'epoch': 4.75}\n",
            "{'loss': 4.8381, 'learning_rate': 1.516393442622951e-05, 'epoch': 4.83}\n",
            "{'loss': 4.8309, 'learning_rate': 1.5081967213114754e-05, 'epoch': 4.91}\n",
            "{'loss': 4.8285, 'learning_rate': 1.5000000000000002e-05, 'epoch': 4.99}\n",
            " 25% 305/1220 [1:21:16<3:49:15, 15.03s/it][INFO|trainer.py:2443] 2022-04-28 01:50:40,035 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2445] 2022-04-28 01:50:40,035 >>   Num examples = 219\n",
            "[INFO|trainer.py:2448] 2022-04-28 01:50:40,035 >>   Batch size = 4\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:14,  3.75it/s]\u001b[A\n",
            "  5% 3/55 [00:01<00:19,  2.68it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:22,  2.30it/s]\u001b[A\n",
            "  9% 5/55 [00:02<00:23,  2.15it/s]\u001b[A\n",
            " 11% 6/55 [00:02<00:23,  2.05it/s]\u001b[A\n",
            " 13% 7/55 [00:03<00:23,  2.00it/s]\u001b[A\n",
            " 15% 8/55 [00:03<00:23,  1.97it/s]\u001b[A\n",
            " 16% 9/55 [00:04<00:23,  1.95it/s]\u001b[A\n",
            " 18% 10/55 [00:04<00:23,  1.93it/s]\u001b[A\n",
            " 20% 11/55 [00:05<00:22,  1.92it/s]\u001b[A\n",
            " 22% 12/55 [00:05<00:22,  1.91it/s]\u001b[A\n",
            " 24% 13/55 [00:06<00:22,  1.91it/s]\u001b[A\n",
            " 25% 14/55 [00:06<00:21,  1.90it/s]\u001b[A\n",
            " 27% 15/55 [00:07<00:21,  1.90it/s]\u001b[A\n",
            " 29% 16/55 [00:07<00:20,  1.90it/s]\u001b[A\n",
            " 31% 17/55 [00:08<00:20,  1.89it/s]\u001b[A\n",
            " 33% 18/55 [00:08<00:19,  1.89it/s]\u001b[A\n",
            " 35% 19/55 [00:09<00:19,  1.89it/s]\u001b[A\n",
            " 36% 20/55 [00:10<00:18,  1.88it/s]\u001b[A\n",
            " 38% 21/55 [00:10<00:18,  1.88it/s]\u001b[A\n",
            " 40% 22/55 [00:11<00:17,  1.88it/s]\u001b[A\n",
            " 42% 23/55 [00:11<00:16,  1.88it/s]\u001b[A\n",
            " 44% 24/55 [00:12<00:16,  1.88it/s]\u001b[A\n",
            " 45% 25/55 [00:12<00:15,  1.89it/s]\u001b[A\n",
            " 47% 26/55 [00:13<00:15,  1.89it/s]\u001b[A\n",
            " 49% 27/55 [00:13<00:14,  1.89it/s]\u001b[A\n",
            " 51% 28/55 [00:14<00:14,  1.89it/s]\u001b[A\n",
            " 53% 29/55 [00:14<00:13,  1.89it/s]\u001b[A\n",
            " 55% 30/55 [00:15<00:13,  1.89it/s]\u001b[A\n",
            " 56% 31/55 [00:15<00:12,  1.89it/s]\u001b[A\n",
            " 58% 32/55 [00:16<00:12,  1.88it/s]\u001b[A\n",
            " 60% 33/55 [00:16<00:11,  1.88it/s]\u001b[A\n",
            " 62% 34/55 [00:17<00:11,  1.88it/s]\u001b[A\n",
            " 64% 35/55 [00:18<00:10,  1.88it/s]\u001b[A\n",
            " 65% 36/55 [00:18<00:10,  1.89it/s]\u001b[A\n",
            " 67% 37/55 [00:19<00:09,  1.88it/s]\u001b[A\n",
            " 69% 38/55 [00:19<00:09,  1.89it/s]\u001b[A\n",
            " 71% 39/55 [00:20<00:08,  1.89it/s]\u001b[A\n",
            " 73% 40/55 [00:20<00:07,  1.89it/s]\u001b[A\n",
            " 75% 41/55 [00:21<00:07,  1.89it/s]\u001b[A\n",
            " 76% 42/55 [00:21<00:06,  1.89it/s]\u001b[A\n",
            " 78% 43/55 [00:22<00:06,  1.89it/s]\u001b[A\n",
            " 80% 44/55 [00:22<00:05,  1.89it/s]\u001b[A\n",
            " 82% 45/55 [00:23<00:05,  1.89it/s]\u001b[A\n",
            " 84% 46/55 [00:23<00:04,  1.89it/s]\u001b[A\n",
            " 85% 47/55 [00:24<00:04,  1.89it/s]\u001b[A\n",
            " 87% 48/55 [00:24<00:03,  1.89it/s]\u001b[A\n",
            " 89% 49/55 [00:25<00:03,  1.89it/s]\u001b[A\n",
            " 91% 50/55 [00:25<00:02,  1.89it/s]\u001b[A\n",
            " 93% 51/55 [00:26<00:02,  1.89it/s]\u001b[A\n",
            " 95% 52/55 [00:27<00:01,  1.89it/s]\u001b[A\n",
            " 96% 53/55 [00:27<00:01,  1.89it/s]\u001b[A\n",
            " 98% 54/55 [00:28<00:00,  1.89it/s]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 4.866714954376221, 'eval_accuracy': 0.5159817351598174, 'eval_runtime': 29.0048, 'eval_samples_per_second': 7.55, 'eval_steps_per_second': 1.896, 'epoch': 4.99}\n",
            " 25% 305/1220 [1:21:53<3:49:15, 15.03s/it]\n",
            "100% 55/55 [00:28<00:00,  2.04it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2193] 2022-04-28 01:51:09,041 >> Saving model checkpoint to ./orchid219_vit-huge-patch14-224-in21k/checkpoint-305\n",
            "[INFO|configuration_utils.py:446] 2022-04-28 01:51:09,043 >> Configuration saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-305/config.json\n",
            "[INFO|modeling_utils.py:1468] 2022-04-28 01:51:18,586 >> Model weights saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-305/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-04-28 01:51:18,587 >> Feature extractor saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-305/preprocessor_config.json\n",
            "[INFO|trainer.py:2271] 2022-04-28 01:51:38,663 >> Deleting older checkpoint [orchid219_vit-huge-patch14-224-in21k/checkpoint-183] due to args.save_total_limit\n",
            "{'loss': 5.358, 'learning_rate': 1.4918032786885249e-05, 'epoch': 5.08}\n",
            "{'loss': 4.7867, 'learning_rate': 1.4836065573770492e-05, 'epoch': 5.16}\n",
            "{'loss': 4.748, 'learning_rate': 1.4754098360655739e-05, 'epoch': 5.24}\n",
            "{'loss': 4.7573, 'learning_rate': 1.4672131147540984e-05, 'epoch': 5.32}\n",
            "{'loss': 4.7299, 'learning_rate': 1.459016393442623e-05, 'epoch': 5.41}\n",
            "{'loss': 4.7294, 'learning_rate': 1.4508196721311476e-05, 'epoch': 5.49}\n",
            "{'loss': 4.753, 'learning_rate': 1.4426229508196722e-05, 'epoch': 5.57}\n",
            "{'loss': 4.7191, 'learning_rate': 1.4344262295081968e-05, 'epoch': 5.65}\n",
            "{'loss': 4.7266, 'learning_rate': 1.4262295081967214e-05, 'epoch': 5.73}\n",
            "{'loss': 4.7094, 'learning_rate': 1.418032786885246e-05, 'epoch': 5.81}\n",
            "{'loss': 4.7292, 'learning_rate': 1.4098360655737706e-05, 'epoch': 5.89}\n",
            "{'loss': 4.6967, 'learning_rate': 1.4016393442622951e-05, 'epoch': 5.97}\n",
            " 30% 366/1220 [1:37:39<3:34:45, 15.09s/it][INFO|trainer.py:2443] 2022-04-28 02:07:03,073 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2445] 2022-04-28 02:07:03,073 >>   Num examples = 219\n",
            "[INFO|trainer.py:2448] 2022-04-28 02:07:03,073 >>   Batch size = 4\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:14,  3.78it/s]\u001b[A\n",
            "  5% 3/55 [00:01<00:19,  2.69it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:21,  2.33it/s]\u001b[A\n",
            "  9% 5/55 [00:02<00:23,  2.16it/s]\u001b[A\n",
            " 11% 6/55 [00:02<00:23,  2.07it/s]\u001b[A\n",
            " 13% 7/55 [00:03<00:23,  2.01it/s]\u001b[A\n",
            " 15% 8/55 [00:03<00:23,  1.97it/s]\u001b[A\n",
            " 16% 9/55 [00:04<00:23,  1.95it/s]\u001b[A\n",
            " 18% 10/55 [00:04<00:23,  1.93it/s]\u001b[A\n",
            " 20% 11/55 [00:05<00:22,  1.92it/s]\u001b[A\n",
            " 22% 12/55 [00:05<00:22,  1.92it/s]\u001b[A\n",
            " 24% 13/55 [00:06<00:22,  1.91it/s]\u001b[A\n",
            " 25% 14/55 [00:06<00:21,  1.91it/s]\u001b[A\n",
            " 27% 15/55 [00:07<00:21,  1.90it/s]\u001b[A\n",
            " 29% 16/55 [00:07<00:20,  1.90it/s]\u001b[A\n",
            " 31% 17/55 [00:08<00:19,  1.90it/s]\u001b[A\n",
            " 33% 18/55 [00:08<00:19,  1.90it/s]\u001b[A\n",
            " 35% 19/55 [00:09<00:18,  1.90it/s]\u001b[A\n",
            " 36% 20/55 [00:10<00:18,  1.90it/s]\u001b[A\n",
            " 38% 21/55 [00:10<00:17,  1.89it/s]\u001b[A\n",
            " 40% 22/55 [00:11<00:17,  1.90it/s]\u001b[A\n",
            " 42% 23/55 [00:11<00:16,  1.89it/s]\u001b[A\n",
            " 44% 24/55 [00:12<00:16,  1.90it/s]\u001b[A\n",
            " 45% 25/55 [00:12<00:15,  1.90it/s]\u001b[A\n",
            " 47% 26/55 [00:13<00:15,  1.90it/s]\u001b[A\n",
            " 49% 27/55 [00:13<00:14,  1.90it/s]\u001b[A\n",
            " 51% 28/55 [00:14<00:14,  1.90it/s]\u001b[A\n",
            " 53% 29/55 [00:14<00:13,  1.90it/s]\u001b[A\n",
            " 55% 30/55 [00:15<00:13,  1.90it/s]\u001b[A\n",
            " 56% 31/55 [00:15<00:12,  1.90it/s]\u001b[A\n",
            " 58% 32/55 [00:16<00:12,  1.90it/s]\u001b[A\n",
            " 60% 33/55 [00:16<00:11,  1.90it/s]\u001b[A\n",
            " 62% 34/55 [00:17<00:11,  1.91it/s]\u001b[A\n",
            " 64% 35/55 [00:17<00:10,  1.90it/s]\u001b[A\n",
            " 65% 36/55 [00:18<00:09,  1.91it/s]\u001b[A\n",
            " 67% 37/55 [00:18<00:09,  1.90it/s]\u001b[A\n",
            " 69% 38/55 [00:19<00:08,  1.90it/s]\u001b[A\n",
            " 71% 39/55 [00:20<00:08,  1.89it/s]\u001b[A\n",
            " 73% 40/55 [00:20<00:07,  1.90it/s]\u001b[A\n",
            " 75% 41/55 [00:21<00:07,  1.90it/s]\u001b[A\n",
            " 76% 42/55 [00:21<00:06,  1.90it/s]\u001b[A\n",
            " 78% 43/55 [00:22<00:06,  1.90it/s]\u001b[A\n",
            " 80% 44/55 [00:22<00:05,  1.90it/s]\u001b[A\n",
            " 82% 45/55 [00:23<00:05,  1.90it/s]\u001b[A\n",
            " 84% 46/55 [00:23<00:04,  1.90it/s]\u001b[A\n",
            " 85% 47/55 [00:24<00:04,  1.90it/s]\u001b[A\n",
            " 87% 48/55 [00:24<00:03,  1.90it/s]\u001b[A\n",
            " 89% 49/55 [00:25<00:03,  1.90it/s]\u001b[A\n",
            " 91% 50/55 [00:25<00:02,  1.90it/s]\u001b[A\n",
            " 93% 51/55 [00:26<00:02,  1.90it/s]\u001b[A\n",
            " 95% 52/55 [00:26<00:01,  1.90it/s]\u001b[A\n",
            " 96% 53/55 [00:27<00:01,  1.90it/s]\u001b[A\n",
            " 98% 54/55 [00:27<00:00,  1.90it/s]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 4.770205497741699, 'eval_accuracy': 0.547945205479452, 'eval_runtime': 28.8431, 'eval_samples_per_second': 7.593, 'eval_steps_per_second': 1.907, 'epoch': 5.99}\n",
            " 30% 366/1220 [1:38:16<3:34:45, 15.09s/it]\n",
            "100% 55/55 [00:28<00:00,  2.05it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2193] 2022-04-28 02:07:31,918 >> Saving model checkpoint to ./orchid219_vit-huge-patch14-224-in21k/checkpoint-366\n",
            "[INFO|configuration_utils.py:446] 2022-04-28 02:07:31,919 >> Configuration saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-366/config.json\n",
            "[INFO|modeling_utils.py:1468] 2022-04-28 02:07:41,474 >> Model weights saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-366/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-04-28 02:07:41,475 >> Feature extractor saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-366/preprocessor_config.json\n",
            "[INFO|trainer.py:2271] 2022-04-28 02:08:01,549 >> Deleting older checkpoint [orchid219_vit-huge-patch14-224-in21k/checkpoint-244] due to args.save_total_limit\n",
            "{'loss': 5.3024, 'learning_rate': 1.3934426229508198e-05, 'epoch': 6.06}\n",
            "{'loss': 4.6616, 'learning_rate': 1.3852459016393445e-05, 'epoch': 6.15}\n",
            "{'loss': 4.6249, 'learning_rate': 1.377049180327869e-05, 'epoch': 6.23}\n",
            "{'loss': 4.638, 'learning_rate': 1.3688524590163936e-05, 'epoch': 6.31}\n",
            "{'loss': 4.6392, 'learning_rate': 1.3606557377049181e-05, 'epoch': 6.39}\n",
            "{'loss': 4.6386, 'learning_rate': 1.3524590163934428e-05, 'epoch': 6.47}\n",
            "{'loss': 4.5978, 'learning_rate': 1.3442622950819673e-05, 'epoch': 6.55}\n",
            "{'loss': 4.6116, 'learning_rate': 1.336065573770492e-05, 'epoch': 6.63}\n",
            "{'loss': 4.6167, 'learning_rate': 1.3278688524590165e-05, 'epoch': 6.71}\n",
            "{'loss': 4.5867, 'learning_rate': 1.3196721311475412e-05, 'epoch': 6.8}\n",
            "{'loss': 4.5963, 'learning_rate': 1.3114754098360655e-05, 'epoch': 6.88}\n",
            "{'loss': 4.5961, 'learning_rate': 1.3032786885245904e-05, 'epoch': 6.96}\n",
            " 35% 427/1220 [1:54:01<3:18:38, 15.03s/it][INFO|trainer.py:2443] 2022-04-28 02:23:25,438 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2445] 2022-04-28 02:23:25,439 >>   Num examples = 219\n",
            "[INFO|trainer.py:2448] 2022-04-28 02:23:25,439 >>   Batch size = 4\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:14,  3.76it/s]\u001b[A\n",
            "  5% 3/55 [00:01<00:19,  2.69it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:22,  2.31it/s]\u001b[A\n",
            "  9% 5/55 [00:02<00:23,  2.16it/s]\u001b[A\n",
            " 11% 6/55 [00:02<00:23,  2.05it/s]\u001b[A\n",
            " 13% 7/55 [00:03<00:23,  2.01it/s]\u001b[A\n",
            " 15% 8/55 [00:03<00:23,  1.96it/s]\u001b[A\n",
            " 16% 9/55 [00:04<00:23,  1.96it/s]\u001b[A\n",
            " 18% 10/55 [00:04<00:23,  1.92it/s]\u001b[A\n",
            " 20% 11/55 [00:05<00:22,  1.92it/s]\u001b[A\n",
            " 22% 12/55 [00:05<00:22,  1.90it/s]\u001b[A\n",
            " 24% 13/55 [00:06<00:22,  1.91it/s]\u001b[A\n",
            " 25% 14/55 [00:06<00:21,  1.90it/s]\u001b[A\n",
            " 27% 15/55 [00:07<00:21,  1.90it/s]\u001b[A\n",
            " 29% 16/55 [00:07<00:20,  1.89it/s]\u001b[A\n",
            " 31% 17/55 [00:08<00:20,  1.90it/s]\u001b[A\n",
            " 33% 18/55 [00:08<00:19,  1.89it/s]\u001b[A\n",
            " 35% 19/55 [00:09<00:18,  1.90it/s]\u001b[A\n",
            " 36% 20/55 [00:10<00:18,  1.89it/s]\u001b[A\n",
            " 38% 21/55 [00:10<00:17,  1.90it/s]\u001b[A\n",
            " 40% 22/55 [00:11<00:17,  1.89it/s]\u001b[A\n",
            " 42% 23/55 [00:11<00:16,  1.90it/s]\u001b[A\n",
            " 44% 24/55 [00:12<00:16,  1.89it/s]\u001b[A\n",
            " 45% 25/55 [00:12<00:15,  1.90it/s]\u001b[A\n",
            " 47% 26/55 [00:13<00:15,  1.89it/s]\u001b[A\n",
            " 49% 27/55 [00:13<00:14,  1.90it/s]\u001b[A\n",
            " 51% 28/55 [00:14<00:14,  1.88it/s]\u001b[A\n",
            " 53% 29/55 [00:14<00:13,  1.90it/s]\u001b[A\n",
            " 55% 30/55 [00:15<00:13,  1.89it/s]\u001b[A\n",
            " 56% 31/55 [00:15<00:12,  1.89it/s]\u001b[A\n",
            " 58% 32/55 [00:16<00:12,  1.89it/s]\u001b[A\n",
            " 60% 33/55 [00:16<00:11,  1.90it/s]\u001b[A\n",
            " 62% 34/55 [00:17<00:11,  1.90it/s]\u001b[A\n",
            " 64% 35/55 [00:17<00:10,  1.90it/s]\u001b[A\n",
            " 65% 36/55 [00:18<00:10,  1.89it/s]\u001b[A\n",
            " 67% 37/55 [00:19<00:09,  1.90it/s]\u001b[A\n",
            " 69% 38/55 [00:19<00:08,  1.89it/s]\u001b[A\n",
            " 71% 39/55 [00:20<00:08,  1.90it/s]\u001b[A\n",
            " 73% 40/55 [00:20<00:07,  1.89it/s]\u001b[A\n",
            " 75% 41/55 [00:21<00:07,  1.90it/s]\u001b[A\n",
            " 76% 42/55 [00:21<00:06,  1.89it/s]\u001b[A\n",
            " 78% 43/55 [00:22<00:06,  1.90it/s]\u001b[A\n",
            " 80% 44/55 [00:22<00:05,  1.89it/s]\u001b[A\n",
            " 82% 45/55 [00:23<00:05,  1.90it/s]\u001b[A\n",
            " 84% 46/55 [00:23<00:04,  1.89it/s]\u001b[A\n",
            " 85% 47/55 [00:24<00:04,  1.90it/s]\u001b[A\n",
            " 87% 48/55 [00:24<00:03,  1.89it/s]\u001b[A\n",
            " 89% 49/55 [00:25<00:03,  1.90it/s]\u001b[A\n",
            " 91% 50/55 [00:25<00:02,  1.89it/s]\u001b[A\n",
            " 93% 51/55 [00:26<00:02,  1.90it/s]\u001b[A\n",
            " 95% 52/55 [00:26<00:01,  1.89it/s]\u001b[A\n",
            " 96% 53/55 [00:27<00:01,  1.90it/s]\u001b[A\n",
            " 98% 54/55 [00:27<00:00,  1.89it/s]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 4.678547382354736, 'eval_accuracy': 0.5799086757990868, 'eval_runtime': 28.9218, 'eval_samples_per_second': 7.572, 'eval_steps_per_second': 1.902, 'epoch': 6.99}\n",
            " 35% 427/1220 [1:54:39<3:18:38, 15.03s/it]\n",
            "100% 55/55 [00:28<00:00,  2.04it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2193] 2022-04-28 02:23:54,362 >> Saving model checkpoint to ./orchid219_vit-huge-patch14-224-in21k/checkpoint-427\n",
            "[INFO|configuration_utils.py:446] 2022-04-28 02:23:54,364 >> Configuration saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-427/config.json\n",
            "[INFO|modeling_utils.py:1468] 2022-04-28 02:24:03,957 >> Model weights saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-427/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-04-28 02:24:03,958 >> Feature extractor saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-427/preprocessor_config.json\n",
            "[INFO|trainer.py:2271] 2022-04-28 02:24:24,004 >> Deleting older checkpoint [orchid219_vit-huge-patch14-224-in21k/checkpoint-305] due to args.save_total_limit\n",
            "{'loss': 5.1297, 'learning_rate': 1.295081967213115e-05, 'epoch': 7.05}\n",
            "{'loss': 4.5379, 'learning_rate': 1.2868852459016394e-05, 'epoch': 7.13}\n",
            "{'loss': 4.555, 'learning_rate': 1.2786885245901642e-05, 'epoch': 7.21}\n",
            "{'loss': 4.5224, 'learning_rate': 1.2704918032786885e-05, 'epoch': 7.29}\n",
            "{'loss': 4.5355, 'learning_rate': 1.2622950819672132e-05, 'epoch': 7.37}\n",
            "{'loss': 4.5641, 'learning_rate': 1.2540983606557377e-05, 'epoch': 7.45}\n",
            "{'loss': 4.5286, 'learning_rate': 1.2459016393442624e-05, 'epoch': 7.54}\n",
            "{'loss': 4.5165, 'learning_rate': 1.2377049180327869e-05, 'epoch': 7.62}\n",
            "{'loss': 4.5146, 'learning_rate': 1.2295081967213116e-05, 'epoch': 7.7}\n",
            "{'loss': 4.5174, 'learning_rate': 1.221311475409836e-05, 'epoch': 7.78}\n",
            "{'loss': 4.4816, 'learning_rate': 1.2131147540983608e-05, 'epoch': 7.86}\n",
            "{'loss': 4.4747, 'learning_rate': 1.2049180327868853e-05, 'epoch': 7.94}\n",
            " 40% 488/1220 [2:10:25<3:03:46, 15.06s/it][INFO|trainer.py:2443] 2022-04-28 02:39:49,244 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2445] 2022-04-28 02:39:49,244 >>   Num examples = 219\n",
            "[INFO|trainer.py:2448] 2022-04-28 02:39:49,244 >>   Batch size = 4\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:13,  3.80it/s]\u001b[A\n",
            "  5% 3/55 [00:01<00:19,  2.69it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:21,  2.32it/s]\u001b[A\n",
            "  9% 5/55 [00:02<00:23,  2.16it/s]\u001b[A\n",
            " 11% 6/55 [00:02<00:23,  2.06it/s]\u001b[A\n",
            " 13% 7/55 [00:03<00:23,  2.01it/s]\u001b[A\n",
            " 15% 8/55 [00:03<00:23,  1.96it/s]\u001b[A\n",
            " 16% 9/55 [00:04<00:23,  1.96it/s]\u001b[A\n",
            " 18% 10/55 [00:04<00:23,  1.93it/s]\u001b[A\n",
            " 20% 11/55 [00:05<00:22,  1.93it/s]\u001b[A\n",
            " 22% 12/55 [00:05<00:22,  1.91it/s]\u001b[A\n",
            " 24% 13/55 [00:06<00:21,  1.92it/s]\u001b[A\n",
            " 25% 14/55 [00:06<00:21,  1.91it/s]\u001b[A\n",
            " 27% 15/55 [00:07<00:20,  1.91it/s]\u001b[A\n",
            " 29% 16/55 [00:07<00:20,  1.90it/s]\u001b[A\n",
            " 31% 17/55 [00:08<00:19,  1.90it/s]\u001b[A\n",
            " 33% 18/55 [00:08<00:19,  1.90it/s]\u001b[A\n",
            " 35% 19/55 [00:09<00:18,  1.90it/s]\u001b[A\n",
            " 36% 20/55 [00:10<00:18,  1.89it/s]\u001b[A\n",
            " 38% 21/55 [00:10<00:17,  1.90it/s]\u001b[A\n",
            " 40% 22/55 [00:11<00:17,  1.89it/s]\u001b[A\n",
            " 42% 23/55 [00:11<00:16,  1.90it/s]\u001b[A\n",
            " 44% 24/55 [00:12<00:16,  1.89it/s]\u001b[A\n",
            " 45% 25/55 [00:12<00:15,  1.90it/s]\u001b[A\n",
            " 47% 26/55 [00:13<00:15,  1.90it/s]\u001b[A\n",
            " 49% 27/55 [00:13<00:14,  1.90it/s]\u001b[A\n",
            " 51% 28/55 [00:14<00:14,  1.89it/s]\u001b[A\n",
            " 53% 29/55 [00:14<00:13,  1.90it/s]\u001b[A\n",
            " 55% 30/55 [00:15<00:13,  1.89it/s]\u001b[A\n",
            " 56% 31/55 [00:15<00:12,  1.90it/s]\u001b[A\n",
            " 58% 32/55 [00:16<00:12,  1.89it/s]\u001b[A\n",
            " 60% 33/55 [00:16<00:11,  1.90it/s]\u001b[A\n",
            " 62% 34/55 [00:17<00:11,  1.89it/s]\u001b[A\n",
            " 64% 35/55 [00:17<00:10,  1.90it/s]\u001b[A\n",
            " 65% 36/55 [00:18<00:10,  1.89it/s]\u001b[A\n",
            " 67% 37/55 [00:18<00:09,  1.90it/s]\u001b[A\n",
            " 69% 38/55 [00:19<00:08,  1.89it/s]\u001b[A\n",
            " 71% 39/55 [00:20<00:08,  1.90it/s]\u001b[A\n",
            " 73% 40/55 [00:20<00:07,  1.89it/s]\u001b[A\n",
            " 75% 41/55 [00:21<00:07,  1.90it/s]\u001b[A\n",
            " 76% 42/55 [00:21<00:06,  1.89it/s]\u001b[A\n",
            " 78% 43/55 [00:22<00:06,  1.90it/s]\u001b[A\n",
            " 80% 44/55 [00:22<00:05,  1.89it/s]\u001b[A\n",
            " 82% 45/55 [00:23<00:05,  1.90it/s]\u001b[A\n",
            " 84% 46/55 [00:23<00:04,  1.89it/s]\u001b[A\n",
            " 85% 47/55 [00:24<00:04,  1.90it/s]\u001b[A\n",
            " 87% 48/55 [00:24<00:03,  1.89it/s]\u001b[A\n",
            " 89% 49/55 [00:25<00:03,  1.90it/s]\u001b[A\n",
            " 91% 50/55 [00:25<00:02,  1.89it/s]\u001b[A\n",
            " 93% 51/55 [00:26<00:02,  1.91it/s]\u001b[A\n",
            " 95% 52/55 [00:26<00:01,  1.89it/s]\u001b[A\n",
            " 96% 53/55 [00:27<00:01,  1.91it/s]\u001b[A\n",
            " 98% 54/55 [00:27<00:00,  1.89it/s]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 4.594412326812744, 'eval_accuracy': 0.6073059360730594, 'eval_runtime': 28.8617, 'eval_samples_per_second': 7.588, 'eval_steps_per_second': 1.906, 'epoch': 7.99}\n",
            " 40% 488/1220 [2:11:02<3:03:46, 15.06s/it]\n",
            "100% 55/55 [00:28<00:00,  2.05it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2193] 2022-04-28 02:40:18,107 >> Saving model checkpoint to ./orchid219_vit-huge-patch14-224-in21k/checkpoint-488\n",
            "[INFO|configuration_utils.py:446] 2022-04-28 02:40:18,109 >> Configuration saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-488/config.json\n",
            "[INFO|modeling_utils.py:1468] 2022-04-28 02:40:27,648 >> Model weights saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-488/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-04-28 02:40:27,653 >> Feature extractor saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-488/preprocessor_config.json\n",
            "[INFO|trainer.py:2271] 2022-04-28 02:40:47,720 >> Deleting older checkpoint [orchid219_vit-huge-patch14-224-in21k/checkpoint-366] due to args.save_total_limit\n",
            "{'loss': 5.0738, 'learning_rate': 1.19672131147541e-05, 'epoch': 8.03}\n",
            "{'loss': 4.4668, 'learning_rate': 1.1885245901639346e-05, 'epoch': 8.11}\n",
            "{'loss': 4.4637, 'learning_rate': 1.1803278688524591e-05, 'epoch': 8.19}\n",
            "{'loss': 4.4525, 'learning_rate': 1.1721311475409838e-05, 'epoch': 8.28}\n",
            "{'loss': 4.428, 'learning_rate': 1.1639344262295083e-05, 'epoch': 8.36}\n",
            "{'loss': 4.4452, 'learning_rate': 1.155737704918033e-05, 'epoch': 8.44}\n",
            "{'loss': 4.3902, 'learning_rate': 1.1475409836065575e-05, 'epoch': 8.52}\n",
            "{'loss': 4.4152, 'learning_rate': 1.1393442622950821e-05, 'epoch': 8.6}\n",
            "{'loss': 4.4291, 'learning_rate': 1.1311475409836066e-05, 'epoch': 8.68}\n",
            "{'loss': 4.4133, 'learning_rate': 1.1229508196721313e-05, 'epoch': 8.76}\n",
            "{'loss': 4.3848, 'learning_rate': 1.1147540983606557e-05, 'epoch': 8.84}\n",
            "{'loss': 4.4173, 'learning_rate': 1.1065573770491805e-05, 'epoch': 8.92}\n",
            " 45% 549/1220 [2:26:47<2:48:27, 15.06s/it][INFO|trainer.py:2443] 2022-04-28 02:56:11,761 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2445] 2022-04-28 02:56:11,761 >>   Num examples = 219\n",
            "[INFO|trainer.py:2448] 2022-04-28 02:56:11,761 >>   Batch size = 4\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:14,  3.71it/s]\u001b[A\n",
            "  5% 3/55 [00:01<00:19,  2.66it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:22,  2.30it/s]\u001b[A\n",
            "  9% 5/55 [00:02<00:23,  2.14it/s]\u001b[A\n",
            " 11% 6/55 [00:02<00:23,  2.05it/s]\u001b[A\n",
            " 13% 7/55 [00:03<00:23,  2.00it/s]\u001b[A\n",
            " 15% 8/55 [00:03<00:23,  1.96it/s]\u001b[A\n",
            " 16% 9/55 [00:04<00:23,  1.95it/s]\u001b[A\n",
            " 18% 10/55 [00:04<00:23,  1.92it/s]\u001b[A\n",
            " 20% 11/55 [00:05<00:22,  1.91it/s]\u001b[A\n",
            " 22% 12/55 [00:05<00:22,  1.90it/s]\u001b[A\n",
            " 24% 13/55 [00:06<00:22,  1.90it/s]\u001b[A\n",
            " 25% 14/55 [00:06<00:21,  1.90it/s]\u001b[A\n",
            " 27% 15/55 [00:07<00:21,  1.89it/s]\u001b[A\n",
            " 29% 16/55 [00:07<00:20,  1.89it/s]\u001b[A\n",
            " 31% 17/55 [00:08<00:20,  1.90it/s]\u001b[A\n",
            " 33% 18/55 [00:09<00:19,  1.89it/s]\u001b[A\n",
            " 35% 19/55 [00:09<00:18,  1.89it/s]\u001b[A\n",
            " 36% 20/55 [00:10<00:18,  1.89it/s]\u001b[A\n",
            " 38% 21/55 [00:10<00:17,  1.89it/s]\u001b[A\n",
            " 40% 22/55 [00:11<00:17,  1.89it/s]\u001b[A\n",
            " 42% 23/55 [00:11<00:16,  1.89it/s]\u001b[A\n",
            " 44% 24/55 [00:12<00:16,  1.89it/s]\u001b[A\n",
            " 45% 25/55 [00:12<00:15,  1.89it/s]\u001b[A\n",
            " 47% 26/55 [00:13<00:15,  1.90it/s]\u001b[A\n",
            " 49% 27/55 [00:13<00:14,  1.89it/s]\u001b[A\n",
            " 51% 28/55 [00:14<00:14,  1.90it/s]\u001b[A\n",
            " 53% 29/55 [00:14<00:13,  1.89it/s]\u001b[A\n",
            " 55% 30/55 [00:15<00:13,  1.90it/s]\u001b[A\n",
            " 56% 31/55 [00:15<00:12,  1.89it/s]\u001b[A\n",
            " 58% 32/55 [00:16<00:12,  1.90it/s]\u001b[A\n",
            " 60% 33/55 [00:16<00:11,  1.88it/s]\u001b[A\n",
            " 62% 34/55 [00:17<00:11,  1.89it/s]\u001b[A\n",
            " 64% 35/55 [00:17<00:10,  1.89it/s]\u001b[A\n",
            " 65% 36/55 [00:18<00:10,  1.89it/s]\u001b[A\n",
            " 67% 37/55 [00:19<00:09,  1.89it/s]\u001b[A\n",
            " 69% 38/55 [00:19<00:08,  1.89it/s]\u001b[A\n",
            " 71% 39/55 [00:20<00:08,  1.89it/s]\u001b[A\n",
            " 73% 40/55 [00:20<00:07,  1.89it/s]\u001b[A\n",
            " 75% 41/55 [00:21<00:07,  1.89it/s]\u001b[A\n",
            " 76% 42/55 [00:21<00:06,  1.89it/s]\u001b[A\n",
            " 78% 43/55 [00:22<00:06,  1.89it/s]\u001b[A\n",
            " 80% 44/55 [00:22<00:05,  1.89it/s]\u001b[A\n",
            " 82% 45/55 [00:23<00:05,  1.89it/s]\u001b[A\n",
            " 84% 46/55 [00:23<00:04,  1.90it/s]\u001b[A\n",
            " 85% 47/55 [00:24<00:04,  1.89it/s]\u001b[A\n",
            " 87% 48/55 [00:24<00:03,  1.90it/s]\u001b[A\n",
            " 89% 49/55 [00:25<00:03,  1.89it/s]\u001b[A\n",
            " 91% 50/55 [00:25<00:02,  1.90it/s]\u001b[A\n",
            " 93% 51/55 [00:26<00:02,  1.89it/s]\u001b[A\n",
            " 95% 52/55 [00:26<00:01,  1.89it/s]\u001b[A\n",
            " 96% 53/55 [00:27<00:01,  1.89it/s]\u001b[A\n",
            " 98% 54/55 [00:28<00:00,  1.89it/s]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 4.519579887390137, 'eval_accuracy': 0.6210045662100456, 'eval_runtime': 28.9787, 'eval_samples_per_second': 7.557, 'eval_steps_per_second': 1.898, 'epoch': 8.99}\n",
            " 45% 549/1220 [2:27:25<2:48:27, 15.06s/it]\n",
            "100% 55/55 [00:28<00:00,  2.03it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2193] 2022-04-28 02:56:40,741 >> Saving model checkpoint to ./orchid219_vit-huge-patch14-224-in21k/checkpoint-549\n",
            "[INFO|configuration_utils.py:446] 2022-04-28 02:56:40,743 >> Configuration saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-549/config.json\n",
            "[INFO|modeling_utils.py:1468] 2022-04-28 02:56:50,308 >> Model weights saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-549/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-04-28 02:56:50,309 >> Feature extractor saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-549/preprocessor_config.json\n",
            "[INFO|trainer.py:2271] 2022-04-28 02:57:10,527 >> Deleting older checkpoint [orchid219_vit-huge-patch14-224-in21k/checkpoint-427] due to args.save_total_limit\n",
            "{'loss': 4.9582, 'learning_rate': 1.0983606557377052e-05, 'epoch': 9.02}\n",
            "{'loss': 4.3651, 'learning_rate': 1.0901639344262295e-05, 'epoch': 9.1}\n",
            "{'loss': 4.3876, 'learning_rate': 1.0819672131147544e-05, 'epoch': 9.18}\n",
            "{'loss': 4.3662, 'learning_rate': 1.0737704918032787e-05, 'epoch': 9.26}\n",
            "{'loss': 4.3704, 'learning_rate': 1.0655737704918034e-05, 'epoch': 9.34}\n",
            "{'loss': 4.371, 'learning_rate': 1.0573770491803279e-05, 'epoch': 9.42}\n",
            "{'loss': 4.3685, 'learning_rate': 1.0491803278688525e-05, 'epoch': 9.5}\n",
            "{'loss': 4.3182, 'learning_rate': 1.040983606557377e-05, 'epoch': 9.58}\n",
            "{'loss': 4.3165, 'learning_rate': 1.0327868852459017e-05, 'epoch': 9.67}\n",
            "{'loss': 4.3236, 'learning_rate': 1.0245901639344262e-05, 'epoch': 9.75}\n",
            "{'loss': 4.3359, 'learning_rate': 1.0163934426229509e-05, 'epoch': 9.83}\n",
            "{'loss': 4.3318, 'learning_rate': 1.0081967213114754e-05, 'epoch': 9.91}\n",
            "{'loss': 4.3052, 'learning_rate': 1e-05, 'epoch': 9.99}\n",
            " 50% 610/1220 [2:43:12<2:34:46, 15.22s/it][INFO|trainer.py:2443] 2022-04-28 03:12:36,222 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2445] 2022-04-28 03:12:36,222 >>   Num examples = 219\n",
            "[INFO|trainer.py:2448] 2022-04-28 03:12:36,222 >>   Batch size = 4\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:14,  3.72it/s]\u001b[A\n",
            "  5% 3/55 [00:01<00:19,  2.64it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:22,  2.28it/s]\u001b[A\n",
            "  9% 5/55 [00:02<00:23,  2.13it/s]\u001b[A\n",
            " 11% 6/55 [00:02<00:24,  2.02it/s]\u001b[A\n",
            " 13% 7/55 [00:03<00:24,  1.98it/s]\u001b[A\n",
            " 15% 8/55 [00:03<00:24,  1.94it/s]\u001b[A\n",
            " 16% 9/55 [00:04<00:23,  1.92it/s]\u001b[A\n",
            " 18% 10/55 [00:04<00:23,  1.90it/s]\u001b[A\n",
            " 20% 11/55 [00:05<00:23,  1.90it/s]\u001b[A\n",
            " 22% 12/55 [00:05<00:22,  1.88it/s]\u001b[A\n",
            " 24% 13/55 [00:06<00:22,  1.88it/s]\u001b[A\n",
            " 25% 14/55 [00:06<00:21,  1.87it/s]\u001b[A\n",
            " 27% 15/55 [00:07<00:21,  1.88it/s]\u001b[A\n",
            " 29% 16/55 [00:08<00:20,  1.87it/s]\u001b[A\n",
            " 31% 17/55 [00:08<00:20,  1.87it/s]\u001b[A\n",
            " 33% 18/55 [00:09<00:19,  1.87it/s]\u001b[A\n",
            " 35% 19/55 [00:09<00:19,  1.87it/s]\u001b[A\n",
            " 36% 20/55 [00:10<00:18,  1.87it/s]\u001b[A\n",
            " 38% 21/55 [00:10<00:18,  1.87it/s]\u001b[A\n",
            " 40% 22/55 [00:11<00:17,  1.87it/s]\u001b[A\n",
            " 42% 23/55 [00:11<00:17,  1.87it/s]\u001b[A\n",
            " 44% 24/55 [00:12<00:16,  1.87it/s]\u001b[A\n",
            " 45% 25/55 [00:12<00:16,  1.87it/s]\u001b[A\n",
            " 47% 26/55 [00:13<00:15,  1.87it/s]\u001b[A\n",
            " 49% 27/55 [00:13<00:14,  1.87it/s]\u001b[A\n",
            " 51% 28/55 [00:14<00:14,  1.87it/s]\u001b[A\n",
            " 53% 29/55 [00:14<00:13,  1.88it/s]\u001b[A\n",
            " 55% 30/55 [00:15<00:13,  1.87it/s]\u001b[A\n",
            " 56% 31/55 [00:16<00:12,  1.88it/s]\u001b[A\n",
            " 58% 32/55 [00:16<00:12,  1.87it/s]\u001b[A\n",
            " 60% 33/55 [00:17<00:11,  1.87it/s]\u001b[A\n",
            " 62% 34/55 [00:17<00:11,  1.86it/s]\u001b[A\n",
            " 64% 35/55 [00:18<00:10,  1.88it/s]\u001b[A\n",
            " 65% 36/55 [00:18<00:10,  1.87it/s]\u001b[A\n",
            " 67% 37/55 [00:19<00:09,  1.87it/s]\u001b[A\n",
            " 69% 38/55 [00:19<00:09,  1.87it/s]\u001b[A\n",
            " 71% 39/55 [00:20<00:08,  1.87it/s]\u001b[A\n",
            " 73% 40/55 [00:20<00:08,  1.87it/s]\u001b[A\n",
            " 75% 41/55 [00:21<00:07,  1.87it/s]\u001b[A\n",
            " 76% 42/55 [00:21<00:06,  1.87it/s]\u001b[A\n",
            " 78% 43/55 [00:22<00:06,  1.88it/s]\u001b[A\n",
            " 80% 44/55 [00:22<00:05,  1.87it/s]\u001b[A\n",
            " 82% 45/55 [00:23<00:05,  1.88it/s]\u001b[A\n",
            " 84% 46/55 [00:24<00:04,  1.87it/s]\u001b[A\n",
            " 85% 47/55 [00:24<00:04,  1.87it/s]\u001b[A\n",
            " 87% 48/55 [00:25<00:03,  1.87it/s]\u001b[A\n",
            " 89% 49/55 [00:25<00:03,  1.87it/s]\u001b[A\n",
            " 91% 50/55 [00:26<00:02,  1.86it/s]\u001b[A\n",
            " 93% 51/55 [00:26<00:02,  1.87it/s]\u001b[A\n",
            " 95% 52/55 [00:27<00:01,  1.86it/s]\u001b[A\n",
            " 96% 53/55 [00:27<00:01,  1.87it/s]\u001b[A\n",
            " 98% 54/55 [00:28<00:00,  1.87it/s]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 4.448592185974121, 'eval_accuracy': 0.6438356164383562, 'eval_runtime': 29.2868, 'eval_samples_per_second': 7.478, 'eval_steps_per_second': 1.878, 'epoch': 9.99}\n",
            " 50% 610/1220 [2:43:50<2:34:46, 15.22s/it]\n",
            "100% 55/55 [00:28<00:00,  2.01it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2193] 2022-04-28 03:13:05,510 >> Saving model checkpoint to ./orchid219_vit-huge-patch14-224-in21k/checkpoint-610\n",
            "[INFO|configuration_utils.py:446] 2022-04-28 03:13:05,512 >> Configuration saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-610/config.json\n",
            "[INFO|modeling_utils.py:1468] 2022-04-28 03:13:15,050 >> Model weights saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-610/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-04-28 03:13:15,051 >> Feature extractor saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-610/preprocessor_config.json\n",
            "[INFO|trainer.py:2271] 2022-04-28 03:13:35,110 >> Deleting older checkpoint [orchid219_vit-huge-patch14-224-in21k/checkpoint-488] due to args.save_total_limit\n",
            "{'loss': 4.8154, 'learning_rate': 9.918032786885246e-06, 'epoch': 10.08}\n",
            "{'loss': 4.2755, 'learning_rate': 9.836065573770493e-06, 'epoch': 10.16}\n",
            "{'loss': 4.2786, 'learning_rate': 9.754098360655738e-06, 'epoch': 10.24}\n",
            "{'loss': 4.2793, 'learning_rate': 9.672131147540984e-06, 'epoch': 10.32}\n",
            "{'loss': 4.2831, 'learning_rate': 9.59016393442623e-06, 'epoch': 10.41}\n",
            "{'loss': 4.3136, 'learning_rate': 9.508196721311476e-06, 'epoch': 10.49}\n",
            "{'loss': 4.2502, 'learning_rate': 9.426229508196723e-06, 'epoch': 10.57}\n",
            "{'loss': 4.226, 'learning_rate': 9.344262295081968e-06, 'epoch': 10.65}\n",
            "{'loss': 4.2046, 'learning_rate': 9.262295081967215e-06, 'epoch': 10.73}\n",
            "{'loss': 4.2889, 'learning_rate': 9.18032786885246e-06, 'epoch': 10.81}\n",
            "{'loss': 4.2663, 'learning_rate': 9.098360655737707e-06, 'epoch': 10.89}\n",
            "{'loss': 4.259, 'learning_rate': 9.016393442622952e-06, 'epoch': 10.97}\n",
            " 55% 671/1220 [2:59:51<2:19:52, 15.29s/it][INFO|trainer.py:2443] 2022-04-28 03:29:15,381 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2445] 2022-04-28 03:29:15,381 >>   Num examples = 219\n",
            "[INFO|trainer.py:2448] 2022-04-28 03:29:15,381 >>   Batch size = 4\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:14,  3.72it/s]\u001b[A\n",
            "  5% 3/55 [00:01<00:19,  2.63it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:22,  2.28it/s]\u001b[A\n",
            "  9% 5/55 [00:02<00:23,  2.11it/s]\u001b[A\n",
            " 11% 6/55 [00:02<00:24,  2.03it/s]\u001b[A\n",
            " 13% 7/55 [00:03<00:24,  1.97it/s]\u001b[A\n",
            " 15% 8/55 [00:03<00:24,  1.94it/s]\u001b[A\n",
            " 16% 9/55 [00:04<00:23,  1.92it/s]\u001b[A\n",
            " 18% 10/55 [00:04<00:23,  1.90it/s]\u001b[A\n",
            " 20% 11/55 [00:05<00:23,  1.89it/s]\u001b[A\n",
            " 22% 12/55 [00:05<00:22,  1.89it/s]\u001b[A\n",
            " 24% 13/55 [00:06<00:22,  1.88it/s]\u001b[A\n",
            " 25% 14/55 [00:06<00:21,  1.88it/s]\u001b[A\n",
            " 27% 15/55 [00:07<00:21,  1.88it/s]\u001b[A\n",
            " 29% 16/55 [00:08<00:20,  1.87it/s]\u001b[A\n",
            " 31% 17/55 [00:08<00:20,  1.87it/s]\u001b[A\n",
            " 33% 18/55 [00:09<00:19,  1.86it/s]\u001b[A\n",
            " 35% 19/55 [00:09<00:19,  1.87it/s]\u001b[A\n",
            " 36% 20/55 [00:10<00:18,  1.87it/s]\u001b[A\n",
            " 38% 21/55 [00:10<00:18,  1.87it/s]\u001b[A\n",
            " 40% 22/55 [00:11<00:17,  1.87it/s]\u001b[A\n",
            " 42% 23/55 [00:11<00:17,  1.87it/s]\u001b[A\n",
            " 44% 24/55 [00:12<00:16,  1.87it/s]\u001b[A\n",
            " 45% 25/55 [00:12<00:16,  1.87it/s]\u001b[A\n",
            " 47% 26/55 [00:13<00:15,  1.87it/s]\u001b[A\n",
            " 49% 27/55 [00:13<00:15,  1.86it/s]\u001b[A\n",
            " 51% 28/55 [00:14<00:14,  1.87it/s]\u001b[A\n",
            " 53% 29/55 [00:14<00:13,  1.87it/s]\u001b[A\n",
            " 55% 30/55 [00:15<00:13,  1.87it/s]\u001b[A\n",
            " 56% 31/55 [00:16<00:12,  1.87it/s]\u001b[A\n",
            " 58% 32/55 [00:16<00:12,  1.87it/s]\u001b[A\n",
            " 60% 33/55 [00:17<00:11,  1.87it/s]\u001b[A\n",
            " 62% 34/55 [00:17<00:11,  1.87it/s]\u001b[A\n",
            " 64% 35/55 [00:18<00:10,  1.87it/s]\u001b[A\n",
            " 65% 36/55 [00:18<00:10,  1.87it/s]\u001b[A\n",
            " 67% 37/55 [00:19<00:09,  1.87it/s]\u001b[A\n",
            " 69% 38/55 [00:19<00:09,  1.87it/s]\u001b[A\n",
            " 71% 39/55 [00:20<00:08,  1.87it/s]\u001b[A\n",
            " 73% 40/55 [00:20<00:08,  1.87it/s]\u001b[A\n",
            " 75% 41/55 [00:21<00:07,  1.87it/s]\u001b[A\n",
            " 76% 42/55 [00:21<00:06,  1.86it/s]\u001b[A\n",
            " 78% 43/55 [00:22<00:06,  1.87it/s]\u001b[A\n",
            " 80% 44/55 [00:23<00:05,  1.87it/s]\u001b[A\n",
            " 82% 45/55 [00:23<00:05,  1.87it/s]\u001b[A\n",
            " 84% 46/55 [00:24<00:04,  1.87it/s]\u001b[A\n",
            " 85% 47/55 [00:24<00:04,  1.87it/s]\u001b[A\n",
            " 87% 48/55 [00:25<00:03,  1.87it/s]\u001b[A\n",
            " 89% 49/55 [00:25<00:03,  1.87it/s]\u001b[A\n",
            " 91% 50/55 [00:26<00:02,  1.87it/s]\u001b[A\n",
            " 93% 51/55 [00:26<00:02,  1.87it/s]\u001b[A\n",
            " 95% 52/55 [00:27<00:01,  1.87it/s]\u001b[A\n",
            " 96% 53/55 [00:27<00:01,  1.87it/s]\u001b[A\n",
            " 98% 54/55 [00:28<00:00,  1.87it/s]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 4.38859224319458, 'eval_accuracy': 0.6484018264840182, 'eval_runtime': 29.3103, 'eval_samples_per_second': 7.472, 'eval_steps_per_second': 1.876, 'epoch': 10.99}\n",
            " 55% 671/1220 [3:00:29<2:19:52, 15.29s/it]\n",
            "100% 55/55 [00:28<00:00,  2.01it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2193] 2022-04-28 03:29:44,693 >> Saving model checkpoint to ./orchid219_vit-huge-patch14-224-in21k/checkpoint-671\n",
            "[INFO|configuration_utils.py:446] 2022-04-28 03:29:44,694 >> Configuration saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-671/config.json\n",
            "[INFO|modeling_utils.py:1468] 2022-04-28 03:29:54,211 >> Model weights saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-671/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-04-28 03:29:54,212 >> Feature extractor saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-671/preprocessor_config.json\n",
            "[INFO|trainer.py:2271] 2022-04-28 03:30:14,294 >> Deleting older checkpoint [orchid219_vit-huge-patch14-224-in21k/checkpoint-549] due to args.save_total_limit\n",
            "{'loss': 4.7149, 'learning_rate': 8.934426229508197e-06, 'epoch': 11.06}\n",
            "{'loss': 4.2413, 'learning_rate': 8.852459016393443e-06, 'epoch': 11.15}\n",
            "{'loss': 4.2156, 'learning_rate': 8.770491803278688e-06, 'epoch': 11.23}\n",
            "{'loss': 4.2165, 'learning_rate': 8.688524590163935e-06, 'epoch': 11.31}\n",
            "{'loss': 4.1801, 'learning_rate': 8.60655737704918e-06, 'epoch': 11.39}\n",
            "{'loss': 4.1755, 'learning_rate': 8.524590163934427e-06, 'epoch': 11.47}\n",
            "{'loss': 4.2026, 'learning_rate': 8.442622950819674e-06, 'epoch': 11.55}\n",
            "{'loss': 4.1737, 'learning_rate': 8.360655737704919e-06, 'epoch': 11.63}\n",
            "{'loss': 4.1919, 'learning_rate': 8.278688524590165e-06, 'epoch': 11.71}\n",
            "{'loss': 4.2291, 'learning_rate': 8.19672131147541e-06, 'epoch': 11.8}\n",
            "{'loss': 4.1707, 'learning_rate': 8.114754098360657e-06, 'epoch': 11.88}\n",
            "{'loss': 4.2171, 'learning_rate': 8.032786885245902e-06, 'epoch': 11.96}\n",
            " 60% 732/1220 [3:16:29<2:03:58, 15.24s/it][INFO|trainer.py:2443] 2022-04-28 03:45:53,829 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2445] 2022-04-28 03:45:53,829 >>   Num examples = 219\n",
            "[INFO|trainer.py:2448] 2022-04-28 03:45:53,829 >>   Batch size = 4\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:14,  3.76it/s]\u001b[A\n",
            "  5% 3/55 [00:01<00:19,  2.65it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:22,  2.29it/s]\u001b[A\n",
            "  9% 5/55 [00:02<00:23,  2.13it/s]\u001b[A\n",
            " 11% 6/55 [00:02<00:24,  2.03it/s]\u001b[A\n",
            " 13% 7/55 [00:03<00:24,  1.98it/s]\u001b[A\n",
            " 15% 8/55 [00:03<00:24,  1.94it/s]\u001b[A\n",
            " 16% 9/55 [00:04<00:23,  1.92it/s]\u001b[A\n",
            " 18% 10/55 [00:04<00:23,  1.90it/s]\u001b[A\n",
            " 20% 11/55 [00:05<00:23,  1.90it/s]\u001b[A\n",
            " 22% 12/55 [00:05<00:22,  1.89it/s]\u001b[A\n",
            " 24% 13/55 [00:06<00:22,  1.89it/s]\u001b[A\n",
            " 25% 14/55 [00:06<00:21,  1.88it/s]\u001b[A\n",
            " 27% 15/55 [00:07<00:21,  1.88it/s]\u001b[A\n",
            " 29% 16/55 [00:08<00:20,  1.87it/s]\u001b[A\n",
            " 31% 17/55 [00:08<00:20,  1.88it/s]\u001b[A\n",
            " 33% 18/55 [00:09<00:19,  1.87it/s]\u001b[A\n",
            " 35% 19/55 [00:09<00:19,  1.88it/s]\u001b[A\n",
            " 36% 20/55 [00:10<00:18,  1.87it/s]\u001b[A\n",
            " 38% 21/55 [00:10<00:18,  1.88it/s]\u001b[A\n",
            " 40% 22/55 [00:11<00:17,  1.88it/s]\u001b[A\n",
            " 42% 23/55 [00:11<00:17,  1.87it/s]\u001b[A\n",
            " 44% 24/55 [00:12<00:16,  1.87it/s]\u001b[A\n",
            " 45% 25/55 [00:12<00:16,  1.87it/s]\u001b[A\n",
            " 47% 26/55 [00:13<00:15,  1.87it/s]\u001b[A\n",
            " 49% 27/55 [00:13<00:14,  1.88it/s]\u001b[A\n",
            " 51% 28/55 [00:14<00:14,  1.87it/s]\u001b[A\n",
            " 53% 29/55 [00:14<00:13,  1.87it/s]\u001b[A\n",
            " 55% 30/55 [00:15<00:13,  1.87it/s]\u001b[A\n",
            " 56% 31/55 [00:16<00:12,  1.88it/s]\u001b[A\n",
            " 58% 32/55 [00:16<00:12,  1.88it/s]\u001b[A\n",
            " 60% 33/55 [00:17<00:11,  1.87it/s]\u001b[A\n",
            " 62% 34/55 [00:17<00:11,  1.87it/s]\u001b[A\n",
            " 64% 35/55 [00:18<00:10,  1.88it/s]\u001b[A\n",
            " 65% 36/55 [00:18<00:10,  1.88it/s]\u001b[A\n",
            " 67% 37/55 [00:19<00:09,  1.88it/s]\u001b[A\n",
            " 69% 38/55 [00:19<00:09,  1.88it/s]\u001b[A\n",
            " 71% 39/55 [00:20<00:08,  1.88it/s]\u001b[A\n",
            " 73% 40/55 [00:20<00:07,  1.88it/s]\u001b[A\n",
            " 75% 41/55 [00:21<00:07,  1.88it/s]\u001b[A\n",
            " 76% 42/55 [00:21<00:06,  1.88it/s]\u001b[A\n",
            " 78% 43/55 [00:22<00:06,  1.87it/s]\u001b[A\n",
            " 80% 44/55 [00:22<00:05,  1.87it/s]\u001b[A\n",
            " 82% 45/55 [00:23<00:05,  1.87it/s]\u001b[A\n",
            " 84% 46/55 [00:24<00:04,  1.87it/s]\u001b[A\n",
            " 85% 47/55 [00:24<00:04,  1.87it/s]\u001b[A\n",
            " 87% 48/55 [00:25<00:03,  1.87it/s]\u001b[A\n",
            " 89% 49/55 [00:25<00:03,  1.87it/s]\u001b[A\n",
            " 91% 50/55 [00:26<00:02,  1.87it/s]\u001b[A\n",
            " 93% 51/55 [00:26<00:02,  1.87it/s]\u001b[A\n",
            " 95% 52/55 [00:27<00:01,  1.87it/s]\u001b[A\n",
            " 96% 53/55 [00:27<00:01,  1.88it/s]\u001b[A\n",
            " 98% 54/55 [00:28<00:00,  1.88it/s]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 4.336172580718994, 'eval_accuracy': 0.680365296803653, 'eval_runtime': 29.2413, 'eval_samples_per_second': 7.489, 'eval_steps_per_second': 1.881, 'epoch': 11.99}\n",
            " 60% 732/1220 [3:17:07<2:03:58, 15.24s/it]\n",
            "100% 55/55 [00:28<00:00,  2.02it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2193] 2022-04-28 03:46:23,071 >> Saving model checkpoint to ./orchid219_vit-huge-patch14-224-in21k/checkpoint-732\n",
            "[INFO|configuration_utils.py:446] 2022-04-28 03:46:23,073 >> Configuration saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-732/config.json\n",
            "[INFO|modeling_utils.py:1468] 2022-04-28 03:46:32,601 >> Model weights saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-732/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-04-28 03:46:32,602 >> Feature extractor saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-732/preprocessor_config.json\n",
            "[INFO|trainer.py:2271] 2022-04-28 03:46:52,655 >> Deleting older checkpoint [orchid219_vit-huge-patch14-224-in21k/checkpoint-610] due to args.save_total_limit\n",
            "{'loss': 4.6708, 'learning_rate': 7.950819672131147e-06, 'epoch': 12.05}\n",
            "{'loss': 4.1503, 'learning_rate': 7.868852459016394e-06, 'epoch': 12.13}\n",
            "{'loss': 4.1392, 'learning_rate': 7.786885245901639e-06, 'epoch': 12.21}\n",
            "{'loss': 4.1595, 'learning_rate': 7.704918032786886e-06, 'epoch': 12.29}\n",
            "{'loss': 4.1723, 'learning_rate': 7.622950819672132e-06, 'epoch': 12.37}\n",
            "{'loss': 4.1115, 'learning_rate': 7.540983606557377e-06, 'epoch': 12.45}\n",
            "{'loss': 4.1675, 'learning_rate': 7.459016393442624e-06, 'epoch': 12.54}\n",
            "{'loss': 4.1626, 'learning_rate': 7.3770491803278695e-06, 'epoch': 12.62}\n",
            "{'loss': 4.0827, 'learning_rate': 7.295081967213115e-06, 'epoch': 12.7}\n",
            "{'loss': 4.1235, 'learning_rate': 7.213114754098361e-06, 'epoch': 12.78}\n",
            "{'loss': 4.1755, 'learning_rate': 7.131147540983607e-06, 'epoch': 12.86}\n",
            "{'loss': 4.173, 'learning_rate': 7.049180327868853e-06, 'epoch': 12.94}\n",
            " 65% 793/1220 [3:33:07<1:48:35, 15.26s/it][INFO|trainer.py:2443] 2022-04-28 04:02:31,924 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2445] 2022-04-28 04:02:31,924 >>   Num examples = 219\n",
            "[INFO|trainer.py:2448] 2022-04-28 04:02:31,924 >>   Batch size = 4\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:14,  3.70it/s]\u001b[A\n",
            "  5% 3/55 [00:01<00:19,  2.63it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:22,  2.28it/s]\u001b[A\n",
            "  9% 5/55 [00:02<00:23,  2.11it/s]\u001b[A\n",
            " 11% 6/55 [00:02<00:24,  2.03it/s]\u001b[A\n",
            " 13% 7/55 [00:03<00:24,  1.97it/s]\u001b[A\n",
            " 15% 8/55 [00:03<00:24,  1.94it/s]\u001b[A\n",
            " 16% 9/55 [00:04<00:24,  1.91it/s]\u001b[A\n",
            " 18% 10/55 [00:04<00:23,  1.90it/s]\u001b[A\n",
            " 20% 11/55 [00:05<00:23,  1.89it/s]\u001b[A\n",
            " 22% 12/55 [00:05<00:22,  1.89it/s]\u001b[A\n",
            " 24% 13/55 [00:06<00:22,  1.87it/s]\u001b[A\n",
            " 25% 14/55 [00:06<00:21,  1.87it/s]\u001b[A\n",
            " 27% 15/55 [00:07<00:21,  1.87it/s]\u001b[A\n",
            " 29% 16/55 [00:08<00:20,  1.87it/s]\u001b[A\n",
            " 31% 17/55 [00:08<00:20,  1.87it/s]\u001b[A\n",
            " 33% 18/55 [00:09<00:19,  1.87it/s]\u001b[A\n",
            " 35% 19/55 [00:09<00:19,  1.87it/s]\u001b[A\n",
            " 36% 20/55 [00:10<00:18,  1.87it/s]\u001b[A\n",
            " 38% 21/55 [00:10<00:18,  1.87it/s]\u001b[A\n",
            " 40% 22/55 [00:11<00:17,  1.87it/s]\u001b[A\n",
            " 42% 23/55 [00:11<00:17,  1.86it/s]\u001b[A\n",
            " 44% 24/55 [00:12<00:16,  1.87it/s]\u001b[A\n",
            " 45% 25/55 [00:12<00:16,  1.87it/s]\u001b[A\n",
            " 47% 26/55 [00:13<00:15,  1.87it/s]\u001b[A\n",
            " 49% 27/55 [00:13<00:14,  1.87it/s]\u001b[A\n",
            " 51% 28/55 [00:14<00:14,  1.87it/s]\u001b[A\n",
            " 53% 29/55 [00:14<00:13,  1.87it/s]\u001b[A\n",
            " 55% 30/55 [00:15<00:13,  1.88it/s]\u001b[A\n",
            " 56% 31/55 [00:16<00:12,  1.87it/s]\u001b[A\n",
            " 58% 32/55 [00:16<00:12,  1.87it/s]\u001b[A\n",
            " 60% 33/55 [00:17<00:11,  1.86it/s]\u001b[A\n",
            " 62% 34/55 [00:17<00:11,  1.86it/s]\u001b[A\n",
            " 64% 35/55 [00:18<00:10,  1.87it/s]\u001b[A\n",
            " 65% 36/55 [00:18<00:10,  1.86it/s]\u001b[A\n",
            " 67% 37/55 [00:19<00:09,  1.87it/s]\u001b[A\n",
            " 69% 38/55 [00:19<00:09,  1.87it/s]\u001b[A\n",
            " 71% 39/55 [00:20<00:08,  1.87it/s]\u001b[A\n",
            " 73% 40/55 [00:20<00:08,  1.87it/s]\u001b[A\n",
            " 75% 41/55 [00:21<00:07,  1.88it/s]\u001b[A\n",
            " 76% 42/55 [00:21<00:06,  1.87it/s]\u001b[A\n",
            " 78% 43/55 [00:22<00:06,  1.88it/s]\u001b[A\n",
            " 80% 44/55 [00:23<00:05,  1.87it/s]\u001b[A\n",
            " 82% 45/55 [00:23<00:05,  1.87it/s]\u001b[A\n",
            " 84% 46/55 [00:24<00:04,  1.87it/s]\u001b[A\n",
            " 85% 47/55 [00:24<00:04,  1.88it/s]\u001b[A\n",
            " 87% 48/55 [00:25<00:03,  1.87it/s]\u001b[A\n",
            " 89% 49/55 [00:25<00:03,  1.87it/s]\u001b[A\n",
            " 91% 50/55 [00:26<00:02,  1.87it/s]\u001b[A\n",
            " 93% 51/55 [00:26<00:02,  1.88it/s]\u001b[A\n",
            " 95% 52/55 [00:27<00:01,  1.87it/s]\u001b[A\n",
            " 96% 53/55 [00:27<00:01,  1.87it/s]\u001b[A\n",
            " 98% 54/55 [00:28<00:00,  1.87it/s]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 4.292978763580322, 'eval_accuracy': 0.684931506849315, 'eval_runtime': 29.3105, 'eval_samples_per_second': 7.472, 'eval_steps_per_second': 1.876, 'epoch': 12.99}\n",
            " 65% 793/1220 [3:33:46<1:48:35, 15.26s/it]\n",
            "100% 55/55 [00:28<00:00,  2.02it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2193] 2022-04-28 04:03:01,236 >> Saving model checkpoint to ./orchid219_vit-huge-patch14-224-in21k/checkpoint-793\n",
            "[INFO|configuration_utils.py:446] 2022-04-28 04:03:01,237 >> Configuration saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-793/config.json\n",
            "[INFO|modeling_utils.py:1468] 2022-04-28 04:03:10,750 >> Model weights saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-793/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-04-28 04:03:10,751 >> Feature extractor saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-793/preprocessor_config.json\n",
            "[INFO|trainer.py:2271] 2022-04-28 04:03:30,846 >> Deleting older checkpoint [orchid219_vit-huge-patch14-224-in21k/checkpoint-671] due to args.save_total_limit\n",
            "{'loss': 4.6052, 'learning_rate': 6.967213114754099e-06, 'epoch': 13.03}\n",
            "{'loss': 4.1076, 'learning_rate': 6.885245901639345e-06, 'epoch': 13.11}\n",
            "{'loss': 4.1449, 'learning_rate': 6.803278688524591e-06, 'epoch': 13.19}\n",
            "{'loss': 4.0755, 'learning_rate': 6.721311475409837e-06, 'epoch': 13.28}\n",
            "{'loss': 4.0695, 'learning_rate': 6.6393442622950825e-06, 'epoch': 13.36}\n",
            "{'loss': 4.0369, 'learning_rate': 6.5573770491803276e-06, 'epoch': 13.44}\n",
            "{'loss': 4.1105, 'learning_rate': 6.475409836065575e-06, 'epoch': 13.52}\n",
            "{'loss': 4.1268, 'learning_rate': 6.393442622950821e-06, 'epoch': 13.6}\n",
            "{'loss': 4.1272, 'learning_rate': 6.311475409836066e-06, 'epoch': 13.68}\n",
            "{'loss': 4.0862, 'learning_rate': 6.229508196721312e-06, 'epoch': 13.76}\n",
            "{'loss': 4.0982, 'learning_rate': 6.147540983606558e-06, 'epoch': 13.84}\n",
            "{'loss': 4.0766, 'learning_rate': 6.065573770491804e-06, 'epoch': 13.92}\n",
            " 70% 854/1220 [3:49:47<1:32:55, 15.23s/it][INFO|trainer.py:2443] 2022-04-28 04:19:11,170 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2445] 2022-04-28 04:19:11,170 >>   Num examples = 219\n",
            "[INFO|trainer.py:2448] 2022-04-28 04:19:11,170 >>   Batch size = 4\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:14,  3.72it/s]\u001b[A\n",
            "  5% 3/55 [00:01<00:19,  2.63it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:22,  2.28it/s]\u001b[A\n",
            "  9% 5/55 [00:02<00:23,  2.12it/s]\u001b[A\n",
            " 11% 6/55 [00:02<00:24,  2.03it/s]\u001b[A\n",
            " 13% 7/55 [00:03<00:24,  1.98it/s]\u001b[A\n",
            " 15% 8/55 [00:03<00:24,  1.94it/s]\u001b[A\n",
            " 16% 9/55 [00:04<00:23,  1.92it/s]\u001b[A\n",
            " 18% 10/55 [00:04<00:23,  1.91it/s]\u001b[A\n",
            " 20% 11/55 [00:05<00:23,  1.90it/s]\u001b[A\n",
            " 22% 12/55 [00:05<00:22,  1.89it/s]\u001b[A\n",
            " 24% 13/55 [00:06<00:22,  1.89it/s]\u001b[A\n",
            " 25% 14/55 [00:06<00:21,  1.88it/s]\u001b[A\n",
            " 27% 15/55 [00:07<00:21,  1.88it/s]\u001b[A\n",
            " 29% 16/55 [00:08<00:20,  1.88it/s]\u001b[A\n",
            " 31% 17/55 [00:08<00:20,  1.88it/s]\u001b[A\n",
            " 33% 18/55 [00:09<00:19,  1.88it/s]\u001b[A\n",
            " 35% 19/55 [00:09<00:19,  1.88it/s]\u001b[A\n",
            " 36% 20/55 [00:10<00:18,  1.88it/s]\u001b[A\n",
            " 38% 21/55 [00:10<00:18,  1.88it/s]\u001b[A\n",
            " 40% 22/55 [00:11<00:17,  1.87it/s]\u001b[A\n",
            " 42% 23/55 [00:11<00:17,  1.87it/s]\u001b[A\n",
            " 44% 24/55 [00:12<00:16,  1.87it/s]\u001b[A\n",
            " 45% 25/55 [00:12<00:16,  1.87it/s]\u001b[A\n",
            " 47% 26/55 [00:13<00:15,  1.87it/s]\u001b[A\n",
            " 49% 27/55 [00:13<00:14,  1.87it/s]\u001b[A\n",
            " 51% 28/55 [00:14<00:14,  1.87it/s]\u001b[A\n",
            " 53% 29/55 [00:14<00:13,  1.88it/s]\u001b[A\n",
            " 55% 30/55 [00:15<00:13,  1.87it/s]\u001b[A\n",
            " 56% 31/55 [00:16<00:12,  1.88it/s]\u001b[A\n",
            " 58% 32/55 [00:16<00:12,  1.87it/s]\u001b[A\n",
            " 60% 33/55 [00:17<00:11,  1.87it/s]\u001b[A\n",
            " 62% 34/55 [00:17<00:11,  1.87it/s]\u001b[A\n",
            " 64% 35/55 [00:18<00:10,  1.87it/s]\u001b[A\n",
            " 65% 36/55 [00:18<00:10,  1.87it/s]\u001b[A\n",
            " 67% 37/55 [00:19<00:09,  1.87it/s]\u001b[A\n",
            " 69% 38/55 [00:19<00:09,  1.87it/s]\u001b[A\n",
            " 71% 39/55 [00:20<00:08,  1.87it/s]\u001b[A\n",
            " 73% 40/55 [00:20<00:08,  1.87it/s]\u001b[A\n",
            " 75% 41/55 [00:21<00:07,  1.87it/s]\u001b[A\n",
            " 76% 42/55 [00:21<00:06,  1.87it/s]\u001b[A\n",
            " 78% 43/55 [00:22<00:06,  1.87it/s]\u001b[A\n",
            " 80% 44/55 [00:22<00:05,  1.87it/s]\u001b[A\n",
            " 82% 45/55 [00:23<00:05,  1.87it/s]\u001b[A\n",
            " 84% 46/55 [00:24<00:04,  1.87it/s]\u001b[A\n",
            " 85% 47/55 [00:24<00:04,  1.87it/s]\u001b[A\n",
            " 87% 48/55 [00:25<00:03,  1.87it/s]\u001b[A\n",
            " 89% 49/55 [00:25<00:03,  1.87it/s]\u001b[A\n",
            " 91% 50/55 [00:26<00:02,  1.87it/s]\u001b[A\n",
            " 93% 51/55 [00:26<00:02,  1.87it/s]\u001b[A\n",
            " 95% 52/55 [00:27<00:01,  1.87it/s]\u001b[A\n",
            " 96% 53/55 [00:27<00:01,  1.87it/s]\u001b[A\n",
            " 98% 54/55 [00:28<00:00,  1.87it/s]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 4.251832962036133, 'eval_accuracy': 0.684931506849315, 'eval_runtime': 29.2614, 'eval_samples_per_second': 7.484, 'eval_steps_per_second': 1.88, 'epoch': 13.99}\n",
            " 70% 854/1220 [3:50:25<1:32:55, 15.23s/it]\n",
            "100% 55/55 [00:28<00:00,  2.02it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2193] 2022-04-28 04:19:40,432 >> Saving model checkpoint to ./orchid219_vit-huge-patch14-224-in21k/checkpoint-854\n",
            "[INFO|configuration_utils.py:446] 2022-04-28 04:19:40,434 >> Configuration saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-854/config.json\n",
            "[INFO|modeling_utils.py:1468] 2022-04-28 04:19:49,997 >> Model weights saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-854/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-04-28 04:19:49,998 >> Feature extractor saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-854/preprocessor_config.json\n",
            "[INFO|trainer.py:2271] 2022-04-28 04:20:10,082 >> Deleting older checkpoint [orchid219_vit-huge-patch14-224-in21k/checkpoint-732] due to args.save_total_limit\n",
            "{'loss': 4.6017, 'learning_rate': 5.98360655737705e-06, 'epoch': 14.02}\n",
            "{'loss': 4.0968, 'learning_rate': 5.9016393442622956e-06, 'epoch': 14.1}\n",
            "{'loss': 4.0391, 'learning_rate': 5.8196721311475415e-06, 'epoch': 14.18}\n",
            "{'loss': 4.0718, 'learning_rate': 5.737704918032787e-06, 'epoch': 14.26}\n",
            "{'loss': 4.1343, 'learning_rate': 5.655737704918033e-06, 'epoch': 14.34}\n",
            "{'loss': 4.0295, 'learning_rate': 5.573770491803278e-06, 'epoch': 14.42}\n",
            "{'loss': 4.0482, 'learning_rate': 5.491803278688526e-06, 'epoch': 14.5}\n",
            "{'loss': 4.1302, 'learning_rate': 5.409836065573772e-06, 'epoch': 14.58}\n",
            "{'loss': 4.0187, 'learning_rate': 5.327868852459017e-06, 'epoch': 14.67}\n",
            "{'loss': 4.0407, 'learning_rate': 5.245901639344263e-06, 'epoch': 14.75}\n",
            "{'loss': 4.0334, 'learning_rate': 5.163934426229509e-06, 'epoch': 14.83}\n",
            "{'loss': 4.0689, 'learning_rate': 5.0819672131147545e-06, 'epoch': 14.91}\n",
            "{'loss': 4.0142, 'learning_rate': 5e-06, 'epoch': 14.99}\n",
            " 75% 915/1220 [4:06:25<1:17:20, 15.22s/it][INFO|trainer.py:2443] 2022-04-28 04:35:49,947 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2445] 2022-04-28 04:35:49,947 >>   Num examples = 219\n",
            "[INFO|trainer.py:2448] 2022-04-28 04:35:49,947 >>   Batch size = 4\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:14,  3.76it/s]\u001b[A\n",
            "  5% 3/55 [00:01<00:19,  2.65it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:22,  2.29it/s]\u001b[A\n",
            "  9% 5/55 [00:02<00:23,  2.13it/s]\u001b[A\n",
            " 11% 6/55 [00:02<00:24,  2.04it/s]\u001b[A\n",
            " 13% 7/55 [00:03<00:24,  1.98it/s]\u001b[A\n",
            " 15% 8/55 [00:03<00:24,  1.95it/s]\u001b[A\n",
            " 16% 9/55 [00:04<00:24,  1.92it/s]\u001b[A\n",
            " 18% 10/55 [00:04<00:23,  1.90it/s]\u001b[A\n",
            " 20% 11/55 [00:05<00:23,  1.89it/s]\u001b[A\n",
            " 22% 12/55 [00:05<00:22,  1.88it/s]\u001b[A\n",
            " 24% 13/55 [00:06<00:22,  1.88it/s]\u001b[A\n",
            " 25% 14/55 [00:06<00:21,  1.88it/s]\u001b[A\n",
            " 27% 15/55 [00:07<00:21,  1.88it/s]\u001b[A\n",
            " 29% 16/55 [00:08<00:20,  1.88it/s]\u001b[A\n",
            " 31% 17/55 [00:08<00:20,  1.87it/s]\u001b[A\n",
            " 33% 18/55 [00:09<00:19,  1.87it/s]\u001b[A\n",
            " 35% 19/55 [00:09<00:19,  1.87it/s]\u001b[A\n",
            " 36% 20/55 [00:10<00:18,  1.87it/s]\u001b[A\n",
            " 38% 21/55 [00:10<00:18,  1.88it/s]\u001b[A\n",
            " 40% 22/55 [00:11<00:17,  1.87it/s]\u001b[A\n",
            " 42% 23/55 [00:11<00:17,  1.87it/s]\u001b[A\n",
            " 44% 24/55 [00:12<00:16,  1.87it/s]\u001b[A\n",
            " 45% 25/55 [00:12<00:16,  1.87it/s]\u001b[A\n",
            " 47% 26/55 [00:13<00:15,  1.87it/s]\u001b[A\n",
            " 49% 27/55 [00:13<00:14,  1.87it/s]\u001b[A\n",
            " 51% 28/55 [00:14<00:14,  1.87it/s]\u001b[A\n",
            " 53% 29/55 [00:14<00:13,  1.87it/s]\u001b[A\n",
            " 55% 30/55 [00:15<00:13,  1.87it/s]\u001b[A\n",
            " 56% 31/55 [00:16<00:12,  1.87it/s]\u001b[A\n",
            " 58% 32/55 [00:16<00:12,  1.88it/s]\u001b[A\n",
            " 60% 33/55 [00:17<00:11,  1.87it/s]\u001b[A\n",
            " 62% 34/55 [00:17<00:11,  1.87it/s]\u001b[A\n",
            " 64% 35/55 [00:18<00:10,  1.87it/s]\u001b[A\n",
            " 65% 36/55 [00:18<00:10,  1.87it/s]\u001b[A\n",
            " 67% 37/55 [00:19<00:09,  1.87it/s]\u001b[A\n",
            " 69% 38/55 [00:19<00:09,  1.87it/s]\u001b[A\n",
            " 71% 39/55 [00:20<00:08,  1.87it/s]\u001b[A\n",
            " 73% 40/55 [00:20<00:08,  1.87it/s]\u001b[A\n",
            " 75% 41/55 [00:21<00:07,  1.87it/s]\u001b[A\n",
            " 76% 42/55 [00:21<00:06,  1.88it/s]\u001b[A\n",
            " 78% 43/55 [00:22<00:06,  1.87it/s]\u001b[A\n",
            " 80% 44/55 [00:22<00:05,  1.87it/s]\u001b[A\n",
            " 82% 45/55 [00:23<00:05,  1.88it/s]\u001b[A\n",
            " 84% 46/55 [00:24<00:04,  1.87it/s]\u001b[A\n",
            " 85% 47/55 [00:24<00:04,  1.87it/s]\u001b[A\n",
            " 87% 48/55 [00:25<00:03,  1.88it/s]\u001b[A\n",
            " 89% 49/55 [00:25<00:03,  1.87it/s]\u001b[A\n",
            " 91% 50/55 [00:26<00:02,  1.87it/s]\u001b[A\n",
            " 93% 51/55 [00:26<00:02,  1.86it/s]\u001b[A\n",
            " 95% 52/55 [00:27<00:01,  1.87it/s]\u001b[A\n",
            " 96% 53/55 [00:27<00:01,  1.87it/s]\u001b[A\n",
            " 98% 54/55 [00:28<00:00,  1.87it/s]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 4.220093727111816, 'eval_accuracy': 0.684931506849315, 'eval_runtime': 29.2863, 'eval_samples_per_second': 7.478, 'eval_steps_per_second': 1.878, 'epoch': 14.99}\n",
            " 75% 915/1220 [4:07:04<1:17:20, 15.22s/it]\n",
            "100% 55/55 [00:28<00:00,  2.01it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2193] 2022-04-28 04:36:19,234 >> Saving model checkpoint to ./orchid219_vit-huge-patch14-224-in21k/checkpoint-915\n",
            "[INFO|configuration_utils.py:446] 2022-04-28 04:36:19,236 >> Configuration saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-915/config.json\n",
            "[INFO|modeling_utils.py:1468] 2022-04-28 04:36:28,784 >> Model weights saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-915/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-04-28 04:36:28,785 >> Feature extractor saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-915/preprocessor_config.json\n",
            "[INFO|trainer.py:2271] 2022-04-28 04:36:48,879 >> Deleting older checkpoint [orchid219_vit-huge-patch14-224-in21k/checkpoint-793] due to args.save_total_limit\n",
            "{'loss': 4.5056, 'learning_rate': 4.918032786885246e-06, 'epoch': 15.08}\n",
            "{'loss': 4.0281, 'learning_rate': 4.836065573770492e-06, 'epoch': 15.16}\n",
            "{'loss': 4.0313, 'learning_rate': 4.754098360655738e-06, 'epoch': 15.24}\n",
            "{'loss': 3.9953, 'learning_rate': 4.672131147540984e-06, 'epoch': 15.32}\n",
            "{'loss': 3.9953, 'learning_rate': 4.59016393442623e-06, 'epoch': 15.41}\n",
            "{'loss': 4.0619, 'learning_rate': 4.508196721311476e-06, 'epoch': 15.49}\n",
            "{'loss': 4.0118, 'learning_rate': 4.426229508196722e-06, 'epoch': 15.57}\n",
            "{'loss': 3.9984, 'learning_rate': 4.3442622950819676e-06, 'epoch': 15.65}\n",
            "{'loss': 3.9946, 'learning_rate': 4.2622950819672135e-06, 'epoch': 15.73}\n",
            "{'loss': 4.0211, 'learning_rate': 4.180327868852459e-06, 'epoch': 15.81}\n",
            "{'loss': 4.0336, 'learning_rate': 4.098360655737705e-06, 'epoch': 15.89}\n",
            "{'loss': 4.0198, 'learning_rate': 4.016393442622951e-06, 'epoch': 15.97}\n",
            " 80% 976/1220 [4:23:04<1:01:46, 15.19s/it][INFO|trainer.py:2443] 2022-04-28 04:52:28,112 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2445] 2022-04-28 04:52:28,112 >>   Num examples = 219\n",
            "[INFO|trainer.py:2448] 2022-04-28 04:52:28,112 >>   Batch size = 4\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:14,  3.71it/s]\u001b[A\n",
            "  5% 3/55 [00:01<00:19,  2.65it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:22,  2.28it/s]\u001b[A\n",
            "  9% 5/55 [00:02<00:23,  2.13it/s]\u001b[A\n",
            " 11% 6/55 [00:02<00:24,  2.03it/s]\u001b[A\n",
            " 13% 7/55 [00:03<00:24,  1.98it/s]\u001b[A\n",
            " 15% 8/55 [00:03<00:24,  1.94it/s]\u001b[A\n",
            " 16% 9/55 [00:04<00:23,  1.93it/s]\u001b[A\n",
            " 18% 10/55 [00:04<00:23,  1.91it/s]\u001b[A\n",
            " 20% 11/55 [00:05<00:23,  1.90it/s]\u001b[A\n",
            " 22% 12/55 [00:05<00:22,  1.89it/s]\u001b[A\n",
            " 24% 13/55 [00:06<00:22,  1.88it/s]\u001b[A\n",
            " 25% 14/55 [00:06<00:21,  1.88it/s]\u001b[A\n",
            " 27% 15/55 [00:07<00:21,  1.88it/s]\u001b[A\n",
            " 29% 16/55 [00:08<00:20,  1.87it/s]\u001b[A\n",
            " 31% 17/55 [00:08<00:20,  1.88it/s]\u001b[A\n",
            " 33% 18/55 [00:09<00:19,  1.87it/s]\u001b[A\n",
            " 35% 19/55 [00:09<00:19,  1.88it/s]\u001b[A\n",
            " 36% 20/55 [00:10<00:18,  1.88it/s]\u001b[A\n",
            " 38% 21/55 [00:10<00:18,  1.88it/s]\u001b[A\n",
            " 40% 22/55 [00:11<00:17,  1.87it/s]\u001b[A\n",
            " 42% 23/55 [00:11<00:17,  1.87it/s]\u001b[A\n",
            " 44% 24/55 [00:12<00:16,  1.86it/s]\u001b[A\n",
            " 45% 25/55 [00:12<00:15,  1.88it/s]\u001b[A\n",
            " 47% 26/55 [00:13<00:15,  1.87it/s]\u001b[A\n",
            " 49% 27/55 [00:13<00:14,  1.87it/s]\u001b[A\n",
            " 51% 28/55 [00:14<00:14,  1.86it/s]\u001b[A\n",
            " 53% 29/55 [00:14<00:13,  1.87it/s]\u001b[A\n",
            " 55% 30/55 [00:15<00:13,  1.86it/s]\u001b[A\n",
            " 56% 31/55 [00:16<00:12,  1.87it/s]\u001b[A\n",
            " 58% 32/55 [00:16<00:12,  1.87it/s]\u001b[A\n",
            " 60% 33/55 [00:17<00:11,  1.86it/s]\u001b[A\n",
            " 62% 34/55 [00:17<00:11,  1.85it/s]\u001b[A\n",
            " 64% 35/55 [00:18<00:10,  1.87it/s]\u001b[A\n",
            " 65% 36/55 [00:18<00:10,  1.86it/s]\u001b[A\n",
            " 67% 37/55 [00:19<00:09,  1.86it/s]\u001b[A\n",
            " 69% 38/55 [00:19<00:09,  1.86it/s]\u001b[A\n",
            " 71% 39/55 [00:20<00:08,  1.87it/s]\u001b[A\n",
            " 73% 40/55 [00:20<00:08,  1.86it/s]\u001b[A\n",
            " 75% 41/55 [00:21<00:07,  1.87it/s]\u001b[A\n",
            " 76% 42/55 [00:21<00:06,  1.87it/s]\u001b[A\n",
            " 78% 43/55 [00:22<00:06,  1.88it/s]\u001b[A\n",
            " 80% 44/55 [00:22<00:05,  1.87it/s]\u001b[A\n",
            " 82% 45/55 [00:23<00:05,  1.88it/s]\u001b[A\n",
            " 84% 46/55 [00:24<00:04,  1.87it/s]\u001b[A\n",
            " 85% 47/55 [00:24<00:04,  1.88it/s]\u001b[A\n",
            " 87% 48/55 [00:25<00:03,  1.87it/s]\u001b[A\n",
            " 89% 49/55 [00:25<00:03,  1.87it/s]\u001b[A\n",
            " 91% 50/55 [00:26<00:02,  1.87it/s]\u001b[A\n",
            " 93% 51/55 [00:26<00:02,  1.87it/s]\u001b[A\n",
            " 95% 52/55 [00:27<00:01,  1.87it/s]\u001b[A\n",
            " 96% 53/55 [00:27<00:01,  1.88it/s]\u001b[A\n",
            " 98% 54/55 [00:28<00:00,  1.87it/s]\u001b[A\n",
            "                                          \n",
            "\u001b[A{'eval_loss': 4.194068431854248, 'eval_accuracy': 0.6894977168949772, 'eval_runtime': 29.2879, 'eval_samples_per_second': 7.477, 'eval_steps_per_second': 1.878, 'epoch': 15.99}\n",
            " 80% 976/1220 [4:23:42<1:01:46, 15.19s/it]\n",
            "100% 55/55 [00:28<00:00,  2.02it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2193] 2022-04-28 04:52:57,401 >> Saving model checkpoint to ./orchid219_vit-huge-patch14-224-in21k/checkpoint-976\n",
            "[INFO|configuration_utils.py:446] 2022-04-28 04:52:57,403 >> Configuration saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-976/config.json\n",
            "[INFO|modeling_utils.py:1468] 2022-04-28 04:53:06,914 >> Model weights saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-976/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-04-28 04:53:06,914 >> Feature extractor saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-976/preprocessor_config.json\n",
            "[INFO|trainer.py:2271] 2022-04-28 04:53:26,990 >> Deleting older checkpoint [orchid219_vit-huge-patch14-224-in21k/checkpoint-854] due to args.save_total_limit\n",
            "{'loss': 4.5496, 'learning_rate': 3.934426229508197e-06, 'epoch': 16.06}\n",
            "{'loss': 3.9836, 'learning_rate': 3.852459016393443e-06, 'epoch': 16.15}\n",
            "{'loss': 4.0162, 'learning_rate': 3.7704918032786884e-06, 'epoch': 16.23}\n",
            "{'loss': 3.9957, 'learning_rate': 3.6885245901639347e-06, 'epoch': 16.31}\n",
            "{'loss': 3.9826, 'learning_rate': 3.6065573770491806e-06, 'epoch': 16.39}\n",
            "{'loss': 4.0041, 'learning_rate': 3.5245901639344265e-06, 'epoch': 16.47}\n",
            "{'loss': 3.9451, 'learning_rate': 3.4426229508196724e-06, 'epoch': 16.55}\n",
            "{'loss': 3.9785, 'learning_rate': 3.3606557377049183e-06, 'epoch': 16.63}\n",
            "{'loss': 4.007, 'learning_rate': 3.2786885245901638e-06, 'epoch': 16.71}\n",
            "{'loss': 4.0131, 'learning_rate': 3.1967213114754105e-06, 'epoch': 16.8}\n",
            "{'loss': 3.9644, 'learning_rate': 3.114754098360656e-06, 'epoch': 16.88}\n",
            "{'loss': 3.9907, 'learning_rate': 3.032786885245902e-06, 'epoch': 16.96}\n",
            " 85% 1037/1220 [4:39:43<46:22, 15.21s/it][INFO|trainer.py:2443] 2022-04-28 05:09:07,311 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2445] 2022-04-28 05:09:07,312 >>   Num examples = 219\n",
            "[INFO|trainer.py:2448] 2022-04-28 05:09:07,312 >>   Batch size = 4\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:14,  3.72it/s]\u001b[A\n",
            "  5% 3/55 [00:01<00:19,  2.65it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:22,  2.28it/s]\u001b[A\n",
            "  9% 5/55 [00:02<00:23,  2.13it/s]\u001b[A\n",
            " 11% 6/55 [00:02<00:24,  2.02it/s]\u001b[A\n",
            " 13% 7/55 [00:03<00:24,  1.98it/s]\u001b[A\n",
            " 15% 8/55 [00:03<00:24,  1.94it/s]\u001b[A\n",
            " 16% 9/55 [00:04<00:23,  1.92it/s]\u001b[A\n",
            " 18% 10/55 [00:04<00:23,  1.90it/s]\u001b[A\n",
            " 20% 11/55 [00:05<00:23,  1.90it/s]\u001b[A\n",
            " 22% 12/55 [00:05<00:22,  1.89it/s]\u001b[A\n",
            " 24% 13/55 [00:06<00:22,  1.89it/s]\u001b[A\n",
            " 25% 14/55 [00:06<00:21,  1.88it/s]\u001b[A\n",
            " 27% 15/55 [00:07<00:21,  1.88it/s]\u001b[A\n",
            " 29% 16/55 [00:08<00:20,  1.88it/s]\u001b[A\n",
            " 31% 17/55 [00:08<00:20,  1.88it/s]\u001b[A\n",
            " 33% 18/55 [00:09<00:19,  1.87it/s]\u001b[A\n",
            " 35% 19/55 [00:09<00:19,  1.87it/s]\u001b[A\n",
            " 36% 20/55 [00:10<00:18,  1.88it/s]\u001b[A\n",
            " 38% 21/55 [00:10<00:18,  1.87it/s]\u001b[A\n",
            " 40% 22/55 [00:11<00:17,  1.87it/s]\u001b[A\n",
            " 42% 23/55 [00:11<00:17,  1.86it/s]\u001b[A\n",
            " 44% 24/55 [00:12<00:16,  1.87it/s]\u001b[A\n",
            " 45% 25/55 [00:12<00:16,  1.87it/s]\u001b[A\n",
            " 47% 26/55 [00:13<00:15,  1.87it/s]\u001b[A\n",
            " 49% 27/55 [00:13<00:14,  1.87it/s]\u001b[A\n",
            " 51% 28/55 [00:14<00:14,  1.87it/s]\u001b[A\n",
            " 53% 29/55 [00:14<00:13,  1.87it/s]\u001b[A\n",
            " 55% 30/55 [00:15<00:13,  1.87it/s]\u001b[A\n",
            " 56% 31/55 [00:16<00:12,  1.87it/s]\u001b[A\n",
            " 58% 32/55 [00:16<00:12,  1.87it/s]\u001b[A\n",
            " 60% 33/55 [00:17<00:11,  1.87it/s]\u001b[A\n",
            " 62% 34/55 [00:17<00:11,  1.87it/s]\u001b[A\n",
            " 64% 35/55 [00:18<00:10,  1.87it/s]\u001b[A\n",
            " 65% 36/55 [00:18<00:10,  1.87it/s]\u001b[A\n",
            " 67% 37/55 [00:19<00:09,  1.87it/s]\u001b[A\n",
            " 69% 38/55 [00:19<00:09,  1.86it/s]\u001b[A\n",
            " 71% 39/55 [00:20<00:08,  1.87it/s]\u001b[A\n",
            " 73% 40/55 [00:20<00:08,  1.87it/s]\u001b[A\n",
            " 75% 41/55 [00:21<00:07,  1.87it/s]\u001b[A\n",
            " 76% 42/55 [00:21<00:06,  1.87it/s]\u001b[A\n",
            " 78% 43/55 [00:22<00:06,  1.86it/s]\u001b[A\n",
            " 80% 44/55 [00:22<00:05,  1.87it/s]\u001b[A\n",
            " 82% 45/55 [00:23<00:05,  1.87it/s]\u001b[A\n",
            " 84% 46/55 [00:24<00:04,  1.87it/s]\u001b[A\n",
            " 85% 47/55 [00:24<00:04,  1.87it/s]\u001b[A\n",
            " 87% 48/55 [00:25<00:03,  1.87it/s]\u001b[A\n",
            " 89% 49/55 [00:25<00:03,  1.87it/s]\u001b[A\n",
            " 91% 50/55 [00:26<00:02,  1.87it/s]\u001b[A\n",
            " 93% 51/55 [00:26<00:02,  1.87it/s]\u001b[A\n",
            " 95% 52/55 [00:27<00:01,  1.88it/s]\u001b[A\n",
            " 96% 53/55 [00:27<00:01,  1.87it/s]\u001b[A\n",
            " 98% 54/55 [00:28<00:00,  1.88it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 4.173236846923828, 'eval_accuracy': 0.6986301369863014, 'eval_runtime': 29.287, 'eval_samples_per_second': 7.478, 'eval_steps_per_second': 1.878, 'epoch': 16.99}\n",
            " 85% 1037/1220 [4:40:21<46:22, 15.21s/it]\n",
            "100% 55/55 [00:28<00:00,  2.01it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2193] 2022-04-28 05:09:36,600 >> Saving model checkpoint to ./orchid219_vit-huge-patch14-224-in21k/checkpoint-1037\n",
            "[INFO|configuration_utils.py:446] 2022-04-28 05:09:36,601 >> Configuration saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-1037/config.json\n",
            "[INFO|modeling_utils.py:1468] 2022-04-28 05:09:46,121 >> Model weights saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-1037/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-04-28 05:09:46,122 >> Feature extractor saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-1037/preprocessor_config.json\n",
            "[INFO|trainer.py:2271] 2022-04-28 05:10:06,179 >> Deleting older checkpoint [orchid219_vit-huge-patch14-224-in21k/checkpoint-915] due to args.save_total_limit\n",
            "{'loss': 4.4324, 'learning_rate': 2.9508196721311478e-06, 'epoch': 17.05}\n",
            "{'loss': 3.9789, 'learning_rate': 2.8688524590163937e-06, 'epoch': 17.13}\n",
            "{'loss': 3.981, 'learning_rate': 2.786885245901639e-06, 'epoch': 17.21}\n",
            "{'loss': 4.0077, 'learning_rate': 2.704918032786886e-06, 'epoch': 17.29}\n",
            "{'loss': 3.9337, 'learning_rate': 2.6229508196721314e-06, 'epoch': 17.37}\n",
            "{'loss': 3.9924, 'learning_rate': 2.5409836065573773e-06, 'epoch': 17.45}\n",
            "{'loss': 3.8988, 'learning_rate': 2.459016393442623e-06, 'epoch': 17.54}\n",
            "{'loss': 3.9419, 'learning_rate': 2.377049180327869e-06, 'epoch': 17.62}\n",
            "{'loss': 3.9792, 'learning_rate': 2.295081967213115e-06, 'epoch': 17.7}\n",
            "{'loss': 3.979, 'learning_rate': 2.213114754098361e-06, 'epoch': 17.78}\n",
            "{'loss': 3.9809, 'learning_rate': 2.1311475409836067e-06, 'epoch': 17.86}\n",
            "{'loss': 3.9492, 'learning_rate': 2.0491803278688526e-06, 'epoch': 17.94}\n",
            " 90% 1098/1220 [4:56:22<31:03, 15.28s/it][INFO|trainer.py:2443] 2022-04-28 05:25:46,197 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2445] 2022-04-28 05:25:46,197 >>   Num examples = 219\n",
            "[INFO|trainer.py:2448] 2022-04-28 05:25:46,197 >>   Batch size = 4\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:14,  3.69it/s]\u001b[A\n",
            "  5% 3/55 [00:01<00:19,  2.65it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:22,  2.27it/s]\u001b[A\n",
            "  9% 5/55 [00:02<00:23,  2.12it/s]\u001b[A\n",
            " 11% 6/55 [00:02<00:24,  2.02it/s]\u001b[A\n",
            " 13% 7/55 [00:03<00:24,  1.97it/s]\u001b[A\n",
            " 15% 8/55 [00:03<00:24,  1.94it/s]\u001b[A\n",
            " 16% 9/55 [00:04<00:24,  1.91it/s]\u001b[A\n",
            " 18% 10/55 [00:04<00:23,  1.90it/s]\u001b[A\n",
            " 20% 11/55 [00:05<00:23,  1.88it/s]\u001b[A\n",
            " 22% 12/55 [00:05<00:22,  1.89it/s]\u001b[A\n",
            " 24% 13/55 [00:06<00:22,  1.87it/s]\u001b[A\n",
            " 25% 14/55 [00:06<00:21,  1.88it/s]\u001b[A\n",
            " 27% 15/55 [00:07<00:21,  1.88it/s]\u001b[A\n",
            " 29% 16/55 [00:08<00:20,  1.87it/s]\u001b[A\n",
            " 31% 17/55 [00:08<00:20,  1.87it/s]\u001b[A\n",
            " 33% 18/55 [00:09<00:19,  1.86it/s]\u001b[A\n",
            " 35% 19/55 [00:09<00:19,  1.87it/s]\u001b[A\n",
            " 36% 20/55 [00:10<00:18,  1.86it/s]\u001b[A\n",
            " 38% 21/55 [00:10<00:18,  1.87it/s]\u001b[A\n",
            " 40% 22/55 [00:11<00:17,  1.86it/s]\u001b[A\n",
            " 42% 23/55 [00:11<00:17,  1.87it/s]\u001b[A\n",
            " 44% 24/55 [00:12<00:16,  1.86it/s]\u001b[A\n",
            " 45% 25/55 [00:12<00:16,  1.87it/s]\u001b[A\n",
            " 47% 26/55 [00:13<00:15,  1.86it/s]\u001b[A\n",
            " 49% 27/55 [00:13<00:14,  1.87it/s]\u001b[A\n",
            " 51% 28/55 [00:14<00:14,  1.87it/s]\u001b[A\n",
            " 53% 29/55 [00:15<00:13,  1.87it/s]\u001b[A\n",
            " 55% 30/55 [00:15<00:13,  1.87it/s]\u001b[A\n",
            " 56% 31/55 [00:16<00:12,  1.86it/s]\u001b[A\n",
            " 58% 32/55 [00:16<00:12,  1.87it/s]\u001b[A\n",
            " 60% 33/55 [00:17<00:11,  1.86it/s]\u001b[A\n",
            " 62% 34/55 [00:17<00:11,  1.87it/s]\u001b[A\n",
            " 64% 35/55 [00:18<00:10,  1.87it/s]\u001b[A\n",
            " 65% 36/55 [00:18<00:10,  1.87it/s]\u001b[A\n",
            " 67% 37/55 [00:19<00:09,  1.87it/s]\u001b[A\n",
            " 69% 38/55 [00:19<00:09,  1.86it/s]\u001b[A\n",
            " 71% 39/55 [00:20<00:08,  1.87it/s]\u001b[A\n",
            " 73% 40/55 [00:20<00:08,  1.86it/s]\u001b[A\n",
            " 75% 41/55 [00:21<00:07,  1.87it/s]\u001b[A\n",
            " 76% 42/55 [00:21<00:06,  1.87it/s]\u001b[A\n",
            " 78% 43/55 [00:22<00:06,  1.86it/s]\u001b[A\n",
            " 80% 44/55 [00:23<00:05,  1.87it/s]\u001b[A\n",
            " 82% 45/55 [00:23<00:05,  1.87it/s]\u001b[A\n",
            " 84% 46/55 [00:24<00:04,  1.87it/s]\u001b[A\n",
            " 85% 47/55 [00:24<00:04,  1.87it/s]\u001b[A\n",
            " 87% 48/55 [00:25<00:03,  1.87it/s]\u001b[A\n",
            " 89% 49/55 [00:25<00:03,  1.87it/s]\u001b[A\n",
            " 91% 50/55 [00:26<00:02,  1.86it/s]\u001b[A\n",
            " 93% 51/55 [00:26<00:02,  1.87it/s]\u001b[A\n",
            " 95% 52/55 [00:27<00:01,  1.87it/s]\u001b[A\n",
            " 96% 53/55 [00:27<00:01,  1.87it/s]\u001b[A\n",
            " 98% 54/55 [00:28<00:00,  1.87it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 4.158570289611816, 'eval_accuracy': 0.7077625570776256, 'eval_runtime': 29.3517, 'eval_samples_per_second': 7.461, 'eval_steps_per_second': 1.874, 'epoch': 17.99}\n",
            " 90% 1098/1220 [4:57:00<31:03, 15.28s/it]\n",
            "100% 55/55 [00:28<00:00,  2.02it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2193] 2022-04-28 05:26:15,550 >> Saving model checkpoint to ./orchid219_vit-huge-patch14-224-in21k/checkpoint-1098\n",
            "[INFO|configuration_utils.py:446] 2022-04-28 05:26:15,552 >> Configuration saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-1098/config.json\n",
            "[INFO|modeling_utils.py:1468] 2022-04-28 05:26:25,063 >> Model weights saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-1098/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-04-28 05:26:25,064 >> Feature extractor saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-1098/preprocessor_config.json\n",
            "[INFO|trainer.py:2271] 2022-04-28 05:26:45,160 >> Deleting older checkpoint [orchid219_vit-huge-patch14-224-in21k/checkpoint-976] due to args.save_total_limit\n",
            "{'loss': 4.4557, 'learning_rate': 1.9672131147540985e-06, 'epoch': 18.03}\n",
            "{'loss': 3.916, 'learning_rate': 1.8852459016393442e-06, 'epoch': 18.11}\n",
            "{'loss': 3.9714, 'learning_rate': 1.8032786885245903e-06, 'epoch': 18.19}\n",
            "{'loss': 3.9538, 'learning_rate': 1.7213114754098362e-06, 'epoch': 18.28}\n",
            "{'loss': 3.9912, 'learning_rate': 1.6393442622950819e-06, 'epoch': 18.36}\n",
            "{'loss': 3.9232, 'learning_rate': 1.557377049180328e-06, 'epoch': 18.44}\n",
            "{'loss': 3.9911, 'learning_rate': 1.4754098360655739e-06, 'epoch': 18.52}\n",
            "{'loss': 4.0021, 'learning_rate': 1.3934426229508196e-06, 'epoch': 18.6}\n",
            "{'loss': 3.9608, 'learning_rate': 1.3114754098360657e-06, 'epoch': 18.68}\n",
            "{'loss': 3.9331, 'learning_rate': 1.2295081967213116e-06, 'epoch': 18.76}\n",
            "{'loss': 3.9719, 'learning_rate': 1.1475409836065575e-06, 'epoch': 18.84}\n",
            "{'loss': 3.9636, 'learning_rate': 1.0655737704918034e-06, 'epoch': 18.92}\n",
            " 95% 1159/1220 [5:13:02<15:27, 15.21s/it][INFO|trainer.py:2443] 2022-04-28 05:42:26,198 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2445] 2022-04-28 05:42:26,199 >>   Num examples = 219\n",
            "[INFO|trainer.py:2448] 2022-04-28 05:42:26,199 >>   Batch size = 4\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:14,  3.70it/s]\u001b[A\n",
            "  5% 3/55 [00:01<00:19,  2.65it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:22,  2.29it/s]\u001b[A\n",
            "  9% 5/55 [00:02<00:23,  2.13it/s]\u001b[A\n",
            " 11% 6/55 [00:02<00:24,  2.04it/s]\u001b[A\n",
            " 13% 7/55 [00:03<00:24,  1.99it/s]\u001b[A\n",
            " 15% 8/55 [00:03<00:24,  1.94it/s]\u001b[A\n",
            " 16% 9/55 [00:04<00:23,  1.93it/s]\u001b[A\n",
            " 18% 10/55 [00:04<00:23,  1.90it/s]\u001b[A\n",
            " 20% 11/55 [00:05<00:23,  1.89it/s]\u001b[A\n",
            " 22% 12/55 [00:05<00:22,  1.89it/s]\u001b[A\n",
            " 24% 13/55 [00:06<00:22,  1.88it/s]\u001b[A\n",
            " 25% 14/55 [00:06<00:21,  1.88it/s]\u001b[A\n",
            " 27% 15/55 [00:07<00:21,  1.88it/s]\u001b[A\n",
            " 29% 16/55 [00:08<00:20,  1.88it/s]\u001b[A\n",
            " 31% 17/55 [00:08<00:20,  1.88it/s]\u001b[A\n",
            " 33% 18/55 [00:09<00:19,  1.88it/s]\u001b[A\n",
            " 35% 19/55 [00:09<00:19,  1.88it/s]\u001b[A\n",
            " 36% 20/55 [00:10<00:18,  1.88it/s]\u001b[A\n",
            " 38% 21/55 [00:10<00:18,  1.88it/s]\u001b[A\n",
            " 40% 22/55 [00:11<00:17,  1.87it/s]\u001b[A\n",
            " 42% 23/55 [00:11<00:17,  1.87it/s]\u001b[A\n",
            " 44% 24/55 [00:12<00:16,  1.87it/s]\u001b[A\n",
            " 45% 25/55 [00:12<00:16,  1.87it/s]\u001b[A\n",
            " 47% 26/55 [00:13<00:15,  1.87it/s]\u001b[A\n",
            " 49% 27/55 [00:13<00:14,  1.87it/s]\u001b[A\n",
            " 51% 28/55 [00:14<00:14,  1.86it/s]\u001b[A\n",
            " 53% 29/55 [00:14<00:13,  1.88it/s]\u001b[A\n",
            " 55% 30/55 [00:15<00:13,  1.87it/s]\u001b[A\n",
            " 56% 31/55 [00:16<00:12,  1.87it/s]\u001b[A\n",
            " 58% 32/55 [00:16<00:12,  1.87it/s]\u001b[A\n",
            " 60% 33/55 [00:17<00:11,  1.87it/s]\u001b[A\n",
            " 62% 34/55 [00:17<00:11,  1.87it/s]\u001b[A\n",
            " 64% 35/55 [00:18<00:10,  1.87it/s]\u001b[A\n",
            " 65% 36/55 [00:18<00:10,  1.87it/s]\u001b[A\n",
            " 67% 37/55 [00:19<00:09,  1.87it/s]\u001b[A\n",
            " 69% 38/55 [00:19<00:09,  1.87it/s]\u001b[A\n",
            " 71% 39/55 [00:20<00:08,  1.87it/s]\u001b[A\n",
            " 73% 40/55 [00:20<00:08,  1.87it/s]\u001b[A\n",
            " 75% 41/55 [00:21<00:07,  1.88it/s]\u001b[A\n",
            " 76% 42/55 [00:21<00:06,  1.87it/s]\u001b[A\n",
            " 78% 43/55 [00:22<00:06,  1.88it/s]\u001b[A\n",
            " 80% 44/55 [00:22<00:05,  1.88it/s]\u001b[A\n",
            " 82% 45/55 [00:23<00:05,  1.87it/s]\u001b[A\n",
            " 84% 46/55 [00:24<00:04,  1.87it/s]\u001b[A\n",
            " 85% 47/55 [00:24<00:04,  1.87it/s]\u001b[A\n",
            " 87% 48/55 [00:25<00:03,  1.87it/s]\u001b[A\n",
            " 89% 49/55 [00:25<00:03,  1.87it/s]\u001b[A\n",
            " 91% 50/55 [00:26<00:02,  1.87it/s]\u001b[A\n",
            " 93% 51/55 [00:26<00:02,  1.87it/s]\u001b[A\n",
            " 95% 52/55 [00:27<00:01,  1.87it/s]\u001b[A\n",
            " 96% 53/55 [00:27<00:01,  1.86it/s]\u001b[A\n",
            " 98% 54/55 [00:28<00:00,  1.87it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 4.15009880065918, 'eval_accuracy': 0.7077625570776256, 'eval_runtime': 29.2605, 'eval_samples_per_second': 7.484, 'eval_steps_per_second': 1.88, 'epoch': 18.99}\n",
            " 95% 1159/1220 [5:13:40<15:27, 15.21s/it]\n",
            "100% 55/55 [00:28<00:00,  2.01it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2193] 2022-04-28 05:42:55,460 >> Saving model checkpoint to ./orchid219_vit-huge-patch14-224-in21k/checkpoint-1159\n",
            "[INFO|configuration_utils.py:446] 2022-04-28 05:42:55,462 >> Configuration saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-1159/config.json\n",
            "[INFO|modeling_utils.py:1468] 2022-04-28 05:43:04,980 >> Model weights saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-1159/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-04-28 05:43:04,980 >> Feature extractor saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-1159/preprocessor_config.json\n",
            "[INFO|trainer.py:2271] 2022-04-28 05:43:25,068 >> Deleting older checkpoint [orchid219_vit-huge-patch14-224-in21k/checkpoint-1037] due to args.save_total_limit\n",
            "{'loss': 4.4403, 'learning_rate': 9.836065573770493e-07, 'epoch': 19.02}\n",
            "{'loss': 3.9448, 'learning_rate': 9.016393442622952e-07, 'epoch': 19.1}\n",
            "{'loss': 3.9722, 'learning_rate': 8.196721311475409e-07, 'epoch': 19.18}\n",
            "{'loss': 3.9609, 'learning_rate': 7.377049180327869e-07, 'epoch': 19.26}\n",
            "{'loss': 3.957, 'learning_rate': 6.557377049180328e-07, 'epoch': 19.34}\n",
            "{'loss': 3.9455, 'learning_rate': 5.737704918032787e-07, 'epoch': 19.42}\n",
            "{'loss': 3.9418, 'learning_rate': 4.918032786885246e-07, 'epoch': 19.5}\n",
            "{'loss': 3.9262, 'learning_rate': 4.0983606557377047e-07, 'epoch': 19.58}\n",
            "{'loss': 3.9776, 'learning_rate': 3.278688524590164e-07, 'epoch': 19.67}\n",
            "{'loss': 3.914, 'learning_rate': 2.459016393442623e-07, 'epoch': 19.75}\n",
            "{'loss': 3.913, 'learning_rate': 1.639344262295082e-07, 'epoch': 19.83}\n",
            "{'loss': 3.9467, 'learning_rate': 8.19672131147541e-08, 'epoch': 19.91}\n",
            "{'loss': 3.8974, 'learning_rate': 0.0, 'epoch': 19.99}\n",
            "100% 1220/1220 [5:29:40<00:00, 15.17s/it][INFO|trainer.py:2443] 2022-04-28 05:58:55,759 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2445] 2022-04-28 05:58:55,759 >>   Num examples = 219\n",
            "[INFO|trainer.py:2448] 2022-04-28 05:58:55,759 >>   Batch size = 4\n",
            "\n",
            "  0% 0/55 [00:00<?, ?it/s]\u001b[A\n",
            "  4% 2/55 [00:00<00:14,  3.56it/s]\u001b[A\n",
            "  5% 3/55 [00:01<00:19,  2.65it/s]\u001b[A\n",
            "  7% 4/55 [00:01<00:22,  2.26it/s]\u001b[A\n",
            "  9% 5/55 [00:02<00:23,  2.13it/s]\u001b[A\n",
            " 11% 6/55 [00:02<00:24,  2.02it/s]\u001b[A\n",
            " 13% 7/55 [00:03<00:24,  1.99it/s]\u001b[A\n",
            " 15% 8/55 [00:03<00:24,  1.94it/s]\u001b[A\n",
            " 16% 9/55 [00:04<00:23,  1.92it/s]\u001b[A\n",
            " 18% 10/55 [00:04<00:23,  1.90it/s]\u001b[A\n",
            " 20% 11/55 [00:05<00:23,  1.90it/s]\u001b[A\n",
            " 22% 12/55 [00:05<00:22,  1.89it/s]\u001b[A\n",
            " 24% 13/55 [00:06<00:22,  1.89it/s]\u001b[A\n",
            " 25% 14/55 [00:06<00:21,  1.88it/s]\u001b[A\n",
            " 27% 15/55 [00:07<00:21,  1.88it/s]\u001b[A\n",
            " 29% 16/55 [00:08<00:20,  1.87it/s]\u001b[A\n",
            " 31% 17/55 [00:08<00:20,  1.88it/s]\u001b[A\n",
            " 33% 18/55 [00:09<00:19,  1.87it/s]\u001b[A\n",
            " 35% 19/55 [00:09<00:19,  1.88it/s]\u001b[A\n",
            " 36% 20/55 [00:10<00:18,  1.88it/s]\u001b[A\n",
            " 38% 21/55 [00:10<00:18,  1.88it/s]\u001b[A\n",
            " 40% 22/55 [00:11<00:17,  1.87it/s]\u001b[A\n",
            " 42% 23/55 [00:11<00:17,  1.87it/s]\u001b[A\n",
            " 44% 24/55 [00:12<00:16,  1.87it/s]\u001b[A\n",
            " 45% 25/55 [00:12<00:15,  1.88it/s]\u001b[A\n",
            " 47% 26/55 [00:13<00:15,  1.87it/s]\u001b[A\n",
            " 49% 27/55 [00:13<00:14,  1.88it/s]\u001b[A\n",
            " 51% 28/55 [00:14<00:14,  1.88it/s]\u001b[A\n",
            " 53% 29/55 [00:14<00:13,  1.88it/s]\u001b[A\n",
            " 55% 30/55 [00:15<00:13,  1.87it/s]\u001b[A\n",
            " 56% 31/55 [00:16<00:12,  1.88it/s]\u001b[A\n",
            " 58% 32/55 [00:16<00:12,  1.86it/s]\u001b[A\n",
            " 60% 33/55 [00:17<00:11,  1.87it/s]\u001b[A\n",
            " 62% 34/55 [00:17<00:11,  1.87it/s]\u001b[A\n",
            " 64% 35/55 [00:18<00:10,  1.87it/s]\u001b[A\n",
            " 65% 36/55 [00:18<00:10,  1.87it/s]\u001b[A\n",
            " 67% 37/55 [00:19<00:09,  1.88it/s]\u001b[A\n",
            " 69% 38/55 [00:19<00:09,  1.88it/s]\u001b[A\n",
            " 71% 39/55 [00:20<00:08,  1.88it/s]\u001b[A\n",
            " 73% 40/55 [00:20<00:07,  1.88it/s]\u001b[A\n",
            " 75% 41/55 [00:21<00:07,  1.87it/s]\u001b[A\n",
            " 76% 42/55 [00:21<00:06,  1.88it/s]\u001b[A\n",
            " 78% 43/55 [00:22<00:06,  1.88it/s]\u001b[A\n",
            " 80% 44/55 [00:22<00:05,  1.88it/s]\u001b[A\n",
            " 82% 45/55 [00:23<00:05,  1.88it/s]\u001b[A\n",
            " 84% 46/55 [00:24<00:04,  1.88it/s]\u001b[A\n",
            " 85% 47/55 [00:24<00:04,  1.88it/s]\u001b[A\n",
            " 87% 48/55 [00:25<00:03,  1.88it/s]\u001b[A\n",
            " 89% 49/55 [00:25<00:03,  1.88it/s]\u001b[A\n",
            " 91% 50/55 [00:26<00:02,  1.88it/s]\u001b[A\n",
            " 93% 51/55 [00:26<00:02,  1.87it/s]\u001b[A\n",
            " 95% 52/55 [00:27<00:01,  1.88it/s]\u001b[A\n",
            " 96% 53/55 [00:27<00:01,  1.87it/s]\u001b[A\n",
            " 98% 54/55 [00:28<00:00,  1.87it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 4.147315979003906, 'eval_accuracy': 0.7077625570776256, 'eval_runtime': 29.2352, 'eval_samples_per_second': 7.491, 'eval_steps_per_second': 1.881, 'epoch': 19.99}\n",
            "100% 1220/1220 [5:30:09<00:00, 15.17s/it]\n",
            "100% 55/55 [00:28<00:00,  2.01it/s]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:2193] 2022-04-28 05:59:24,995 >> Saving model checkpoint to ./orchid219_vit-huge-patch14-224-in21k/checkpoint-1220\n",
            "[INFO|configuration_utils.py:446] 2022-04-28 05:59:24,997 >> Configuration saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-1220/config.json\n",
            "[INFO|modeling_utils.py:1468] 2022-04-28 05:59:34,507 >> Model weights saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-1220/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-04-28 05:59:34,508 >> Feature extractor saved in ./orchid219_vit-huge-patch14-224-in21k/checkpoint-1220/preprocessor_config.json\n",
            "[INFO|trainer.py:2271] 2022-04-28 05:59:54,582 >> Deleting older checkpoint [orchid219_vit-huge-patch14-224-in21k/checkpoint-1098] due to args.save_total_limit\n",
            "[INFO|trainer.py:1557] 2022-04-28 05:59:54,735 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "[INFO|trainer.py:1566] 2022-04-28 05:59:54,736 >> Loading best model from ./orchid219_vit-huge-patch14-224-in21k/checkpoint-1220 (score: 4.147315979003906).\n",
            "{'train_runtime': 19850.45, 'train_samples_per_second': 1.986, 'train_steps_per_second': 0.061, 'train_loss': 4.488042132580866, 'epoch': 19.99}\n",
            "100% 1220/1220 [5:30:50<00:00, 16.27s/it]\n",
            "[INFO|trainer.py:2193] 2022-04-28 06:00:05,773 >> Saving model checkpoint to ./orchid219_vit-huge-patch14-224-in21k\n",
            "[INFO|configuration_utils.py:446] 2022-04-28 06:00:05,775 >> Configuration saved in ./orchid219_vit-huge-patch14-224-in21k/config.json\n",
            "[INFO|modeling_utils.py:1468] 2022-04-28 06:00:15,491 >> Model weights saved in ./orchid219_vit-huge-patch14-224-in21k/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-04-28 06:00:15,492 >> Feature extractor saved in ./orchid219_vit-huge-patch14-224-in21k/preprocessor_config.json\n",
            "[INFO|trainer.py:2193] 2022-04-28 06:00:15,494 >> Saving model checkpoint to ./orchid219_vit-huge-patch14-224-in21k\n",
            "[INFO|configuration_utils.py:446] 2022-04-28 06:00:15,497 >> Configuration saved in ./orchid219_vit-huge-patch14-224-in21k/config.json\n",
            "[INFO|modeling_utils.py:1468] 2022-04-28 06:00:25,510 >> Model weights saved in ./orchid219_vit-huge-patch14-224-in21k/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-04-28 06:00:25,511 >> Feature extractor saved in ./orchid219_vit-huge-patch14-224-in21k/preprocessor_config.json\n",
            "Several commits (2) will be pushed upstream.\n",
            "04/28/2022 06:01:44 - WARNING - huggingface_hub.repository - Several commits (2) will be pushed upstream.\n",
            "The progress bars may be unreliable.\n",
            "04/28/2022 06:01:44 - WARNING - huggingface_hub.repository - The progress bars may be unreliable.\n",
            "Upload file pytorch_model.bin:   0% 3.33k/2.35G [00:00<?, ?B/s]\n",
            "Upload file pytorch_model.bin:   0% 267k/2.35G [00:01<2:35:53, 270kB/s]\n",
            "Upload file pytorch_model.bin:   1% 20.8M/2.35G [00:17<31:01, 1.34MB/s]\n",
            "Upload file pytorch_model.bin: 100% 2.35G/2.35G [30:57<00:00, 1.37MB/s]To https://huggingface.co/gary109/orchid219_vit-huge-patch14-224-in21k\n",
            "   c6a69ad..c5882cb  main -> main\n",
            "\n",
            "04/28/2022 06:32:51 - WARNING - huggingface_hub.repository - To https://huggingface.co/gary109/orchid219_vit-huge-patch14-224-in21k\n",
            "   c6a69ad..c5882cb  main -> main\n",
            "\n",
            "Upload file pytorch_model.bin: 100% 2.35G/2.35G [31:00<00:00, 1.36MB/s]\n",
            "\n",
            "Upload file runs/Apr28_00-28-34_680580e82b1e/events.out.tfevents.1651105755.680580e82b1e.686.0: 100% 54.3k/54.3k [31:00<00:00, 20.8B/s] \u001b[A\n",
            "Upload file runs/Apr28_00-28-34_680580e82b1e/events.out.tfevents.1651105755.680580e82b1e.686.0: 100% 54.3k/54.3k [31:00<00:00, 28.0B/s]\n",
            "To https://huggingface.co/gary109/orchid219_vit-huge-patch14-224-in21k\n",
            "   c5882cb..de1abdd  main -> main\n",
            "\n",
            "04/28/2022 06:33:00 - WARNING - huggingface_hub.repository - To https://huggingface.co/gary109/orchid219_vit-huge-patch14-224-in21k\n",
            "   c5882cb..de1abdd  main -> main\n",
            "\n",
            "***** train metrics *****\n",
            "  epoch                    =      19.99\n",
            "  train_loss               =      4.488\n",
            "  train_runtime            = 5:30:50.45\n",
            "  train_samples_per_second =      1.986\n",
            "  train_steps_per_second   =      0.061\n",
            "[INFO|trainer.py:2443] 2022-04-28 06:33:03,434 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2445] 2022-04-28 06:33:03,442 >>   Num examples = 219\n",
            "[INFO|trainer.py:2448] 2022-04-28 06:33:03,442 >>   Batch size = 4\n",
            "100% 55/55 [00:24<00:00,  2.25it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =      19.99\n",
            "  eval_accuracy           =     0.7078\n",
            "  eval_loss               =     4.1473\n",
            "  eval_runtime            = 0:00:25.48\n",
            "  eval_samples_per_second =      8.593\n",
            "  eval_steps_per_second   =      2.158\n",
            "[INFO|trainer.py:2193] 2022-04-28 06:33:28,965 >> Saving model checkpoint to ./orchid219_vit-huge-patch14-224-in21k\n",
            "[INFO|configuration_utils.py:446] 2022-04-28 06:33:28,967 >> Configuration saved in ./orchid219_vit-huge-patch14-224-in21k/config.json\n",
            "[INFO|modeling_utils.py:1468] 2022-04-28 06:33:38,846 >> Model weights saved in ./orchid219_vit-huge-patch14-224-in21k/pytorch_model.bin\n",
            "[INFO|feature_extraction_utils.py:351] 2022-04-28 06:33:38,847 >> Feature extractor saved in ./orchid219_vit-huge-patch14-224-in21k/preprocessor_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Others\n",
        "---\n",
        "- google/vit-base-patch16-224\n",
        "- google/vit-base-patch16-384\n",
        "- google/vit-base-patch32-384\n",
        "\n",
        "- google/vit-large-patch16-384\n",
        "- google/vit-large-patch16-224\n",
        "- google/vit-large-patch32-384"
      ],
      "metadata": {
        "id": "wVPViAfE4vc6"
      }
    }
  ]
}