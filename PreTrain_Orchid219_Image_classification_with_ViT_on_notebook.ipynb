{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DJgt_njFcA4R",
    "outputId": "0b7c0eaf-4398-47bf-eafa-5e4746ebe373"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device name NVIDIA Graphics Device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if not torch.cuda.is_available():\n",
    "    raise Exception(\"GPU not availalbe. CPU training will be too slow.\")\n",
    "print(\"device name\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yEXRaZK1lWUd"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "c8eh87Hoee5d"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install git+https://github.com/huggingface/datasets.git\n",
    "!pip install git+https://github.com/huggingface/transformers.git\n",
    "!pip install soundfile\n",
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AK6fnTy7N4my",
    "outputId": "056b849c-73a2-46d5-a3f1-920db5055a64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'transformers' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gDqYGxWwztW0",
    "outputId": "0e82a26b-f0c2-4aca-bcd8-688767cb6f20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "git-lfs is already the newest version (2.3.4-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 86 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "! apt install git-lfs\n",
    "! git config --global user.email \"gary109@gmail.com\"\n",
    "! git config --global user.name \"GARY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.8/site-packages (0.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface_hub) (4.0.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from huggingface_hub) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.8/site-packages (from huggingface_hub) (21.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from huggingface_hub) (5.4.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from huggingface_hub) (2.24.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from huggingface_hub) (4.64.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.9->huggingface_hub) (3.0.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface_hub) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface_hub) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface_hub) (2021.10.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface_hub) (1.25.11)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fLI9ee6CkBQg",
    "outputId": "6d31f40c-ae64-4314-ad70-3f34d55bf0a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "        _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "        _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "        _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "        _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "        To login, `huggingface_hub` now requires a token generated from https://huggingface.co/settings/tokens.\n",
      "        (Deprecated, will be removed in v0.3.0) To login with username and password instead, interrupt with Ctrl+C.\n",
      "        \n",
      "Username: "
     ]
    }
   ],
   "source": [
    "! huggingface-cli login\n",
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CsKJDw6q1rez"
   },
   "outputs": [],
   "source": [
    "!git config --global credential.helper store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "! pip install datasets\n",
    "! pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307,
     "referenced_widgets": [
      "3a5591941ee04ad6b3deb29741372d12",
      "5a6d7fa4035c4471855463d27db9ecde",
      "796a343f14e141d38dc457c80e3613cc",
      "b7e85a6ff68f480f9d3b115387cd661e",
      "071bd6eeccc24393ad0c4ed1904d9b99",
      "8def3f91648e4d10ab0cbd59ecff173c",
      "c4793b3ec6464b299ea54c07aafd78de",
      "818fccc99f4946e1a902ac9df64ddb4a",
      "51723f43395349f4965eba96db467854",
      "a3d510498c984e73a3a46825defab03c",
      "6300c5f2ab3c4d918efb56956a745ae5",
      "8e98e0f6ad9d4ad49a14efa65f1b2fa4",
      "7219374e29594fa9a8562bcb4d3887ce",
      "3cfdffc97dd64e689c13a3203c8715c4",
      "faad642c41a243d8a72f64bd9787f164",
      "5a80f83ce5144729b90fe03006e2b7b3",
      "16613c23fc804509875e9b2c4c46fa3b",
      "8831b701e2884c48856f4a34e7ee2228",
      "9170add919094c98839f6355da93bba3",
      "27dafd3d1b42443883a2a67deb691e97",
      "47a7c2c63c6f465f918e83c873b26a83",
      "9f372ce861b4404d878a2384ff100630",
      "6adca3444c844b71a097a94107693eb5",
      "c682bf0dd540477ab1c8fcfb67103b0f",
      "232f450fc1084b368e735e8bdabcb315",
      "c65ee8f3bc55478db07bdedd56b62fc1",
      "d76650ba429c4d28b322310b1b54f785",
      "c34c41b447ac40559d143824c9937dcd",
      "e6e25053f13549eaafc69292a015002a",
      "2b8a4c42e77c4719a7a76f10e4bf6480",
      "e4a237479d5448bb877680f28f26657f",
      "4bcc75560cd24440a03c774991e3d1c0",
      "b58eeebdb4eb4f02b66ea0e1119625e0",
      "799b4d0bcd8642839302114793ed5cb9",
      "d6faa36675944bdc931b9a40689d1333",
      "8bf216fd14d14371bb07547f6853ca6b",
      "f2579b225d3e410a8182d4b63774d00c",
      "ad987281505843b6a0c99864c1ed18d7",
      "d7d7c72243bf4a62bc134e5516107b30",
      "e93605c035234f05ab37334aaf097f2b",
      "9a211590713340ffa2afd8448b289516",
      "a992a4256f514aceae51b60c016450dd",
      "cb70106d26d241c8ada4d671bfa382a2",
      "a76d622b57e24861ad46d939cba47330"
     ]
    },
    "id": "BDNRJpgbkBTg",
    "outputId": "b0908df1-d5be-4347-af91-d78305d745c8"
   },
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "# dataset = load_dataset(\"gary109/orchid219\")\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u6_ypCvRkBdI",
    "outputId": "8980aea8-23ee-42be-cebd-48dbbde08c01"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# ! pip install accelerate deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "la1eQWgLkBgI",
    "outputId": "f3db0bc3-c449-4857-a916-6efa7661b668"
   },
   "outputs": [],
   "source": [
    "# ! accelerate config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oRFVukSv0Gvq",
    "outputId": "036f5ad1-387b-4853-f953-dc98045070c3"
   },
   "outputs": [],
   "source": [
    "# ! accelerate test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7E5Kms3u0Gx6",
    "outputId": "ad9d2c4e-6998-41d8-a88c-4d990786c5a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/orchid219_classification-main/transformers/examples/pytorch/image-pretraining\n"
     ]
    }
   ],
   "source": [
    "%cd /home/orchid219_classification-main/transformers/examples/pytorch/image-pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tNMZWv7q0G02",
    "outputId": "4246abce-d108-4349-b085-3244fde0406d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-04-30 02:05:01,487] [WARNING] [partition_parameters.py:53:<module>] unable to find torch.distributed._all_gather_base. will fall back to torch.distributed.all_gather which will result in suboptimal performance. please consider upgrading your pytorch installation.\n",
      "04/30/2022 02:05:02 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "04/30/2022 02:05:02 - INFO - __main__ - Training/evaluation parameters CustomTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "base_learning_rate=0.00015,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.EPOCH,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=False,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=orchid219_pretrain_vit-base-patch16-224-in21k-mae,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "label_names=['pixel_values'],\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./orchid219_pretrain_vit-base-patch16-224-in21k-mae/runs/Apr30_02-05-02_a8kddhgary109-1651282177194-lbxqg,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.COSINE,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=loss,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=10.0,\n",
      "optim=OptimizerNames.ADAMW_HF,\n",
      "output_dir=./orchid219_pretrain_vit-base-patch16-224-in21k-mae,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=True,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=False,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./orchid219_pretrain_vit-base-patch16-224-in21k-mae,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.EPOCH,\n",
      "save_total_limit=3,\n",
      "seed=1337,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.05,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.05,\n",
      "xpu_backend=None,\n",
      ")\n",
      "04/30/2022 02:05:06 - WARNING - datasets.builder - Using custom data configuration gary109--orchid219-3e706e0e971b6e4d\n",
      "04/30/2022 02:05:06 - WARNING - datasets.builder - Reusing dataset parquet (/root/.cache/huggingface/datasets/parquet/gary109--orchid219-3e706e0e971b6e4d/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 606.95it/s]\n",
      "[INFO|configuration_utils.py:659] 2022-04-30 02:05:07,177 >> loading configuration file https://huggingface.co/google/vit-base-patch16-224-in21k/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/7bba26dd36a6ff9f6a9b19436dec361727bea03ec70fbfa82b70628109163eaa.92995a56e2eabab0c686015c4ad8275b4f9cbd858ed228f6a08936f2c31667e7\n",
      "[WARNING|configuration_utils.py:528] 2022-04-30 02:05:07,177 >> You are using a model of type vit to instantiate a model of type vit_mae. This is not supported for all configurations of models and can yield errors.\n",
      "[INFO|configuration_utils.py:704] 2022-04-30 02:05:07,178 >> Model config ViTMAEConfig {\n",
      "  \"_name_or_path\": \"google/vit-base-patch16-224-in21k\",\n",
      "  \"architectures\": [\n",
      "    \"ViTModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"decoder_hidden_size\": 512,\n",
      "  \"decoder_intermediate_size\": 2048,\n",
      "  \"decoder_num_attention_heads\": 16,\n",
      "  \"decoder_num_hidden_layers\": 8,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"mask_ratio\": 0.75,\n",
      "  \"model_type\": \"vit_mae\",\n",
      "  \"norm_pix_loss\": false,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": true,\n",
      "  \"transformers_version\": \"4.19.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|feature_extraction_utils.py:464] 2022-04-30 02:05:08,104 >> loading feature extractor configuration file https://huggingface.co/google/vit-base-patch16-224-in21k/resolve/main/preprocessor_config.json from cache at /root/.cache/huggingface/transformers/7c7f3e780b30eeeacd3962294e5154788caa6d9aa555ed6d5c2f0d2c485eba18.c322cbf30b69973d5aae6c0866f5cba198b5fe51a2fe259d2a506827ec6274bc\n",
      "[INFO|feature_extraction_utils.py:501] 2022-04-30 02:05:08,105 >> Feature extractor ViTFeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"feature_extractor_type\": \"ViTFeatureExtractor\",\n",
      "  \"image_mean\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"image_std\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"resample\": 2,\n",
      "  \"size\": 224\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:1880] 2022-04-30 02:05:09,137 >> loading weights file https://huggingface.co/google/vit-base-patch16-224-in21k/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/d01bfc4a52063e6f2cc1bc7063192e012043a7c6d8e75981bb6afbb9dc911001.e4710baf72bd00d091aab2ae692d487c057734cf044ba421696823447b95521e\n",
      "[WARNING|modeling_utils.py:2181] 2022-04-30 02:05:09,775 >> Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTMAEForPreTraining: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTMAEForPreTraining from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTMAEForPreTraining from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:2192] 2022-04-30 02:05:09,775 >> Some weights of ViTMAEForPreTraining were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['decoder.decoder_layers.0.attention.attention.query.weight', 'decoder.decoder_layers.1.intermediate.dense.bias', 'decoder.decoder_layers.7.attention.output.dense.weight', 'decoder.decoder_layers.2.layernorm_before.bias', 'decoder.decoder_layers.7.output.dense.bias', 'decoder.decoder_layers.0.attention.attention.value.bias', 'decoder.decoder_layers.7.layernorm_after.weight', 'decoder.decoder_layers.2.attention.output.dense.bias', 'decoder.decoder_layers.1.attention.attention.key.weight', 'decoder.decoder_layers.7.attention.output.dense.bias', 'decoder.decoder_layers.7.intermediate.dense.weight', 'decoder.decoder_layers.1.layernorm_before.bias', 'decoder.decoder_layers.6.layernorm_after.weight', 'decoder.decoder_layers.7.layernorm_before.bias', 'decoder.decoder_layers.3.attention.attention.value.weight', 'decoder.decoder_layers.3.attention.attention.query.weight', 'decoder.decoder_layers.0.attention.attention.key.bias', 'decoder.decoder_layers.3.layernorm_after.bias', 'decoder.decoder_layers.0.attention.output.dense.bias', 'decoder.decoder_pos_embed', 'decoder.decoder_layers.5.attention.attention.key.bias', 'decoder.decoder_layers.2.layernorm_after.weight', 'decoder.decoder_layers.6.attention.attention.query.weight', 'decoder.decoder_norm.bias', 'decoder.decoder_layers.6.layernorm_before.bias', 'decoder.decoder_layers.1.attention.output.dense.bias', 'decoder.decoder_layers.0.layernorm_after.bias', 'decoder.decoder_layers.1.layernorm_after.weight', 'decoder.decoder_layers.6.output.dense.weight', 'decoder.decoder_layers.3.attention.output.dense.weight', 'decoder.decoder_layers.4.output.dense.bias', 'decoder.decoder_layers.7.attention.attention.value.weight', 'decoder.decoder_layers.1.attention.attention.value.bias', 'decoder.decoder_layers.6.intermediate.dense.weight', 'decoder.decoder_layers.6.attention.attention.query.bias', 'decoder.decoder_layers.2.attention.attention.value.weight', 'decoder.decoder_layers.0.intermediate.dense.weight', 'decoder.decoder_layers.4.attention.attention.query.bias', 'decoder.decoder_layers.5.layernorm_after.weight', 'decoder.decoder_layers.1.layernorm_before.weight', 'decoder.decoder_layers.7.attention.attention.query.weight', 'decoder.decoder_layers.3.attention.attention.value.bias', 'decoder.decoder_layers.4.layernorm_before.weight', 'decoder.decoder_layers.1.attention.attention.query.bias', 'decoder.decoder_layers.0.layernorm_before.bias', 'decoder.decoder_layers.0.layernorm_after.weight', 'decoder.decoder_layers.4.attention.attention.key.bias', 'decoder.decoder_layers.4.layernorm_after.weight', 'decoder.decoder_layers.6.attention.output.dense.weight', 'decoder.decoder_layers.0.attention.output.dense.weight', 'decoder.decoder_layers.1.output.dense.bias', 'decoder.decoder_layers.5.attention.attention.query.bias', 'decoder.decoder_layers.6.attention.output.dense.bias', 'decoder.decoder_layers.4.attention.output.dense.bias', 'decoder.decoder_layers.2.attention.attention.query.bias', 'decoder.decoder_layers.4.attention.attention.value.weight', 'decoder.decoder_layers.3.output.dense.bias', 'decoder.decoder_pred.bias', 'decoder.decoder_layers.5.attention.attention.value.weight', 'decoder.decoder_layers.1.layernorm_after.bias', 'decoder.decoder_layers.3.intermediate.dense.bias', 'decoder.decoder_layers.3.intermediate.dense.weight', 'decoder.decoder_layers.0.layernorm_before.weight', 'decoder.decoder_layers.1.output.dense.weight', 'decoder.decoder_layers.2.attention.output.dense.weight', 'decoder.decoder_layers.4.output.dense.weight', 'decoder.decoder_layers.6.attention.attention.value.weight', 'decoder.decoder_layers.5.attention.output.dense.bias', 'decoder.decoder_layers.4.attention.attention.key.weight', 'decoder.decoder_layers.2.attention.attention.key.bias', 'decoder.decoder_layers.4.intermediate.dense.bias', 'decoder.decoder_layers.1.attention.output.dense.weight', 'decoder.decoder_layers.7.attention.attention.key.bias', 'decoder.decoder_layers.0.attention.attention.query.bias', 'decoder.decoder_layers.2.output.dense.bias', 'decoder.decoder_layers.2.layernorm_after.bias', 'decoder.decoder_layers.1.intermediate.dense.weight', 'decoder.decoder_layers.5.layernorm_before.bias', 'decoder.decoder_layers.6.attention.attention.value.bias', 'decoder.decoder_layers.2.attention.attention.key.weight', 'decoder.decoder_layers.7.output.dense.weight', 'decoder.decoder_layers.0.output.dense.weight', 'decoder.decoder_layers.0.attention.attention.key.weight', 'decoder.decoder_layers.3.layernorm_after.weight', 'decoder.decoder_layers.5.attention.attention.query.weight', 'decoder.decoder_layers.4.attention.attention.value.bias', 'decoder.decoder_layers.7.layernorm_after.bias', 'decoder.decoder_layers.7.attention.attention.value.bias', 'decoder.decoder_layers.4.attention.output.dense.weight', 'decoder.decoder_layers.5.layernorm_before.weight', 'decoder.decoder_layers.6.output.dense.bias', 'decoder.decoder_layers.5.layernorm_after.bias', 'decoder.mask_token', 'decoder.decoder_layers.2.attention.attention.query.weight', 'decoder.decoder_layers.5.intermediate.dense.weight', 'decoder.decoder_layers.3.attention.attention.key.bias', 'decoder.decoder_layers.4.layernorm_after.bias', 'decoder.decoder_layers.0.intermediate.dense.bias', 'decoder.decoder_layers.6.attention.attention.key.bias', 'decoder.decoder_layers.3.attention.attention.query.bias', 'decoder.decoder_layers.5.attention.output.dense.weight', 'decoder.decoder_layers.7.layernorm_before.weight', 'decoder.decoder_layers.6.layernorm_after.bias', 'decoder.decoder_layers.5.output.dense.weight', 'decoder.decoder_layers.7.intermediate.dense.bias', 'decoder.decoder_layers.4.attention.attention.query.weight', 'decoder.decoder_layers.1.attention.attention.key.bias', 'decoder.decoder_layers.7.attention.attention.query.bias', 'decoder.decoder_layers.6.intermediate.dense.bias', 'decoder.decoder_layers.0.attention.attention.value.weight', 'decoder.decoder_layers.6.attention.attention.key.weight', 'decoder.decoder_layers.5.attention.attention.value.bias', 'decoder.decoder_embed.bias', 'decoder.decoder_layers.2.intermediate.dense.weight', 'decoder.decoder_layers.3.output.dense.weight', 'decoder.decoder_layers.2.attention.attention.value.bias', 'decoder.decoder_layers.1.attention.attention.value.weight', 'decoder.decoder_layers.4.layernorm_before.bias', 'decoder.decoder_layers.5.intermediate.dense.bias', 'decoder.decoder_layers.3.layernorm_before.weight', 'decoder.decoder_pred.weight', 'decoder.decoder_layers.7.attention.attention.key.weight', 'decoder.decoder_layers.5.output.dense.bias', 'decoder.decoder_norm.weight', 'decoder.decoder_layers.3.layernorm_before.bias', 'decoder.decoder_embed.weight', 'decoder.decoder_layers.2.layernorm_before.weight', 'decoder.decoder_layers.0.output.dense.bias', 'decoder.decoder_layers.3.attention.output.dense.bias', 'decoder.decoder_layers.4.intermediate.dense.weight', 'decoder.decoder_layers.2.output.dense.weight', 'decoder.decoder_layers.6.layernorm_before.weight', 'decoder.decoder_layers.5.attention.attention.key.weight', 'decoder.decoder_layers.3.attention.attention.key.weight', 'decoder.decoder_layers.2.intermediate.dense.bias', 'decoder.decoder_layers.1.attention.attention.query.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Cloning https://huggingface.co/gary109/orchid219_pretrain_vit-base-patch16-224-in21k-mae into local empty directory.\n",
      "04/30/2022 02:05:16 - WARNING - huggingface_hub.repository - Cloning https://huggingface.co/gary109/orchid219_pretrain_vit-base-patch16-224-in21k-mae into local empty directory.\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:1317] 2022-04-30 02:05:23,749 >> ***** Running training *****\n",
      "[INFO|trainer.py:1318] 2022-04-30 02:05:23,749 >>   Num examples = 1971\n",
      "[INFO|trainer.py:1319] 2022-04-30 02:05:23,749 >>   Num Epochs = 10\n",
      "[INFO|trainer.py:1320] 2022-04-30 02:05:23,749 >>   Instantaneous batch size per device = 8\n",
      "[INFO|trainer.py:1321] 2022-04-30 02:05:23,749 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:1322] 2022-04-30 02:05:23,749 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1323] 2022-04-30 02:05:23,749 >>   Total optimization steps = 2470\n",
      "{'loss': 1.1986, 'learning_rate': 3.7802419354838703e-07, 'epoch': 0.04}        \n",
      "{'loss': 1.1865, 'learning_rate': 7.560483870967741e-07, 'epoch': 0.08}         \n",
      "{'loss': 1.1618, 'learning_rate': 1.1340725806451612e-06, 'epoch': 0.12}        \n",
      "{'loss': 1.1262, 'learning_rate': 1.5120967741935481e-06, 'epoch': 0.16}        \n",
      "{'loss': 1.0932, 'learning_rate': 1.8901209677419353e-06, 'epoch': 0.2}         \n",
      "{'loss': 1.0474, 'learning_rate': 2.2681451612903224e-06, 'epoch': 0.24}        \n",
      "{'loss': 1.0022, 'learning_rate': 2.6461693548387098e-06, 'epoch': 0.28}        \n",
      "{'loss': 0.9739, 'learning_rate': 3.0241935483870963e-06, 'epoch': 0.32}        \n",
      "{'loss': 0.9641, 'learning_rate': 3.4022177419354836e-06, 'epoch': 0.36}        \n",
      "{'loss': 0.931, 'learning_rate': 3.7802419354838705e-06, 'epoch': 0.4}          \n",
      "{'loss': 0.9243, 'learning_rate': 4.1582661290322575e-06, 'epoch': 0.45}        \n",
      "{'loss': 0.915, 'learning_rate': 4.536290322580645e-06, 'epoch': 0.49}          \n",
      "{'loss': 0.9257, 'learning_rate': 4.687424347169135e-06, 'epoch': 0.53}         \n",
      "{'loss': 0.9104, 'learning_rate': 4.686962042000381e-06, 'epoch': 0.57}         \n",
      "{'loss': 0.8941, 'learning_rate': 4.6860795438150455e-06, 'epoch': 0.61}        \n",
      "{'loss': 0.8862, 'learning_rate': 4.684777010865806e-06, 'epoch': 0.65}         \n",
      "{'loss': 0.8799, 'learning_rate': 4.683054676727447e-06, 'epoch': 0.69}         \n",
      "{'loss': 0.8834, 'learning_rate': 4.6809128502549774e-06, 'epoch': 0.73}        \n",
      "{'loss': 0.8749, 'learning_rate': 4.6783519155282455e-06, 'epoch': 0.77}        \n",
      "{'loss': 0.8752, 'learning_rate': 4.675372331783065e-06, 'epoch': 0.81}         \n",
      "{'loss': 0.8736, 'learning_rate': 4.671974633328863e-06, 'epoch': 0.85}         \n",
      "{'loss': 0.8979, 'learning_rate': 4.668159429452864e-06, 'epoch': 0.89}         \n",
      "{'loss': 0.9158, 'learning_rate': 4.6639274043108325e-06, 'epoch': 0.93}        \n",
      "{'loss': 0.847, 'learning_rate': 4.659279316804387e-06, 'epoch': 0.97}          \n",
      " 10%|███▉                                    | 246/2470 [00:32<04:52,  7.60it/s][INFO|trainer.py:2443] 2022-04-30 02:05:56,386 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2445] 2022-04-30 02:05:56,386 >>   Num examples = 219\n",
      "[INFO|trainer.py:2448] 2022-04-30 02:05:56,386 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|██████▎                                     | 4/28 [00:00<00:00, 31.11it/s]\u001b[A\n",
      " 29%|████████████▌                               | 8/28 [00:00<00:00, 24.24it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 11/28 [00:00<00:00, 22.48it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 14/28 [00:00<00:00, 22.64it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 17/28 [00:00<00:00, 22.11it/s]\u001b[A\n",
      " 71%|██████████████████████████████▋            | 20/28 [00:00<00:00, 21.32it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 23/28 [00:01<00:00, 21.57it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.877303421497345, 'eval_runtime': 1.2903, 'eval_samples_per_second': 169.727, 'eval_steps_per_second': 21.7, 'epoch': 1.0}\n",
      " 10%|████                                    | 247/2470 [00:33<04:52,  7.60it/s]\n",
      "100%|███████████████████████████████████████████| 28/28 [00:01<00:00, 21.06it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2193] 2022-04-30 02:05:57,679 >> Saving model checkpoint to ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-247\n",
      "[INFO|configuration_utils.py:446] 2022-04-30 02:05:57,698 >> Configuration saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-247/config.json\n",
      "[INFO|modeling_utils.py:1469] 2022-04-30 02:06:03,528 >> Model weights saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-247/pytorch_model.bin\n",
      "[INFO|feature_extraction_utils.py:351] 2022-04-30 02:06:03,546 >> Feature extractor saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-247/preprocessor_config.json\n",
      "[INFO|feature_extraction_utils.py:351] 2022-04-30 02:06:25,418 >> Feature extractor saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/preprocessor_config.json\n",
      "{'loss': 0.8692, 'learning_rate': 4.654216000444911e-06, 'epoch': 1.01}         \n",
      "{'loss': 0.8558, 'learning_rate': 4.648738363204083e-06, 'epoch': 1.05}         \n",
      "{'loss': 0.8637, 'learning_rate': 4.642847387351061e-06, 'epoch': 1.09}         \n",
      "{'loss': 0.8761, 'learning_rate': 4.636544129276333e-06, 'epoch': 1.13}         \n",
      "{'loss': 0.8696, 'learning_rate': 4.6298297193022875e-06, 'epoch': 1.17}        \n",
      "{'loss': 0.8693, 'learning_rate': 4.622705361480509e-06, 'epoch': 1.21}         \n",
      "{'loss': 0.8417, 'learning_rate': 4.615172333375876e-06, 'epoch': 1.26}         \n",
      "{'loss': 0.8797, 'learning_rate': 4.607231985837456e-06, 'epoch': 1.3}          \n",
      "{'loss': 0.8658, 'learning_rate': 4.598885742756271e-06, 'epoch': 1.34}         \n",
      "{'loss': 0.8812, 'learning_rate': 4.590135100809953e-06, 'epoch': 1.38}         \n",
      "{'loss': 0.8287, 'learning_rate': 4.580981629194366e-06, 'epoch': 1.42}         \n",
      "{'loss': 0.8524, 'learning_rate': 4.5714269693422e-06, 'epoch': 1.46}           \n",
      "{'loss': 0.8315, 'learning_rate': 4.561472834628632e-06, 'epoch': 1.5}          \n",
      "{'loss': 0.8574, 'learning_rate': 4.551121010064074e-06, 'epoch': 1.54}         \n",
      "{'loss': 0.8583, 'learning_rate': 4.540373351974079e-06, 'epoch': 1.58}         \n",
      "{'loss': 0.8719, 'learning_rate': 4.529231787666458e-06, 'epoch': 1.62}         \n",
      "{'loss': 0.8845, 'learning_rate': 4.517698315085674e-06, 'epoch': 1.66}         \n",
      "{'loss': 0.8391, 'learning_rate': 4.50577500245455e-06, 'epoch': 1.7}           \n",
      "{'loss': 0.8523, 'learning_rate': 4.493463987903405e-06, 'epoch': 1.74}         \n",
      "{'loss': 0.8234, 'learning_rate': 4.480767479086623e-06, 'epoch': 1.78}         \n",
      "{'loss': 0.8206, 'learning_rate': 4.467687752786777e-06, 'epoch': 1.82}         \n",
      "{'loss': 0.8146, 'learning_rate': 4.454227154506342e-06, 'epoch': 1.86}         \n",
      "{'loss': 0.8572, 'learning_rate': 4.4403880980471015e-06, 'epoch': 1.9}         \n",
      "{'loss': 0.8123, 'learning_rate': 4.4261730650772825e-06, 'epoch': 1.94}        \n",
      "{'loss': 0.8031, 'learning_rate': 4.411584604686544e-06, 'epoch': 1.98}         \n",
      " 20%|███████▉                                | 493/2470 [01:47<04:14,  7.76it/s][INFO|trainer.py:2443] 2022-04-30 02:07:11,070 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2445] 2022-04-30 02:07:11,070 >>   Num examples = 219\n",
      "[INFO|trainer.py:2448] 2022-04-30 02:07:11,070 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|██████▎                                     | 4/28 [00:00<00:00, 37.22it/s]\u001b[A\n",
      " 29%|████████████▌                               | 8/28 [00:00<00:00, 30.15it/s]\u001b[A\n",
      " 43%|██████████████████▍                        | 12/28 [00:00<00:00, 26.45it/s]\u001b[A\n",
      " 54%|███████████████████████                    | 15/28 [00:00<00:00, 25.52it/s]\u001b[A\n",
      " 64%|███████████████████████████▋               | 18/28 [00:00<00:00, 24.18it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 21/28 [00:00<00:00, 24.38it/s]\u001b[A\n",
      " 86%|████████████████████████████████████▊      | 24/28 [00:00<00:00, 24.31it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.8134457468986511, 'eval_runtime': 1.1295, 'eval_samples_per_second': 193.897, 'eval_steps_per_second': 24.791, 'epoch': 2.0}\n",
      " 20%|████████                                | 494/2470 [01:48<04:14,  7.76it/s]\n",
      "100%|███████████████████████████████████████████| 28/28 [00:01<00:00, 24.54it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2193] 2022-04-30 02:07:12,202 >> Saving model checkpoint to ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-494\n",
      "[INFO|configuration_utils.py:446] 2022-04-30 02:07:12,220 >> Configuration saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-494/config.json\n",
      "[INFO|modeling_utils.py:1469] 2022-04-30 02:07:18,080 >> Model weights saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-494/pytorch_model.bin\n",
      "[INFO|feature_extraction_utils.py:351] 2022-04-30 02:07:18,097 >> Feature extractor saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-494/preprocessor_config.json\n",
      "{'loss': 0.8074, 'learning_rate': 4.396625332928861e-06, 'epoch': 2.02}         \n",
      "{'loss': 0.8076, 'learning_rate': 4.38129793235341e-06, 'epoch': 2.06}          \n",
      "{'loss': 0.8072, 'learning_rate': 4.365605151523514e-06, 'epoch': 2.11}         \n",
      "{'loss': 0.7786, 'learning_rate': 4.34954980452377e-06, 'epoch': 2.15}          \n",
      "{'loss': 0.8029, 'learning_rate': 4.333134770455417e-06, 'epoch': 2.19}         \n",
      "{'loss': 0.7611, 'learning_rate': 4.31636299292004e-06, 'epoch': 2.23}          \n",
      "{'loss': 0.8117, 'learning_rate': 4.299237479491716e-06, 'epoch': 2.27}         \n",
      "{'loss': 0.7545, 'learning_rate': 4.281761301177686e-06, 'epoch': 2.31}         \n",
      "{'loss': 0.8044, 'learning_rate': 4.26393759186765e-06, 'epoch': 2.35}          \n",
      "{'loss': 0.8173, 'learning_rate': 4.245769547771789e-06, 'epoch': 2.39}         \n",
      "{'loss': 0.8186, 'learning_rate': 4.227260426847605e-06, 'epoch': 2.43}         \n",
      "{'loss': 0.7728, 'learning_rate': 4.208413548215697e-06, 'epoch': 2.47}         \n",
      "{'loss': 0.7874, 'learning_rate': 4.189232291564562e-06, 'epoch': 2.51}         \n",
      "{'loss': 0.7531, 'learning_rate': 4.16972009654454e-06, 'epoch': 2.55}          \n",
      "{'loss': 0.8144, 'learning_rate': 4.149880462150999e-06, 'epoch': 2.59}         \n",
      "{'loss': 0.776, 'learning_rate': 4.1297169460968894e-06, 'epoch': 2.63}         \n",
      "{'loss': 0.7886, 'learning_rate': 4.109233164174757e-06, 'epoch': 2.67}         \n",
      "{'loss': 0.7934, 'learning_rate': 4.088432789608349e-06, 'epoch': 2.71}         \n",
      "{'loss': 0.779, 'learning_rate': 4.067319552393917e-06, 'epoch': 2.75}          \n",
      "{'loss': 0.7733, 'learning_rate': 4.045897238631342e-06, 'epoch': 2.79}         \n",
      "{'loss': 0.7505, 'learning_rate': 4.024169689845201e-06, 'epoch': 2.83}         \n",
      "{'loss': 0.7745, 'learning_rate': 4.002140802295882e-06, 'epoch': 2.87}         \n",
      "{'loss': 0.7561, 'learning_rate': 3.979814526280904e-06, 'epoch': 2.91}         \n",
      "{'loss': 0.7973, 'learning_rate': 3.957194865426527e-06, 'epoch': 2.96}         \n",
      "{'loss': 0.8078, 'learning_rate': 3.934285875969815e-06, 'epoch': 3.0}          \n",
      " 30%|███████████▉                            | 740/2470 [02:38<03:44,  7.72it/s][INFO|trainer.py:2443] 2022-04-30 02:08:02,288 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2445] 2022-04-30 02:08:02,289 >>   Num examples = 219\n",
      "[INFO|trainer.py:2448] 2022-04-30 02:08:02,289 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|██████▎                                     | 4/28 [00:00<00:00, 36.94it/s]\u001b[A\n",
      " 29%|████████████▌                               | 8/28 [00:00<00:00, 26.43it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 11/28 [00:00<00:00, 25.40it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 14/28 [00:00<00:00, 25.99it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 17/28 [00:00<00:00, 24.96it/s]\u001b[A\n",
      " 71%|██████████████████████████████▋            | 20/28 [00:00<00:00, 24.25it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 23/28 [00:00<00:00, 24.55it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7665088176727295, 'eval_runtime': 1.129, 'eval_samples_per_second': 193.976, 'eval_steps_per_second': 24.801, 'epoch': 3.0}\n",
      " 30%|████████████                            | 741/2470 [02:39<03:44,  7.72it/s]\n",
      "100%|███████████████████████████████████████████| 28/28 [00:01<00:00, 24.32it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2193] 2022-04-30 02:08:03,420 >> Saving model checkpoint to ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-741\n",
      "[INFO|configuration_utils.py:446] 2022-04-30 02:08:03,437 >> Configuration saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-741/config.json\n",
      "[INFO|modeling_utils.py:1469] 2022-04-30 02:08:09,120 >> Model weights saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-741/pytorch_model.bin\n",
      "[INFO|feature_extraction_utils.py:351] 2022-04-30 02:08:09,155 >> Feature extractor saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-741/preprocessor_config.json\n",
      "{'loss': 0.7631, 'learning_rate': 3.911091666031249e-06, 'epoch': 3.04}         \n",
      "{'loss': 0.7946, 'learning_rate': 3.887616394878054e-06, 'epoch': 3.08}         \n",
      "{'loss': 0.7613, 'learning_rate': 3.863864272178334e-06, 'epoch': 3.12}         \n",
      "{'loss': 0.8099, 'learning_rate': 3.83983955724619e-06, 'epoch': 3.16}          \n",
      "{'loss': 0.7652, 'learning_rate': 3.8155465582779164e-06, 'epoch': 3.2}         \n",
      "{'loss': 0.7802, 'learning_rate': 3.7909896315794467e-06, 'epoch': 3.24}        \n",
      "{'loss': 0.7687, 'learning_rate': 3.7661731807851595e-06, 'epoch': 3.28}        \n",
      "{'loss': 0.7782, 'learning_rate': 3.741101656068207e-06, 'epoch': 3.32}         \n",
      "{'loss': 0.7475, 'learning_rate': 3.715779553342496e-06, 'epoch': 3.36}         \n",
      "{'loss': 0.7521, 'learning_rate': 3.690211413456458e-06, 'epoch': 3.4}          \n",
      "{'loss': 0.7458, 'learning_rate': 3.664401821378775e-06, 'epoch': 3.44}         \n",
      "{'loss': 0.7504, 'learning_rate': 3.638355405376185e-06, 'epoch': 3.48}         \n",
      "{'loss': 0.7629, 'learning_rate': 3.6120768361835228e-06, 'epoch': 3.52}        \n",
      "{'loss': 0.7652, 'learning_rate': 3.585570826166149e-06, 'epoch': 3.56}         \n",
      "{'loss': 0.7701, 'learning_rate': 3.5588421284749132e-06, 'epoch': 3.6}         \n",
      "{'loss': 0.7455, 'learning_rate': 3.5318955361938006e-06, 'epoch': 3.64}        \n",
      "{'loss': 0.8017, 'learning_rate': 3.5047358814804186e-06, 'epoch': 3.68}        \n",
      "{'loss': 0.7775, 'learning_rate': 3.4773680346994813e-06, 'epoch': 3.72}        \n",
      "{'loss': 0.7504, 'learning_rate': 3.4497969035494337e-06, 'epoch': 3.77}        \n",
      "{'loss': 0.7849, 'learning_rate': 3.4220274321823874e-06, 'epoch': 3.81}        \n",
      "{'loss': 0.767, 'learning_rate': 3.3940646003175215e-06, 'epoch': 3.85}         \n",
      "{'loss': 0.7964, 'learning_rate': 3.3659134223480975e-06, 'epoch': 3.89}        \n",
      "{'loss': 0.7795, 'learning_rate': 3.337578946442261e-06, 'epoch': 3.93}         \n",
      "{'loss': 0.7716, 'learning_rate': 3.3090662536377892e-06, 'epoch': 3.97}        \n",
      " 40%|███████████████▉                        | 987/2470 [03:29<03:17,  7.50it/s][INFO|trainer.py:2443] 2022-04-30 02:08:52,907 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2445] 2022-04-30 02:08:52,907 >>   Num examples = 219\n",
      "[INFO|trainer.py:2448] 2022-04-30 02:08:52,907 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|██████▎                                     | 4/28 [00:00<00:00, 38.04it/s]\u001b[A\n",
      " 29%|████████████▌                               | 8/28 [00:00<00:00, 28.70it/s]\u001b[A\n",
      " 43%|██████████████████▍                        | 12/28 [00:00<00:00, 26.84it/s]\u001b[A\n",
      " 54%|███████████████████████                    | 15/28 [00:00<00:00, 25.74it/s]\u001b[A\n",
      " 64%|███████████████████████████▋               | 18/28 [00:00<00:00, 25.77it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 21/28 [00:00<00:00, 25.09it/s]\u001b[A\n",
      " 86%|████████████████████████████████████▊      | 24/28 [00:00<00:00, 25.06it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7705405354499817, 'eval_runtime': 1.1224, 'eval_samples_per_second': 195.116, 'eval_steps_per_second': 24.946, 'epoch': 4.0}\n",
      " 40%|████████████████                        | 988/2470 [03:30<03:17,  7.50it/s]\n",
      "100%|███████████████████████████████████████████| 28/28 [00:01<00:00, 23.81it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2193] 2022-04-30 02:08:54,031 >> Saving model checkpoint to ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-988\n",
      "[INFO|configuration_utils.py:446] 2022-04-30 02:08:54,048 >> Configuration saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-988/config.json\n",
      "[INFO|modeling_utils.py:1469] 2022-04-30 02:09:00,199 >> Model weights saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-988/pytorch_model.bin\n",
      "[INFO|feature_extraction_utils.py:351] 2022-04-30 02:09:00,217 >> Feature extractor saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-988/preprocessor_config.json\n",
      "[INFO|trainer.py:2271] 2022-04-30 02:09:12,134 >> Deleting older checkpoint [orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-247] due to args.save_total_limit\n",
      "{'loss': 0.7881, 'learning_rate': 3.2803804569309394e-06, 'epoch': 4.01}        \n",
      "{'loss': 0.7543, 'learning_rate': 3.2515267003595684e-06, 'epoch': 4.05}        \n",
      "{'loss': 0.7848, 'learning_rate': 3.222510158080686e-06, 'epoch': 4.09}         \n",
      "{'loss': 0.75, 'learning_rate': 3.1933360334426083e-06, 'epoch': 4.13}          \n",
      "{'loss': 0.7713, 'learning_rate': 3.1640095580518717e-06, 'epoch': 4.17}        \n",
      "{'loss': 0.7789, 'learning_rate': 3.134535990835087e-06, 'epoch': 4.21}         \n",
      "{'loss': 0.7601, 'learning_rate': 3.104920617095887e-06, 'epoch': 4.25}         \n",
      "{'loss': 0.7475, 'learning_rate': 3.0751687475671475e-06, 'epoch': 4.29}        \n",
      "{'loss': 0.7295, 'learning_rate': 3.0452857174586515e-06, 'epoch': 4.33}        \n",
      "{'loss': 0.7538, 'learning_rate': 3.015276885500354e-06, 'epoch': 4.37}         \n",
      "{'loss': 0.799, 'learning_rate': 2.9851476329814444e-06, 'epoch': 4.41}         \n",
      "{'loss': 0.7508, 'learning_rate': 2.954903362785346e-06, 'epoch': 4.45}         \n",
      "{'loss': 0.7836, 'learning_rate': 2.9245494984208592e-06, 'epoch': 4.49}        \n",
      "{'loss': 0.7591, 'learning_rate': 2.894091483049594e-06, 'epoch': 4.53}         \n",
      "{'loss': 0.7847, 'learning_rate': 2.8635347785098845e-06, 'epoch': 4.57}        \n",
      "{'loss': 0.7541, 'learning_rate': 2.8328848643373556e-06, 'epoch': 4.62}        \n",
      "{'loss': 0.7551, 'learning_rate': 2.802147236782309e-06, 'epoch': 4.66}         \n",
      "{'loss': 0.7331, 'learning_rate': 2.7713274078241178e-06, 'epoch': 4.7}         \n",
      "{'loss': 0.7737, 'learning_rate': 2.740430904182802e-06, 'epoch': 4.74}         \n",
      "{'loss': 0.7497, 'learning_rate': 2.7094632663279542e-06, 'epoch': 4.78}        \n",
      "{'loss': 0.7972, 'learning_rate': 2.678430047485202e-06, 'epoch': 4.82}         \n",
      "{'loss': 0.7104, 'learning_rate': 2.647336812640389e-06, 'epoch': 4.86}         \n",
      "{'loss': 0.7215, 'learning_rate': 2.6161891375416377e-06, 'epoch': 4.9}         \n",
      "{'loss': 0.7025, 'learning_rate': 2.5849926076994885e-06, 'epoch': 4.94}        \n",
      "{'loss': 0.7408, 'learning_rate': 2.5537528173852868e-06, 'epoch': 4.98}        \n",
      " 50%|███████████████████▍                   | 1234/2470 [04:20<02:47,  7.36it/s][INFO|trainer.py:2443] 2022-04-30 02:09:44,531 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2445] 2022-04-30 02:09:44,531 >>   Num examples = 219\n",
      "[INFO|trainer.py:2448] 2022-04-30 02:09:44,531 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|██████▎                                     | 4/28 [00:00<00:00, 29.92it/s]\u001b[A\n",
      " 25%|███████████                                 | 7/28 [00:00<00:00, 25.62it/s]\u001b[A\n",
      " 36%|███████████████▎                           | 10/28 [00:00<00:00, 23.98it/s]\u001b[A\n",
      " 46%|███████████████████▉                       | 13/28 [00:00<00:00, 22.13it/s]\u001b[A\n",
      " 57%|████████████████████████▌                  | 16/28 [00:00<00:00, 21.88it/s]\u001b[A\n",
      " 68%|█████████████████████████████▏             | 19/28 [00:00<00:00, 20.93it/s]\u001b[A\n",
      " 79%|█████████████████████████████████▊         | 22/28 [00:00<00:00, 21.24it/s]\u001b[A\n",
      " 89%|██████████████████████████████████████▍    | 25/28 [00:01<00:00, 20.65it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7381681203842163, 'eval_runtime': 1.3182, 'eval_samples_per_second': 166.133, 'eval_steps_per_second': 21.241, 'epoch': 5.0}\n",
      " 50%|███████████████████▌                   | 1235/2470 [04:22<02:47,  7.36it/s]\n",
      "100%|███████████████████████████████████████████| 28/28 [00:01<00:00, 21.31it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2193] 2022-04-30 02:09:45,851 >> Saving model checkpoint to ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-1235\n",
      "[INFO|configuration_utils.py:446] 2022-04-30 02:09:45,867 >> Configuration saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-1235/config.json\n",
      "[INFO|modeling_utils.py:1469] 2022-04-30 02:09:51,865 >> Model weights saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-1235/pytorch_model.bin\n",
      "[INFO|feature_extraction_utils.py:351] 2022-04-30 02:09:51,882 >> Feature extractor saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-1235/preprocessor_config.json\n",
      "[INFO|trainer.py:2271] 2022-04-30 02:10:03,620 >> Deleting older checkpoint [orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-494] due to args.save_total_limit\n",
      "{'loss': 0.7631, 'learning_rate': 2.522475368627997e-06, 'epoch': 5.02}         \n",
      "{'loss': 0.7726, 'learning_rate': 2.4911658702096276e-06, 'epoch': 5.06}        \n",
      "{'loss': 0.7311, 'learning_rate': 2.459829936659445e-06, 'epoch': 5.1}          \n",
      "{'loss': 0.7462, 'learning_rate': 2.4284731872471587e-06, 'epoch': 5.14}        \n",
      "{'loss': 0.7259, 'learning_rate': 2.3971012449752472e-06, 'epoch': 5.18}        \n",
      "{'loss': 0.7091, 'learning_rate': 2.3657197355706298e-06, 'epoch': 5.22}        \n",
      "{'loss': 0.7528, 'learning_rate': 2.3343342864758367e-06, 'epoch': 5.26}        \n",
      "{'loss': 0.7139, 'learning_rate': 2.3029505258398757e-06, 'epoch': 5.3}         \n",
      "{'loss': 0.7365, 'learning_rate': 2.271574081508976e-06, 'epoch': 5.34}         \n",
      "{'loss': 0.776, 'learning_rate': 2.24021058001738e-06, 'epoch': 5.38}           \n",
      "{'loss': 0.7176, 'learning_rate': 2.2088656455783765e-06, 'epoch': 5.43}        \n",
      "{'loss': 0.7463, 'learning_rate': 2.1775448990757424e-06, 'epoch': 5.47}        \n",
      "{'loss': 0.7619, 'learning_rate': 2.1462539570557918e-06, 'epoch': 5.51}        \n",
      "{'loss': 0.7276, 'learning_rate': 2.1149984307201924e-06, 'epoch': 5.55}        \n",
      "{'loss': 0.7335, 'learning_rate': 2.0837839249197473e-06, 'epoch': 5.59}        \n",
      "{'loss': 0.7473, 'learning_rate': 2.052616037149313e-06, 'epoch': 5.63}         \n",
      "{'loss': 0.7457, 'learning_rate': 2.0215003565440383e-06, 'epoch': 5.67}        \n",
      "{'loss': 0.7537, 'learning_rate': 1.9904424628770977e-06, 'epoch': 5.71}        \n",
      "{'loss': 0.7351, 'learning_rate': 1.9594479255591103e-06, 'epoch': 5.75}        \n",
      "{'loss': 0.6939, 'learning_rate': 1.928522302639412e-06, 'epoch': 5.79}         \n",
      "{'loss': 0.7475, 'learning_rate': 1.8976711398093653e-06, 'epoch': 5.83}        \n",
      "{'loss': 0.7128, 'learning_rate': 1.8668999694078898e-06, 'epoch': 5.87}        \n",
      "{'loss': 0.7504, 'learning_rate': 1.836214309429381e-06, 'epoch': 5.91}         \n",
      "{'loss': 0.6971, 'learning_rate': 1.8056196625342034e-06, 'epoch': 5.95}        \n",
      "{'loss': 0.7813, 'learning_rate': 1.7751215150619378e-06, 'epoch': 5.99}        \n",
      " 60%|███████████████████████▍               | 1481/2470 [05:12<02:13,  7.43it/s][INFO|trainer.py:2443] 2022-04-30 02:10:36,057 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2445] 2022-04-30 02:10:36,057 >>   Num examples = 219\n",
      "[INFO|trainer.py:2448] 2022-04-30 02:10:36,057 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|██████▎                                     | 4/28 [00:00<00:00, 34.66it/s]\u001b[A\n",
      " 29%|████████████▌                               | 8/28 [00:00<00:00, 29.68it/s]\u001b[A\n",
      " 43%|██████████████████▍                        | 12/28 [00:00<00:00, 26.25it/s]\u001b[A\n",
      " 54%|███████████████████████                    | 15/28 [00:00<00:00, 25.53it/s]\u001b[A\n",
      " 64%|███████████████████████████▋               | 18/28 [00:00<00:00, 25.48it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 21/28 [00:00<00:00, 24.64it/s]\u001b[A\n",
      " 86%|████████████████████████████████████▊      | 24/28 [00:00<00:00, 24.55it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7307007908821106, 'eval_runtime': 1.1148, 'eval_samples_per_second': 196.456, 'eval_steps_per_second': 25.118, 'epoch': 6.0}\n",
      " 60%|███████████████████████▍               | 1482/2470 [05:13<02:12,  7.43it/s]\n",
      "100%|███████████████████████████████████████████| 28/28 [00:01<00:00, 24.78it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2193] 2022-04-30 02:10:37,175 >> Saving model checkpoint to ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-1482\n",
      "[INFO|configuration_utils.py:446] 2022-04-30 02:10:37,195 >> Configuration saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-1482/config.json\n",
      "[INFO|modeling_utils.py:1469] 2022-04-30 02:10:42,846 >> Model weights saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-1482/pytorch_model.bin\n",
      "[INFO|feature_extraction_utils.py:351] 2022-04-30 02:10:42,862 >> Feature extractor saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-1482/preprocessor_config.json\n",
      "[INFO|trainer.py:2271] 2022-04-30 02:10:54,625 >> Deleting older checkpoint [orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-741] due to args.save_total_limit\n",
      "{'loss': 0.734, 'learning_rate': 1.7447253360475482e-06, 'epoch': 6.03}         \n",
      "{'loss': 0.7561, 'learning_rate': 1.7144365762406575e-06, 'epoch': 6.07}        \n",
      "{'loss': 0.7262, 'learning_rate': 1.6842606671280969e-06, 'epoch': 6.11}        \n",
      "{'loss': 0.7148, 'learning_rate': 1.6542030199599166e-06, 'epoch': 6.15}        \n",
      "{'loss': 0.7361, 'learning_rate': 1.624269024779019e-06, 'epoch': 6.19}         \n",
      "{'loss': 0.7118, 'learning_rate': 1.5944640494545963e-06, 'epoch': 6.23}        \n",
      "{'loss': 0.7311, 'learning_rate': 1.5647934387195479e-06, 'epoch': 6.28}        \n",
      "{'loss': 0.7516, 'learning_rate': 1.5352625132120437e-06, 'epoch': 6.32}        \n",
      "{'loss': 0.7377, 'learning_rate': 1.5058765685214053e-06, 'epoch': 6.36}        \n",
      "{'loss': 0.7547, 'learning_rate': 1.4766408742384872e-06, 'epoch': 6.4}         \n",
      "{'loss': 0.7142, 'learning_rate': 1.4475606730107127e-06, 'epoch': 6.44}        \n",
      "{'loss': 0.7056, 'learning_rate': 1.4186411796019415e-06, 'epoch': 6.48}        \n",
      "{'loss': 0.7044, 'learning_rate': 1.3898875799573462e-06, 'epoch': 6.52}        \n",
      "{'loss': 0.7337, 'learning_rate': 1.3613050302734443e-06, 'epoch': 6.56}        \n",
      "{'loss': 0.7677, 'learning_rate': 1.3328986560734727e-06, 'epoch': 6.6}         \n",
      "{'loss': 0.6983, 'learning_rate': 1.3046735512882642e-06, 'epoch': 6.64}        \n",
      "{'loss': 0.7465, 'learning_rate': 1.2766347773427824e-06, 'epoch': 6.68}        \n",
      "{'loss': 0.7578, 'learning_rate': 1.2487873622484889e-06, 'epoch': 6.72}        \n",
      "{'loss': 0.7737, 'learning_rate': 1.2211362997017027e-06, 'epoch': 6.76}        \n",
      "{'loss': 0.7377, 'learning_rate': 1.1936865481881178e-06, 'epoch': 6.8}         \n",
      "{'loss': 0.7158, 'learning_rate': 1.1664430300936236e-06, 'epoch': 6.84}        \n",
      "{'loss': 0.6666, 'learning_rate': 1.1394106308216074e-06, 'epoch': 6.88}        \n",
      "{'loss': 0.7163, 'learning_rate': 1.1125941979168907e-06, 'epoch': 6.92}        \n",
      "{'loss': 0.7477, 'learning_rate': 1.0859985401964446e-06, 'epoch': 6.96}        \n",
      " 70%|███████████████████████████▎           | 1728/2470 [06:03<01:36,  7.73it/s][INFO|trainer.py:2443] 2022-04-30 02:11:26,845 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2445] 2022-04-30 02:11:26,845 >>   Num examples = 219\n",
      "[INFO|trainer.py:2448] 2022-04-30 02:11:26,845 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|██████▎                                     | 4/28 [00:00<00:00, 37.82it/s]\u001b[A\n",
      " 29%|████████████▌                               | 8/28 [00:00<00:00, 29.01it/s]\u001b[A\n",
      " 43%|██████████████████▍                        | 12/28 [00:00<00:00, 26.48it/s]\u001b[A\n",
      " 54%|███████████████████████                    | 15/28 [00:00<00:00, 26.21it/s]\u001b[A\n",
      " 64%|███████████████████████████▋               | 18/28 [00:00<00:00, 25.45it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 21/28 [00:00<00:00, 25.02it/s]\u001b[A\n",
      " 86%|████████████████████████████████████▊      | 24/28 [00:00<00:00, 23.97it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7278063297271729, 'eval_runtime': 1.1177, 'eval_samples_per_second': 195.938, 'eval_steps_per_second': 25.051, 'epoch': 7.0}\n",
      " 70%|███████████████████████████▎           | 1729/2470 [06:04<01:35,  7.73it/s]\n",
      "100%|███████████████████████████████████████████| 28/28 [00:01<00:00, 24.39it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2193] 2022-04-30 02:11:27,965 >> Saving model checkpoint to ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-1729\n",
      "[INFO|configuration_utils.py:446] 2022-04-30 02:11:27,984 >> Configuration saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-1729/config.json\n",
      "[INFO|modeling_utils.py:1469] 2022-04-30 02:11:33,874 >> Model weights saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-1729/pytorch_model.bin\n",
      "[INFO|feature_extraction_utils.py:351] 2022-04-30 02:11:33,915 >> Feature extractor saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-1729/preprocessor_config.json\n",
      "[INFO|trainer.py:2271] 2022-04-30 02:11:45,401 >> Deleting older checkpoint [orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-988] due to args.save_total_limit\n",
      "{'loss': 0.743, 'learning_rate': 1.0596284268870582e-06, 'epoch': 7.0}          \n",
      "{'loss': 0.7467, 'learning_rate': 1.033488586770107e-06, 'epoch': 7.04}         \n",
      "{'loss': 0.7177, 'learning_rate': 1.0075837073335662e-06, 'epoch': 7.09}        \n",
      "{'loss': 0.6909, 'learning_rate': 9.819184339314357e-07, 'epoch': 7.13}         \n",
      "{'loss': 0.7214, 'learning_rate': 9.564973689507221e-07, 'epoch': 7.17}         \n",
      "{'loss': 0.7572, 'learning_rate': 9.31325070986118e-07, 'epoch': 7.21}          \n",
      "{'loss': 0.7341, 'learning_rate': 9.064060540225395e-07, 'epoch': 7.25}         \n",
      "{'loss': 0.7298, 'learning_rate': 8.81744786625667e-07, 'epoch': 7.29}          \n",
      "{'loss': 0.7299, 'learning_rate': 8.573456911406198e-07, 'epoch': 7.33}         \n",
      "{'loss': 0.7052, 'learning_rate': 8.332131428989296e-07, 'epoch': 7.37}         \n",
      "{'loss': 0.7329, 'learning_rate': 8.093514694339416e-07, 'epoch': 7.41}         \n",
      "{'loss': 0.7238, 'learning_rate': 7.85764949704782e-07, 'epoch': 7.45}          \n",
      "{'loss': 0.7323, 'learning_rate': 7.624578133290426e-07, 'epoch': 7.49}         \n",
      "{'loss': 0.7165, 'learning_rate': 7.394342398243132e-07, 'epoch': 7.53}         \n",
      "{'loss': 0.7304, 'learning_rate': 7.166983578586889e-07, 'epoch': 7.57}         \n",
      "{'loss': 0.7232, 'learning_rate': 6.942542445104116e-07, 'epoch': 7.61}         \n",
      "{'loss': 0.7412, 'learning_rate': 6.721059245367464e-07, 'epoch': 7.65}         \n",
      "{'loss': 0.7533, 'learning_rate': 6.50257369652252e-07, 'epoch': 7.69}          \n",
      "{'loss': 0.7147, 'learning_rate': 6.287124978165595e-07, 'epoch': 7.73}         \n",
      "{'loss': 0.7007, 'learning_rate': 6.074751725317863e-07, 'epoch': 7.77}         \n",
      "{'loss': 0.7523, 'learning_rate': 5.86549202149723e-07, 'epoch': 7.81}          \n",
      "{'loss': 0.7011, 'learning_rate': 5.659383391889054e-07, 'epoch': 7.85}         \n",
      "{'loss': 0.67, 'learning_rate': 5.456462796616988e-07, 'epoch': 7.89}           \n",
      "{'loss': 0.7188, 'learning_rate': 5.256766624115158e-07, 'epoch': 7.94}         \n",
      "{'loss': 0.7276, 'learning_rate': 5.060330684602889e-07, 'epoch': 7.98}         \n",
      " 80%|███████████████████████████████▏       | 1975/2470 [06:53<01:03,  7.78it/s][INFO|trainer.py:2443] 2022-04-30 02:12:17,609 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2445] 2022-04-30 02:12:17,609 >>   Num examples = 219\n",
      "[INFO|trainer.py:2448] 2022-04-30 02:12:17,609 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|██████▎                                     | 4/28 [00:00<00:00, 38.11it/s]\u001b[A\n",
      " 29%|████████████▌                               | 8/28 [00:00<00:00, 29.43it/s]\u001b[A\n",
      " 43%|██████████████████▍                        | 12/28 [00:00<00:00, 27.31it/s]\u001b[A\n",
      " 54%|███████████████████████                    | 15/28 [00:00<00:00, 25.84it/s]\u001b[A\n",
      " 64%|███████████████████████████▋               | 18/28 [00:00<00:00, 25.10it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 21/28 [00:00<00:00, 24.78it/s]\u001b[A\n",
      " 86%|████████████████████████████████████▊      | 24/28 [00:00<00:00, 24.88it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7208769917488098, 'eval_runtime': 1.1129, 'eval_samples_per_second': 196.777, 'eval_steps_per_second': 25.159, 'epoch': 8.0}\n",
      " 80%|███████████████████████████████▏       | 1976/2470 [06:54<01:03,  7.78it/s]\n",
      "100%|███████████████████████████████████████████| 28/28 [00:01<00:00, 25.48it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2193] 2022-04-30 02:12:18,724 >> Saving model checkpoint to ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-1976\n",
      "[INFO|configuration_utils.py:446] 2022-04-30 02:12:18,743 >> Configuration saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-1976/config.json\n",
      "[INFO|modeling_utils.py:1469] 2022-04-30 02:12:24,737 >> Model weights saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-1976/pytorch_model.bin\n",
      "[INFO|feature_extraction_utils.py:351] 2022-04-30 02:12:24,754 >> Feature extractor saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-1976/preprocessor_config.json\n",
      "[INFO|trainer.py:2271] 2022-04-30 02:12:36,261 >> Deleting older checkpoint [orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-1235] due to args.save_total_limit\n",
      "{'loss': 0.6906, 'learning_rate': 4.867190203663053e-07, 'epoch': 8.02}         \n",
      "{'loss': 0.7335, 'learning_rate': 4.677379815925319e-07, 'epoch': 8.06}         \n",
      "{'loss': 0.7046, 'learning_rate': 4.490933558855346e-07, 'epoch': 8.1}          \n",
      "{'loss': 0.6737, 'learning_rate': 4.307884866651056e-07, 'epoch': 8.14}         \n",
      "{'loss': 0.7344, 'learning_rate': 4.128266564247093e-07, 'epoch': 8.18}         \n",
      "{'loss': 0.7485, 'learning_rate': 3.9521108614285764e-07, 'epoch': 8.22}        \n",
      "{'loss': 0.7354, 'learning_rate': 3.7794493470550725e-07, 'epoch': 8.26}        \n",
      "{'loss': 0.7161, 'learning_rate': 3.6103129833960065e-07, 'epoch': 8.3}         \n",
      "{'loss': 0.7374, 'learning_rate': 3.4447321005784034e-07, 'epoch': 8.34}        \n",
      "{'loss': 0.7282, 'learning_rate': 3.2827363911479587e-07, 'epoch': 8.38}        \n",
      "{'loss': 0.6892, 'learning_rate': 3.1243549047444757e-07, 'epoch': 8.42}        \n",
      "{'loss': 0.7378, 'learning_rate': 2.9696160428926035e-07, 'epoch': 8.46}        \n",
      "{'loss': 0.7225, 'learning_rate': 2.818547553908741e-07, 'epoch': 8.5}          \n",
      "{'loss': 0.7281, 'learning_rate': 2.6711765279251286e-07, 'epoch': 8.54}        \n",
      "{'loss': 0.7493, 'learning_rate': 2.5275293920319627e-07, 'epoch': 8.58}        \n",
      "{'loss': 0.7332, 'learning_rate': 2.3876319055383745e-07, 'epoch': 8.62}        \n",
      "{'loss': 0.7222, 'learning_rate': 2.2515091553531845e-07, 'epoch': 8.66}        \n",
      "{'loss': 0.709, 'learning_rate': 2.119185551486253e-07, 'epoch': 8.7}           \n",
      "{'loss': 0.7464, 'learning_rate': 1.9906848226711596e-07, 'epoch': 8.74}        \n",
      "{'loss': 0.7415, 'learning_rate': 1.8660300121100943e-07, 'epoch': 8.79}        \n",
      "{'loss': 0.7303, 'learning_rate': 1.7452434733416916e-07, 'epoch': 8.83}        \n",
      "{'loss': 0.7081, 'learning_rate': 1.6283468662324747e-07, 'epoch': 8.87}        \n",
      "{'loss': 0.6992, 'learning_rate': 1.515361153092763e-07, 'epoch': 8.91}         \n",
      "{'loss': 0.6944, 'learning_rate': 1.4063065949176363e-07, 'epoch': 8.95}        \n",
      "{'loss': 0.7421, 'learning_rate': 1.3012027477536397e-07, 'epoch': 8.99}        \n",
      " 90%|███████████████████████████████████    | 2222/2470 [07:44<00:32,  7.67it/s][INFO|trainer.py:2443] 2022-04-30 02:13:08,695 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2445] 2022-04-30 02:13:08,695 >>   Num examples = 219\n",
      "[INFO|trainer.py:2448] 2022-04-30 02:13:08,695 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|██████▎                                     | 4/28 [00:00<00:00, 32.40it/s]\u001b[A\n",
      " 29%|████████████▌                               | 8/28 [00:00<00:00, 23.75it/s]\u001b[A\n",
      " 39%|████████████████▉                          | 11/28 [00:00<00:00, 21.72it/s]\u001b[A\n",
      " 50%|█████████████████████▌                     | 14/28 [00:00<00:00, 21.34it/s]\u001b[A\n",
      " 61%|██████████████████████████                 | 17/28 [00:00<00:00, 20.19it/s]\u001b[A\n",
      " 71%|██████████████████████████████▋            | 20/28 [00:00<00:00, 20.45it/s]\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 23/28 [00:01<00:00, 19.88it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7278832793235779, 'eval_runtime': 1.3627, 'eval_samples_per_second': 160.712, 'eval_steps_per_second': 20.548, 'epoch': 9.0}\n",
      " 90%|███████████████████████████████████    | 2223/2470 [07:46<00:32,  7.67it/s]\n",
      "100%|███████████████████████████████████████████| 28/28 [00:01<00:00, 20.33it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2193] 2022-04-30 02:13:10,060 >> Saving model checkpoint to ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-2223\n",
      "[INFO|configuration_utils.py:446] 2022-04-30 02:13:10,083 >> Configuration saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-2223/config.json\n",
      "[INFO|modeling_utils.py:1469] 2022-04-30 02:13:16,157 >> Model weights saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-2223/pytorch_model.bin\n",
      "[INFO|feature_extraction_utils.py:351] 2022-04-30 02:13:16,176 >> Feature extractor saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-2223/preprocessor_config.json\n",
      "[INFO|trainer.py:2271] 2022-04-30 02:13:27,651 >> Deleting older checkpoint [orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-1482] due to args.save_total_limit\n",
      "{'loss': 0.7288, 'learning_rate': 1.2000684591919382e-07, 'epoch': 9.03}        \n",
      "{'loss': 0.7316, 'learning_rate': 1.1029218649885197e-07, 'epoch': 9.07}        \n",
      "{'loss': 0.7329, 'learning_rate': 1.0097803858119847e-07, 'epoch': 9.11}        \n",
      "{'loss': 0.7096, 'learning_rate': 9.206607241196463e-08, 'epoch': 9.15}         \n",
      "{'loss': 0.7174, 'learning_rate': 8.355788611623792e-08, 'epoch': 9.19}         \n",
      "{'loss': 0.7374, 'learning_rate': 7.545500541187898e-08, 'epoch': 9.23}         \n",
      "{'loss': 0.7002, 'learning_rate': 6.775888333592693e-08, 'epoch': 9.27}         \n",
      "{'loss': 0.7451, 'learning_rate': 6.047089998403361e-08, 'epoch': 9.31}         \n",
      "{'loss': 0.7295, 'learning_rate': 5.359236226298051e-08, 'epoch': 9.35}         \n",
      "{'loss': 0.7014, 'learning_rate': 4.712450365632146e-08, 'epoch': 9.39}         \n",
      "{'loss': 0.7199, 'learning_rate': 4.1068484003186925e-08, 'epoch': 9.43}        \n",
      "{'loss': 0.7364, 'learning_rate': 3.54253892902996e-08, 'epoch': 9.47}          \n",
      "{'loss': 0.7319, 'learning_rate': 3.019623145723172e-08, 'epoch': 9.51}         \n",
      "{'loss': 0.7478, 'learning_rate': 2.5381948214939304e-08, 'epoch': 9.55}        \n",
      "{'loss': 0.727, 'learning_rate': 2.0983402877608642e-08, 'epoch': 9.6}          \n",
      "{'loss': 0.7139, 'learning_rate': 1.70013842078447e-08, 'epoch': 9.64}          \n",
      "{'loss': 0.6926, 'learning_rate': 1.3436606275226986e-08, 'epoch': 9.68}        \n",
      "{'loss': 0.7417, 'learning_rate': 1.0289708328259111e-08, 'epoch': 9.72}        \n",
      "{'loss': 0.7599, 'learning_rate': 7.561254679738868e-09, 'epoch': 9.76}         \n",
      "{'loss': 0.7418, 'learning_rate': 5.251734605560537e-09, 'epoch': 9.8}          \n",
      "{'loss': 0.7408, 'learning_rate': 3.3615622569790717e-09, 'epoch': 9.84}        \n",
      "{'loss': 0.6997, 'learning_rate': 1.8910765863411336e-09, 'epoch': 9.88}        \n",
      "{'loss': 0.6796, 'learning_rate': 8.405412863042756e-10, 'epoch': 9.92}         \n",
      "{'loss': 0.72, 'learning_rate': 2.1014474254951037e-10, 'epoch': 9.96}          \n",
      "{'loss': 0.7534, 'learning_rate': 0.0, 'epoch': 10.0}                           \n",
      "100%|███████████████████████████████████████| 2470/2470 [08:36<00:00,  7.55it/s][INFO|trainer.py:2443] 2022-04-30 02:14:00,124 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2445] 2022-04-30 02:14:00,124 >>   Num examples = 219\n",
      "[INFO|trainer.py:2448] 2022-04-30 02:14:00,124 >>   Batch size = 8\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|██████▎                                     | 4/28 [00:00<00:00, 39.19it/s]\u001b[A\n",
      " 29%|████████████▌                               | 8/28 [00:00<00:00, 28.88it/s]\u001b[A\n",
      " 43%|██████████████████▍                        | 12/28 [00:00<00:00, 26.13it/s]\u001b[A\n",
      " 54%|███████████████████████                    | 15/28 [00:00<00:00, 25.29it/s]\u001b[A\n",
      " 64%|███████████████████████████▋               | 18/28 [00:00<00:00, 25.07it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 21/28 [00:00<00:00, 23.93it/s]\u001b[A\n",
      " 86%|████████████████████████████████████▊      | 24/28 [00:00<00:00, 23.64it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.7247821688652039, 'eval_runtime': 1.1398, 'eval_samples_per_second': 192.136, 'eval_steps_per_second': 24.565, 'epoch': 10.0}\n",
      "100%|███████████████████████████████████████| 2470/2470 [08:37<00:00,  7.55it/s]\n",
      "100%|███████████████████████████████████████████| 28/28 [00:01<00:00, 23.94it/s]\u001b[A\n",
      "                                                                                \u001b[A[INFO|trainer.py:2193] 2022-04-30 02:14:01,267 >> Saving model checkpoint to ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-2470\n",
      "[INFO|configuration_utils.py:446] 2022-04-30 02:14:01,294 >> Configuration saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-2470/config.json\n",
      "[INFO|modeling_utils.py:1469] 2022-04-30 02:14:07,347 >> Model weights saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-2470/pytorch_model.bin\n",
      "[INFO|feature_extraction_utils.py:351] 2022-04-30 02:14:07,386 >> Feature extractor saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-2470/preprocessor_config.json\n",
      "[INFO|trainer.py:2271] 2022-04-30 02:14:18,758 >> Deleting older checkpoint [orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-1729] due to args.save_total_limit\n",
      "[INFO|trainer.py:1557] 2022-04-30 02:14:18,845 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:1565] 2022-04-30 02:14:18,845 >> Loading best model from ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/checkpoint-1976 (score: 0.7208769917488098).\n",
      "{'train_runtime': 542.5673, 'train_samples_per_second': 36.327, 'train_steps_per_second': 4.552, 'train_loss': 0.7769892742759303, 'epoch': 10.0}\n",
      "100%|███████████████████████████████████████| 2470/2470 [09:02<00:00,  4.55it/s]\n",
      "[INFO|trainer.py:2193] 2022-04-30 02:14:26,326 >> Saving model checkpoint to ./orchid219_pretrain_vit-base-patch16-224-in21k-mae\n",
      "[INFO|configuration_utils.py:446] 2022-04-30 02:14:26,367 >> Configuration saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/config.json\n",
      "[INFO|modeling_utils.py:1469] 2022-04-30 02:14:32,179 >> Model weights saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/pytorch_model.bin\n",
      "[INFO|feature_extraction_utils.py:351] 2022-04-30 02:14:32,227 >> Feature extractor saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/preprocessor_config.json\n",
      "[INFO|trainer.py:2193] 2022-04-30 02:14:32,259 >> Saving model checkpoint to ./orchid219_pretrain_vit-base-patch16-224-in21k-mae\n",
      "[INFO|configuration_utils.py:446] 2022-04-30 02:14:32,291 >> Configuration saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/config.json\n",
      "[INFO|modeling_utils.py:1469] 2022-04-30 02:14:38,062 >> Model weights saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/pytorch_model.bin\n",
      "[INFO|feature_extraction_utils.py:351] 2022-04-30 02:14:38,130 >> Feature extractor saved in ./orchid219_pretrain_vit-base-patch16-224-in21k-mae/preprocessor_config.json\n",
      "Several commits (2) will be pushed upstream.\n",
      "04/30/2022 02:15:16 - WARNING - huggingface_hub.repository - Several commits (2) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n",
      "04/30/2022 02:15:16 - WARNING - huggingface_hub.repository - The progress bars may be unreliable.\n",
      "Upload file pytorch_model.bin:  11%|▉       | 49.1M/427M [11:34<01:50, 3.58MB/s]^C\n",
      "Upload file pytorch_model.bin: 100%|██████████| 427M/427M [11:35<00:00, 644kB/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"run_mae.py\", line 371, in <module>\n",
      "    main()\n",
      "  File \"run_mae.py\", line 347, in main\n",
      "    trainer.save_model()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\", line 2159, in save_model\n",
      "    self.push_to_hub(commit_message=\"Model save\")\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\", line 2939, in push_to_hub\n",
      "    git_head_commit_url = self.repo.push_to_hub(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/huggingface_hub/repository.py\", line 1475, in push_to_hub\n",
      "    return self.git_push(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/huggingface_hub/repository.py\", line 1193, in git_push\n",
      "    stdout, stderr = process.communicate()\n",
      "  File \"/opt/conda/lib/python3.8/subprocess.py\", line 1028, in communicate\n",
      "    stdout, stderr = self._communicate(input, endtime, timeout)\n",
      "  File \"/opt/conda/lib/python3.8/subprocess.py\", line 1870, in _communicate\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "! accelerate launch run_mae.py \\\n",
    "    --dataset_name=\"gary109/orchid219\" \\\n",
    "    --model_name_or_path=\"google/vit-base-patch16-224-in21k\" \\\n",
    "    --output_dir=\"./orchid219_pretrain_vit-base-patch16-224-in21k-mae\" \\\n",
    "    --remove_unused_columns False \\\n",
    "    --label_names pixel_values \\\n",
    "    --mask_ratio 0.75 \\\n",
    "    --norm_pix_loss \\\n",
    "    --do_train \\\n",
    "    --do_eval \\\n",
    "    --base_learning_rate 1.5e-4 \\\n",
    "    --lr_scheduler_type cosine \\\n",
    "    --weight_decay 0.05 \\\n",
    "    --num_train_epochs 800 \\\n",
    "    --warmup_ratio 0.05 \\\n",
    "    --per_device_train_batch_size 8 \\\n",
    "    --per_device_eval_batch_size 8 \\\n",
    "    --logging_strategy steps \\\n",
    "    --logging_steps 10 \\\n",
    "    --evaluation_strategy epoch \\\n",
    "    --save_strategy epoch \\\n",
    "    --load_best_model_at_end True \\\n",
    "    --save_total_limit 3 \\\n",
    "    --overwrite_output_dir \\\n",
    "    --push_to_hub \\\n",
    "    --hub_model_id=\"orchid219_pretrain_vit-base-patch16-224-in21k-mae\" \\\n",
    "\t--hub_token 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 \\\n",
    "    --seed 1337\n",
    "\n",
    "#     # --gradient_accumulation_steps 8 \\\n",
    "#     # --gradient_checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerate launch run_mae.py --dataset_name=\"gary109/orchid219\" --model_name_or_path=\"google/vit-base-patch16-224-in21k\" --output_dir=\"./orchid219_pretrain_vit-base-patch16-224-in21k-mae\" --remove_unused_columns=\"False\" --label_names=\"pixel_values\" --mask_ratio=\"0.75\" --norm_pix_loss --do_train --do_eval --base_learning_rate=\"1.5e-4\" --lr_scheduler_type=\"cosine\" --weight_decay=\"0.05\" --num_train_epochs=\"800\" --warmup_ratio=\"0.05\" --per_device_train_batch_size=\"8\" --per_device_eval_batch_size=\"8\" --logging_strategy=\"steps\" --logging_steps=\"10\" --evaluation_strategy=\"epoch\" --save_strategy=\"epoch\" --load_best_model_at_end=\"True\" --save_total_limit=\"3\" --overwrite_output_dir --push_to_hub --hub_model_id=\"orchid219_pretrain_vit-base-patch16-224-in21k-mae\" --hub_token=\"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\" --seed=\"1337\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYRmaQJjkBmT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Pre-Train Orchid219 Image classification with ViT",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "071bd6eeccc24393ad0c4ed1904d9b99": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16613c23fc804509875e9b2c4c46fa3b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "232f450fc1084b368e735e8bdabcb315": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b8a4c42e77c4719a7a76f10e4bf6480",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e4a237479d5448bb877680f28f26657f",
      "value": 1
     }
    },
    "27dafd3d1b42443883a2a67deb691e97": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2b8a4c42e77c4719a7a76f10e4bf6480": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "3a5591941ee04ad6b3deb29741372d12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5a6d7fa4035c4471855463d27db9ecde",
       "IPY_MODEL_796a343f14e141d38dc457c80e3613cc",
       "IPY_MODEL_b7e85a6ff68f480f9d3b115387cd661e"
      ],
      "layout": "IPY_MODEL_071bd6eeccc24393ad0c4ed1904d9b99"
     }
    },
    "3cfdffc97dd64e689c13a3203c8715c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9170add919094c98839f6355da93bba3",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_27dafd3d1b42443883a2a67deb691e97",
      "value": 1
     }
    },
    "47a7c2c63c6f465f918e83c873b26a83": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bcc75560cd24440a03c774991e3d1c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "51723f43395349f4965eba96db467854": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5a6d7fa4035c4471855463d27db9ecde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8def3f91648e4d10ab0cbd59ecff173c",
      "placeholder": "​",
      "style": "IPY_MODEL_c4793b3ec6464b299ea54c07aafd78de",
      "value": "Downloading data: 100%"
     }
    },
    "5a80f83ce5144729b90fe03006e2b7b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6300c5f2ab3c4d918efb56956a745ae5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6adca3444c844b71a097a94107693eb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c682bf0dd540477ab1c8fcfb67103b0f",
       "IPY_MODEL_232f450fc1084b368e735e8bdabcb315",
       "IPY_MODEL_c65ee8f3bc55478db07bdedd56b62fc1"
      ],
      "layout": "IPY_MODEL_d76650ba429c4d28b322310b1b54f785"
     }
    },
    "7219374e29594fa9a8562bcb4d3887ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_16613c23fc804509875e9b2c4c46fa3b",
      "placeholder": "​",
      "style": "IPY_MODEL_8831b701e2884c48856f4a34e7ee2228",
      "value": "Generating train split: "
     }
    },
    "796a343f14e141d38dc457c80e3613cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_818fccc99f4946e1a902ac9df64ddb4a",
      "max": 90862213,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_51723f43395349f4965eba96db467854",
      "value": 90862213
     }
    },
    "799b4d0bcd8642839302114793ed5cb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d6faa36675944bdc931b9a40689d1333",
       "IPY_MODEL_8bf216fd14d14371bb07547f6853ca6b",
       "IPY_MODEL_f2579b225d3e410a8182d4b63774d00c"
      ],
      "layout": "IPY_MODEL_ad987281505843b6a0c99864c1ed18d7"
     }
    },
    "818fccc99f4946e1a902ac9df64ddb4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8831b701e2884c48856f4a34e7ee2228": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8bf216fd14d14371bb07547f6853ca6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a211590713340ffa2afd8448b289516",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a992a4256f514aceae51b60c016450dd",
      "value": 2
     }
    },
    "8def3f91648e4d10ab0cbd59ecff173c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e98e0f6ad9d4ad49a14efa65f1b2fa4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7219374e29594fa9a8562bcb4d3887ce",
       "IPY_MODEL_3cfdffc97dd64e689c13a3203c8715c4",
       "IPY_MODEL_faad642c41a243d8a72f64bd9787f164"
      ],
      "layout": "IPY_MODEL_5a80f83ce5144729b90fe03006e2b7b3"
     }
    },
    "9170add919094c98839f6355da93bba3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "9a211590713340ffa2afd8448b289516": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f372ce861b4404d878a2384ff100630": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a3d510498c984e73a3a46825defab03c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a76d622b57e24861ad46d939cba47330": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a992a4256f514aceae51b60c016450dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ad987281505843b6a0c99864c1ed18d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b58eeebdb4eb4f02b66ea0e1119625e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b7e85a6ff68f480f9d3b115387cd661e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3d510498c984e73a3a46825defab03c",
      "placeholder": "​",
      "style": "IPY_MODEL_6300c5f2ab3c4d918efb56956a745ae5",
      "value": " 90.9M/90.9M [00:03&lt;00:00, 34.2MB/s]"
     }
    },
    "c34c41b447ac40559d143824c9937dcd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4793b3ec6464b299ea54c07aafd78de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c65ee8f3bc55478db07bdedd56b62fc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4bcc75560cd24440a03c774991e3d1c0",
      "placeholder": "​",
      "style": "IPY_MODEL_b58eeebdb4eb4f02b66ea0e1119625e0",
      "value": " 69/0 [00:00&lt;00:00, 688.74 examples/s]"
     }
    },
    "c682bf0dd540477ab1c8fcfb67103b0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c34c41b447ac40559d143824c9937dcd",
      "placeholder": "​",
      "style": "IPY_MODEL_e6e25053f13549eaafc69292a015002a",
      "value": "Generating validation split: "
     }
    },
    "cb70106d26d241c8ada4d671bfa382a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6faa36675944bdc931b9a40689d1333": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7d7c72243bf4a62bc134e5516107b30",
      "placeholder": "​",
      "style": "IPY_MODEL_e93605c035234f05ab37334aaf097f2b",
      "value": "100%"
     }
    },
    "d76650ba429c4d28b322310b1b54f785": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7d7c72243bf4a62bc134e5516107b30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4a237479d5448bb877680f28f26657f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e6e25053f13549eaafc69292a015002a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e93605c035234f05ab37334aaf097f2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f2579b225d3e410a8182d4b63774d00c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb70106d26d241c8ada4d671bfa382a2",
      "placeholder": "​",
      "style": "IPY_MODEL_a76d622b57e24861ad46d939cba47330",
      "value": " 2/2 [00:00&lt;00:00, 20.62it/s]"
     }
    },
    "faad642c41a243d8a72f64bd9787f164": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47a7c2c63c6f465f918e83c873b26a83",
      "placeholder": "​",
      "style": "IPY_MODEL_9f372ce861b4404d878a2384ff100630",
      "value": " 1851/0 [00:00&lt;00:00, 1642.21 examples/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
